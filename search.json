[{"path":"https://merck.github.io/simtrial/articles/modestWLRTVignette.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using the Magirr-Burman weights for testing","text":"Magirr Burman (2019) implemented modestly weighted logrank test following claim: Tests new class can constructed high power delayed-onset treatment effect scenario, well almost efficient standard logrank test proportional hazards. implemented package modestWLRT. Since implementation relatively straightforward, added functionality simtrial package explain use mb_weight() function. Packages used follows:","code":"library(simtrial) library(dplyr) library(survival)"},{"path":"https://merck.github.io/simtrial/articles/modestWLRTVignette.html","id":"simulating-a-delayed-effect-example","dir":"Articles","previous_headings":"","what":"Simulating a delayed effect example","title":"Using the Magirr-Burman weights for testing","text":"First, specify study duration, sample size enrollment rates. enrollment rate assumed constant enrollment period targeted sample size reached. failure rates, consider delayed treatment effect example Magirr Burman (2019). control group exponential failure rate median 15 months. initial 6 months, underlying hazard ratio one followed hazard ratio 0.7 thereafter. differs Magirr Burman (2019) delayed effect assumptions assume hazard ratio 0.5 6 months. Now generate single dataset characteristics cut data analysis 36 months post start enrollment. plot Kaplan-Meier curves resulting dataset (red curve experimental treatment, black control):","code":"studyDuration <- 36 sample_size <- 300 enroll_rate <- tibble::tibble(duration = 12, rate = 200 / 12) fail_rate <- tibble::tribble(   ~stratum, ~duration, ~fail_rate, ~hr, ~dropout_rate,   \"All\", 6, log(2) / 15, 1, 0,   \"All\", 36, log(2) / 15, .6, 0 ) set.seed(7789) xpar <- simfix2simpwsurv(fail_rate) MBdelay <- sim_pw_surv(   n = sample_size,   stratum = tibble::tibble(stratum = \"All\", p = 1),   block = c(rep(\"control\", 2), rep(\"experimental\", 2)),   enroll_rate = enroll_rate,   fail_rate = xpar$fail_rate,   dropout_rate = xpar$dropout_rate ) %>%   cut_data_by_date(studyDuration) fit <- survfit(Surv(tte, event) ~ treatment, data = MBdelay) plot(fit, col = 1:2, mark = \"|\", xaxt = \"n\") axis(1, xaxp = c(0, 36, 6))"},{"path":"https://merck.github.io/simtrial/articles/modestWLRTVignette.html","id":"generalizing-the-magirr-burman-test","dir":"Articles","previous_headings":"","what":"Generalizing the Magirr-Burman test","title":"Using the Magirr-Burman weights for testing","text":"Next, consider Magirr (2021) extension modestly weighted logrank test (MWLRT) Magirr Burman (2019) weights follows: \\[w(t, \\tau, w_{\\max}) = \\min\\left(w_{\\max},\\left(\\frac{1}{S(\\min(t,\\tau))}\\right)\\right).\\] requires generating weights computing test. begin default w_max=\\Inf corresponds original Magirr Burman (2019) test set time maximum weight \\(\\tau\\) delay = 6. Now set maximum weight 2 Magirr (2021) set delay=Inf maximum weight begins observed median observed combined treatment Kaplan-Meier curve. Another way can done generalized Fleming-Harrington test \\[w(t; \\rho, \\gamma, w_{\\max})= \\min((1-F(t))^\\rho F(t)^\\gamma, w_{\\max})).\\] let \\(\\gamma=0, \\rho = -1/2.\\)","code":"ZMB <- MBdelay %>%   counting_process(arm = \"experimental\") %>%   mb_weight(delay = 6) %>%   summarize(S = sum(o_minus_e * mb_weight), V = sum(var_o_minus_e * mb_weight^2), z = S / sqrt(V)) # Compute p-value of modestly weighted logrank of Magirr-Burman pnorm(ZMB$z) #> [1] 0.04812254 ZMB <- MBdelay %>%   counting_process(arm = \"experimental\") %>%   mb_weight(delay = Inf, w_max = 2) %>%   summarize(S = sum(o_minus_e * mb_weight), V = sum(var_o_minus_e * mb_weight^2), z = S / sqrt(V)) # Compute p-value of modestly weighted logrank of Magirr-Burman pnorm(ZMB$z) #> [1] 0.04503586 w_max <- 2 Z_modified_FH <- MBdelay %>%   counting_process(arm = \"experimental\") %>%   mutate(w = pmin(w_max, 1 / s)) %>%   summarize(S = sum(o_minus_e * w), V = sum(var_o_minus_e * w^2), z = S / sqrt(V)) # Compute p-value of modestly weighted logrank of Magirr-Burman pnorm(Z_modified_FH$z) #> [1] 0.04503586"},{"path":"https://merck.github.io/simtrial/articles/modestWLRTVignette.html","id":"freidlin-and-korn-strong-null-hypothesis-example","dir":"Articles","previous_headings":"Generalizing the Magirr-Burman test","what":"Freidlin and Korn strong null hypothesis example","title":"Using the Magirr-Burman weights for testing","text":"underlying survival worse experimental group uniformly worse experimental group end study. presented Freidlin Korn (2019). case, hazard ratio 16 1/10 1 year (1.2 months), followed hazard ratio First, specify study duration, sample size enrollment rates. enrollment rate assumed constant enrollment period targeted sample size reached. failure rates, consider delayed treatment effect example Magirr Burman (2019). control group exponential failure rate median 15 months. initial 6 months, underlying hazard ratio one followed hazard ratio 0.7 thereafter. differs Magirr Burman (2019) delayed effect assumptions assume hazard ratio 0.5 6 months. Now generate single dataset characteristics cut data analysis 36 months post start enrollment. plot Kaplan-Meier curves resulting dataset (red curve experimental treatment, black control):  perform logrank weighted logrank tests suggested limited downweighting follows: Now MaxCombo test component tests, p-value Next, consider Magirr Burman (2019) modestly weighted logrank test -weighting specified first 6 months maximum weight 2. requires generating weights computing test. Finally, consider weighted logrank tests less -weighting. Results quite similar results greater -weighting. Now MaxCombo test component tests, p-value Thus, less -weighting MaxCombo test appears less problematic. addressed greater length elsewhere.","code":"studyDuration <- 5 sample_size <- 2000 enrollDuration <- .0001 enroll_rate <- tibble::tibble(duration = enrollDuration, rate = sample_size / enrollDuration) fail_rate <- tibble::tibble(   stratum = \"All\",   fail_rate = 0.25,   dropout_rate = 0,   hr = c(4 / .25, .19 / .25),   duration = c(.1, 4.9) ) set.seed(7783) xpar <- simfix2simpwsurv(fail_rate) FHwn <- sim_pw_surv(   n = sample_size,   stratum = tibble::tibble(stratum = \"All\", p = 1),   block = c(rep(\"control\", 2), rep(\"experimental\", 2)),   enroll_rate = enroll_rate,   fail_rate = xpar$fail_rate,   dropout_rate = xpar$dropout_rate ) %>%   cut_data_by_date(studyDuration) fit <- survfit(Surv(tte, event) ~ treatment, data = FHwn) plot(fit, col = 1:2, mark = \"|\", xaxt = \"n\") axis(1, xaxp = c(0, 36, 6)) xx <- FHwn %>%   counting_process(arm = \"experimental\") %>%   tenFHcorr(rho_gamma = tibble(rho = c(0, 0, 1), gamma = c(0, 1, 1))) %>%   mutate(p = pnorm(z)) xx #>   rho gamma         z        v1        v2        v3 #> 1   0     0  4.808526 1.0000000 0.8652115 0.9356769 #> 2   0     1 -3.204735 0.8652115 1.0000000 0.9580098 #> 3   1     1 -1.220445 0.9356769 0.9580098 1.0000000 #>              p #> 1 0.9999992398 #> 2 0.0006759349 #> 3 0.1111481087 xx %>% pvalue_maxcombo() #> [1] 0.001256683 ZMB <- FHwn %>%   counting_process(arm = \"experimental\") %>%   mb_weight(delay = 6, w_max = 2) %>%   summarize(S = sum(o_minus_e * mb_weight), V = sum(var_o_minus_e * mb_weight^2), z = S / sqrt(V))  # Compute p-value of modestly weighted logrank of Magirr-Burman pnorm(ZMB$z) #> [1] 0.920727 xx <- FHwn %>%   counting_process(arm = \"experimental\") %>%   tenFHcorr(rho_gamma = tibble(rho = c(0, 0, .5), gamma = c(0, .5, .5))) %>%   mutate(p = pnorm(z)) xx #>   rho gamma          z        v1        v2        v3 #> 1 0.0   0.0  4.8085258 1.0000000 0.9421013 0.9709414 #> 2 0.0   0.5 -0.6919228 0.9421013 1.0000000 0.9872682 #> 3 0.5   0.5  0.9278452 0.9709414 0.9872682 1.0000000 #>           p #> 1 0.9999992 #> 2 0.2444929 #> 3 0.8232561 xx %>% pvalue_maxcombo() #> [1] 0.2915952"},{"path":[]},{"path":"https://merck.github.io/simtrial/articles/pvalue_maxcomboVignette.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Computing p-values for Fleming-Harring weighted logrank tests and the MaxCombo test","text":"vignette demonstrates use simple routine simulations testing using Fleming-Harrington weighted logrank tests MaxCombo test. addition, demonstrate perform tests dataset generated simulation routines within package. Note p-values computed one-sided small values indicating experimental treatment favored.","code":""},{"path":"https://merck.github.io/simtrial/articles/pvalue_maxcomboVignette.html","id":"defining-the-test","dir":"Articles","previous_headings":"","what":"Defining the test","title":"Computing p-values for Fleming-Harring weighted logrank tests and the MaxCombo test","text":"MaxCombo test posed maximum multiple Fleming-Harrington weighted logrank tests (Harrington Fleming (1982), Fleming Harrington (2011)). Combination tests looking maximum selected tests class also proposed; see Lee (2007), Roychoudhury et al. (2021), Lin et al. (2020). Fleming-Harrington class indexed parameters \\(\\rho\\ge 0\\) \\(\\gamma\\ge 0\\). denote FH(\\(\\rho,\\gamma\\)). class includes logrank test FH(0,0). tests interest include: FH(0,1): test -weights early events FH(1,0): test -weights late events FH(1,1): test -weights events increasingly quantiles differ median","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/articles/pvalue_maxcomboVignette.html","id":"generating-test-statistics-with-sim_fixed_n","dir":"Articles","previous_headings":"Executing for a single dataset","what":"Generating test statistics with sim_fixed_n()","title":"Computing p-values for Fleming-Harring weighted logrank tests and the MaxCombo test","text":"begin single trial simulation generated routine sim_fixed_n() using default arguments routine. sim_fixed_n() produces one record per test data cutoff method per simulation. choose 3 tests (logrank=FH(0,0), FH(0,1) FH(1,1)). one test chosen correlation tests computed shown Karrison (2016), case columns V1, V2, V3. columns rho, gamma indicate \\(\\rho\\) \\(\\gamma\\) used compute test. z FH(\\(\\rho,\\gamma\\)) normal test statistic variance 1 negative value favoring experimental treatment. variable cut indicates data cut analysis, case maximum targeted minimum follow-last enrollment date targeted event count reached. Sim sequential index simulations performed. format, MaxCombo p-value per Karrison (2016), Roychoudhury et al. (2021) can computed follows (note need package mvtnorm installed):","code":"library(simtrial) library(knitr) library(dplyr) x <- sim_fixed_n(n_sim = 1, timing_type = 5, rho_gamma = tibble::tibble(rho = c(0, 0, 1), gamma = c(0, 1, 1))) x %>% kable(digits = 2) pvalue_maxcombo(x) #> [1] 0.1646379"},{"path":"https://merck.github.io/simtrial/articles/pvalue_maxcomboVignette.html","id":"generating-data-with-simtrialsim_pw_surv","dir":"Articles","previous_headings":"Executing for a single dataset","what":"Generating data with simtrial::sim_pw_surv()","title":"Computing p-values for Fleming-Harring weighted logrank tests and the MaxCombo test","text":"begin another simulation generated simtrial::sim_pw_surv(). , use defaults routine. generated, need cut data analysis. cut 75 events. Now can analyze data. begin s show can done single line. case, use 4 test combination suggested Lin et al. (2020), Roychoudhury et al. (2021). Now compute p-value : Suppose want p-value just based logrank FH(0,1) FH(1,0) suggested Lee (2007). remove rows columns associated FH(0,0) FH(1,1) apply pvalue_maxcombo().","code":"s <- sim_pw_surv(n = 100) head(s) %>% kable(digits = 2) x <- s %>% cut_data_by_event(75) head(x) %>% kable(digits = 2) z <- s %>%   cut_data_by_event(75) %>%   counting_process(arm = \"experimental\") %>%   tenFHcorr(rho_gamma = tibble(rho = c(0, 0, 1, 1), gamma = c(0, 1, 0, 1))) z %>% kable(digits = 2) pvalue_maxcombo(z) #> [1] 0.004625496 pvalue_maxcombo(z %>% select(-c(v1, v4)) %>% filter((rho == 0 & gamma == 1) | (rho == 1 & gamma == 0))) #> [1] 0.003903389"},{"path":"https://merck.github.io/simtrial/articles/pvalue_maxcomboVignette.html","id":"using-survival-data-in-another-format","dir":"Articles","previous_headings":"Executing for a single dataset","what":"Using survival data in another format","title":"Computing p-values for Fleming-Harring weighted logrank tests and the MaxCombo test","text":"trial generated sim_fixed_n(), process slightly involved. consider survival data simtrial format show transformation needed. case use small aml dataset survival package. rename variables create stratum variable follows: Now analyze data MaxCombo logrank FH(0,1) compute p-value.","code":"library(survival) head(aml) %>% kable() x <- aml %>% transmute(tte = time, event = status, stratum = \"All\", treatment = as.character(x)) head(x) %>% kable() x %>%   counting_process(arm = \"Maintained\") %>%   tenFHcorr(rho_gamma = tibble(rho = 0, gamma = c(0, 1))) %>%   pvalue_maxcombo() #> [1] 0.0491509"},{"path":"https://merck.github.io/simtrial/articles/pvalue_maxcomboVignette.html","id":"simulation","dir":"Articles","previous_headings":"","what":"Simulation","title":"Computing p-values for Fleming-Harring weighted logrank tests and the MaxCombo test","text":"now consider example simulation pvalue_maxcombo() help file demonstrate simulate power MaxCombo test. However, increase number simulations 100 case; larger number used (e.g., 1000) better estimate design properties. test \\(\\alpha=0.001\\) level. note use group_map produces list p-values simulation. nice something worked like dplyr::summarize() avoid unlist() allow evaluating, say, multiple data cutoff methods. latter can done without re-run simulations follows, demonstrated smaller number simulations. Now compute p-value separately cut type, first targeted event count. Now use later targeted events minimum follow-cutoffs.","code":"# Only use cut events + min follow-up xx <- sim_fixed_n(n_sim = 100, timing_type = 5, rho_gamma = tibble(rho = c(0, 0, 1), gamma = c(0, 1, 1))) # MaxCombo power estimate for cutoff at max of targeted events, minimum follow-up p <- unlist(xx %>% group_by(sim) %>% group_map(pvalue_maxcombo)) mean(p < .001) #> [1] 0.78 # Only use cuts for events and events + min follow-up xx <- sim_fixed_n(n_sim = 100, timing_type = c(2, 5), rho_gamma = tibble(rho = 0, gamma = c(0, 1))) head(xx) %>% kable(digits = 2) # Subset to targeted events cutoff tests p <- unlist(xx %>% filter(cut == \"Targeted events\") %>% group_by(sim) %>% group_map(pvalue_maxcombo)) mean(p < .025) #> [1] 0.94 # Subset to targeted events cutoff tests p <- unlist(xx %>% filter(cut != \"Targeted events\") %>% group_by(sim) %>% group_map(pvalue_maxcombo)) mean(p < .025) #> [1] 0.95"},{"path":[]},{"path":"https://merck.github.io/simtrial/articles/simtrialroutines.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Basic tools for time-to-event trial simulation and testing","text":"vignette demonstrates lower-level routines simtrial package specifically related trial generation statistical testing. routines follows: randomize_by_fixed_block - fixed block randomization rpw_enroll - random inter-arrival times piecewise constant enrollment rates rpwexp - piecewise exponential failure rate generation cut_data_by_date - cut data analysis specified calendar time cut_data_by_event - cut data analysis specified event count, including ties cutoff date get_cut_date_by_event - find date event count reached counting_process - pre-process survival data counting process format Application demonstrated using higher-level routines sim_pw_surv() sim_fixed_n() generate simulations weighted logrank analysis stratified design. intent write routines spirit tidyverse approach (alternately referred data wrangling, tidy data, R Data Science, split-apply-combine). objectives easily documentable validated package easy use efficient broadly-useful tool simulation time--event clinical trials. package extended many ways future, including: Weighted logrank weighted Kaplan-Meier analyses One-step, hazard ratio estimator (first-order approximation PH) Randomization schemes stratified, fixed-block Poisson mixture survival distribution generation","code":"library(simtrial) library(knitr) library(tibble) library(dplyr)"},{"path":"https://merck.github.io/simtrial/articles/simtrialroutines.html","id":"randomization","dir":"Articles","previous_headings":"","what":"Randomization","title":"Basic tools for time-to-event trial simulation and testing","text":"Fixed block randomization arbitrary block contents performed demonstrated . case block size 5 one string repeated twice block three strings appearing . normally, default blocks size four:","code":"randomize_by_fixed_block(n = 10, block = c(\"A\", \"Dog\", \"Cat\", \"Cat\")) #>  [1] \"Dog\" \"Cat\" \"A\"   \"Cat\" \"Cat\" \"Cat\" \"Dog\" \"A\"   \"A\"   \"Dog\" randomize_by_fixed_block(n = 20) #>  [1] 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0"},{"path":"https://merck.github.io/simtrial/articles/simtrialroutines.html","id":"enrollment","dir":"Articles","previous_headings":"","what":"Enrollment","title":"Basic tools for time-to-event trial simulation and testing","text":"Piecewise constant enrollment can randomly generated follows. Note duration specifies interval durations constant rates; final rate extended long needed generate specified number observations.","code":"rpw_enroll(n = 20, enroll_rate = tibble(   duration = c(1, 2),   rate = c(2, 5) )) #>  [1] 0.1065397 0.1893380 0.3427685 0.7277076 0.7369305 0.8765853 1.0677710 #>  [8] 1.1430300 1.1795148 1.3745383 1.8152499 2.2622588 2.3366339 2.4263280 #> [15] 2.4379181 2.6040720 2.6353415 3.3616755 3.4359556 3.7758535"},{"path":"https://merck.github.io/simtrial/articles/simtrialroutines.html","id":"time-to-event-and-time-to-dropout","dir":"Articles","previous_headings":"","what":"Time-to-event and time-to-dropout","title":"Basic tools for time-to-event trial simulation and testing","text":"Time--event time--dropout random number generation observations generated piecewise exponential failure times. large number observations, log-plot time--failure","code":"x <- rpwexp(10000,   fail_rate = tibble(     rate = c(1, 3, 10),     duration = c(.5, .5, 1)   ) ) plot(sort(x), (10000:1) / 10001,   log = \"y\",   main = \"PW Exponential simulated survival curve\",   xlab = \"Time\", ylab = \"P{Survival}\" )"},{"path":"https://merck.github.io/simtrial/articles/simtrialroutines.html","id":"generating-a-trial","dir":"Articles","previous_headings":"","what":"Generating a trial","title":"Basic tools for time-to-event trial simulation and testing","text":"Ideally, might done routine generation randomization, time--event data done modular fashion plugged general trial generation routine. now, stratified randomization, piecewise constant enrollment, fixed block randomization piecewise exponential failure rates support flexible set trial generation options time--event endpoint trials. present, follow format carefully little checking input developed -date. methods used demonstrated , combined single routine generate trial. Note generated output dataset, cte calendar time event dropout, whichever comes first, fail indicator cte represents event time. First set input variables make later call sim_pw_surv() straightforward read.","code":"stratum <- tibble(stratum = c(\"Negative\", \"Positive\"), p = c(.5, .5))  block <- c(rep(\"control\", 2), rep(\"experimental\", 2))  enroll_rate <- tibble(rate = c(3, 6, 9), duration = c(3, 2, 1))  fail_rate <- tibble(   stratum = c(rep(\"Negative\", 4), rep(\"Positive\", 4)),   period = rep(1:2, 4),   treatment = rep(c(rep(\"control\", 2), rep(\"experimental\", 2)), 2),   duration = rep(c(3, 1), 4),   rate = log(2) / c(4, 9, 4.5, 10, 4, 9, 8, 18) ) dropout_rate <- tibble(   stratum = c(rep(\"Negative\", 4), rep(\"Positive\", 4)),   period = rep(1:2, 4),   treatment = rep(c(rep(\"control\", 2), rep(\"experimental\", 2)), 2),   duration = rep(c(3, 1), 4),   rate = rep(c(.001, .001), 4) ) x <- sim_pw_surv(   n = 400,   stratum = stratum,   block = block,   enroll_rate = enroll_rate,   fail_rate = fail_rate,   dropout_rate = dropout_rate ) head(x) %>% kable(digits = 2)"},{"path":"https://merck.github.io/simtrial/articles/simtrialroutines.html","id":"cutting-data-for-analysis","dir":"Articles","previous_headings":"","what":"Cutting data for analysis","title":"Basic tools for time-to-event trial simulation and testing","text":"two ways cut data generated dataset x . first uses calendar cutoff date. output includes time randomization event dropout (tte), indicator represents event (event), stratum observation generated (stratum) treatment group assigned (treatment). Observations enrolled input cut_date deleted events censoring x cut_date censored specified cut_date. instance, wish cut entire dataset 50 events observed Positive stratum can use get_cut_date_by_event function follows: Perhaps common way cut data event count overall population, done using cut_data_by_event function. Note tied events date cte count reached, included. Also, count never reached, event times included cut - indication error.","code":"y <- cut_data_by_date(x, cut_date = 5)  head(y) %>% kable(digits = 2) cut50Positive <- get_cut_date_by_event(filter(x, stratum == \"Positive\"), 50) y50Positive <- cut_data_by_date(x, cut50Positive)  with(y50Positive, table(stratum, event)) #>           event #> stratum     0  1 #>   Negative 34 74 #>   Positive 49 50 y150 <- cut_data_by_event(x, 150) table(y150$event, y150$treatment) #>     #>     control experimental #>   0      41           55 #>   1      82           68"},{"path":"https://merck.github.io/simtrial/articles/simtrialroutines.html","id":"generating-a-counting-process-dataset","dir":"Articles","previous_headings":"","what":"Generating a counting process dataset","title":"Basic tools for time-to-event trial simulation and testing","text":"cut data analysis, can create dataset simple use weighted logrank tests. slightly complex version developed future enable Kaplan-Meier-based tests. take dataset y150 process format. counting process format discussed next section compute weighted logrank test.","code":"ten150 <- counting_process(y150, arm = \"experimental\")  head(ten150) %>% kable(digits = 2)"},{"path":"https://merck.github.io/simtrial/articles/simtrialroutines.html","id":"logrank-and-weighted-logrank-testing","dir":"Articles","previous_headings":"","what":"Logrank and weighted logrank testing","title":"Basic tools for time-to-event trial simulation and testing","text":"Now stratified logrank stratified weighted logrank tests easily generated based counting process format. record counting process dataset represents tte one events occurs; results stratum-specific. Included observation number events overall (events) experimental treatment group (txevents), number risk overall (atrisk) experimental treatment group (txatrisk) just tte, combined treatment group Kaplan-Meier survival estimate (left-continuous) tte, observed events experimental group minus expected tte based assumption risk observations equally likely event time, variance quantity (Var). generate stratified logrank test corresponding one-sided p-value, simply following: Fleming-Harrington \\(\\rho=1\\), \\(\\gamma=2\\) nearly simple. compute z-statistic corresponding one-sided p-value. Fleming-Harrington tests, routine built tests : wanted take minimum MaxCombo test, first use tenFHcorr compute correlation matrix z-statistics follows. Note ordering rho_gamma g argument list opposite . correlation matrix z-values now V1-V4. can compute p-value MaxCombo follows using pmvnorm function mvtnorm package. Note arguments GenzBretz stringent defaults; also used stringent parameters example help file.","code":"z <- with(ten150, sum(o_minus_e) / sqrt(sum(var_o_minus_e))) c(z, pnorm(z)) #> [1] -1.8049046  0.0355448 xx <- mutate(ten150, w = s * (1 - s)^2) z <- with(xx, sum(o_minus_e * w) / sum(sqrt(var_o_minus_e * w^2))) c(z, pnorm(z)) #> [1] -0.1939244  0.4231175 wlr(x = ten150, rho_gamma = tibble(rho = c(0, 0, 1, 1), gamma = c(0, 1, 0, 1))) %>% kable(digits = 2) x <- ten150 %>% tenFHcorr(rho_gamma = tibble(rho = c(0, 0, 1, 1), gamma = c(0, 1, 0, 1))) x %>% kable(digits = 2) # Compute p-value for MaxCombo pvalue_maxcombo(x) #> [1] 0.05305286"},{"path":"https://merck.github.io/simtrial/articles/simtrialroutines.html","id":"simplification-for-2-arm-trials","dir":"Articles","previous_headings":"","what":"Simplification for 2-arm trials","title":"Basic tools for time-to-event trial simulation and testing","text":"sim_fixed_n() routine combines much go straight generating tests individual trials cutting data analyzing need done separately. argument structure meant simpler sim_pw_surv(). Now simulate trial 2 times cut data analysis based timing_type = 1:5 translates : planned study duration, targeted event count achieved, planned minimum follow-enrollment complete, maximum 1 2, maximum 2 3. look carefully, asking cutoff planned number events different data cutoff methods. explain, note generally want sample_size match enrollment specified enroll_rate: targeted enrollment takes, average, 30 months longer sum enrollment durations enroll_rate (14 months) input enrollment rates. achieve input sample_size 500, final enrollment rate assumed steady state extends simulation targeted enrollment achieved. planned duration trial taken 30 months specified totalDuration. targeted minimum follow-thus, implicit last subject enrolled 16 months prior duration given cutoff “Minimum follow-” cutoff simulations . planned duration cutoff given totalDuration argument results much earlier cutoff.","code":"stratum <- tibble(stratum = \"All\", p = 1) enroll_rate <- tibble(   duration = c(2, 2, 10),   rate = c(3, 6, 9) ) fail_rate <- tibble(   stratum = \"All\",   duration = c(3, 100),   fail_rate = log(2) / c(9, 18),   hr = c(0.9, 0.6),   dropout_rate = rep(0.001, 2) ) block <- rep(c(\"experimental\", \"control\"), 2) rho_gamma <- tibble(rho = 0, gamma = 0) sim_fixed_n(   n_sim = 2, # Number of simulations   sample_size = 500, # Trial sample size   target_event = 350, # Targeted events at analysis   stratum = stratum, # Study stratum   enroll_rate = enroll_rate, # Enrollment rates   fail_rate = fail_rate, # Failure rates   total_duration = 30, # Planned trial duration   block = block, # Block for treatment   timing_type = 1:5, # Use all possible data cutoff methods   rho_gamma = rho_gamma # FH test(s) to use; in this case, logrank ) %>% kable(digits = 2) enroll_rate %>% summarize(\"Targeted enrollment based on input enrollment rates\" = sum(duration * rate)) #> # A tibble: 1 × 1 #>   `Targeted enrollment based on input enrollment rates` #>                                                   <dbl> #> 1                                                   108 totalDuration <- 30 # From above totalDuration - sum(enroll_rate$duration) #> [1] 16"},{"path":"https://merck.github.io/simtrial/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Keaven Anderson. Author. Yilong Zhang. Author. Yujie Zhao. Contributor, maintainer. Nan Xiao. Contributor. Jianxiao Yang. Contributor. Lili Ling. Contributor. Xintong Li. Contributor. Ruixue Wang. Contributor. Yi Cui. Contributor. Ping Yang. Contributor. Yalin Zhu. Contributor. Heng Zhou. Contributor. Amin Shirazi. Contributor. Merck & Co., Inc., Rahway, NJ, USA affiliates. Copyright holder.","code":""},{"path":"https://merck.github.io/simtrial/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Anderson K, Zhang Y (2023). simtrial: Clinical Trial Simulation. https://merck.github.io/simtrial/, https://github.com/Merck/simtrial.","code":"@Manual{,   title = {simtrial: Clinical Trial Simulation},   author = {Keaven Anderson and Yilong Zhang},   year = {2023},   note = {https://merck.github.io/simtrial/, https://github.com/Merck/simtrial}, }"},{"path":[]},{"path":"https://merck.github.io/simtrial/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Clinical Trial Simulation","text":"can install GitHub:","code":"remotes::install_github(\"Merck/simtrial\")"},{"path":"https://merck.github.io/simtrial/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Clinical Trial Simulation","text":"simtrial small package built initially focus evaluating weighted logrank tests combination tests based tests. intent use tidyverse (data wrangling) programming procedures package easy qualify use regulated environment. Initial areas focus : Generating time--event data stratified trials using piecewise constant enrollment piecewise exponential failure rates. proportional non-proportional hazards supported. proportional hazards, assumptions along lines used Lachin Foulkes implemented gsDesign deriving group sequential designs. Setting data cutoffs (interim final) analyses. Support weighted logrank tests arbitrary weighting schemes, specifically supporting Fleming-Harrington set tests, including logrank test.","code":""},{"path":"https://merck.github.io/simtrial/index.html","id":"future-developments","dir":"","previous_headings":"","what":"Future developments","title":"Clinical Trial Simulation","text":"Expectations future development include: Provide test suite document package fit use regulatory environment. examples.","code":""},{"path":"https://merck.github.io/simtrial/reference/Ex1delayedEffect.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-to-event data example 1 for non-proportional hazards working group — Ex1delayedEffect","title":"Time-to-event data example 1 for non-proportional hazards working group — Ex1delayedEffect","text":"Survival objects reverse-engineered datasets published Kaplan-Meier curves. Individual trials de-identified since data approximations actual data. Data intended evaluate methods designs trials non-proportional hazards may anticipated outcome data.","code":""},{"path":"https://merck.github.io/simtrial/reference/Ex1delayedEffect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-to-event data example 1 for non-proportional hazards working group — Ex1delayedEffect","text":"","code":"data(Ex1delayedEffect)"},{"path":"https://merck.github.io/simtrial/reference/Ex1delayedEffect.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Time-to-event data example 1 for non-proportional hazards working group — Ex1delayedEffect","text":"Data frame 4 variables: id: Sequential numbering unique identifiers. month: Time--event. event: 1 event, 0 censored. trt: 1 experimental, 0 control.","code":""},{"path":"https://merck.github.io/simtrial/reference/Ex1delayedEffect.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Time-to-event data example 1 for non-proportional hazards working group — Ex1delayedEffect","text":"TBD","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/reference/Ex1delayedEffect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-to-event data example 1 for non-proportional hazards working group — Ex1delayedEffect","text":"","code":"library(survival)  data(Ex1delayedEffect) km1 <- with(Ex1delayedEffect, survfit(Surv(month, evntd) ~ trt)) km1 #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>         n events median 0.95LCL 0.95UCL #> trt=0 121     86   5.04    4.18    6.21 #> trt=1 240    132   7.66    6.54    9.48 plot(km1)  with(subset(Ex1delayedEffect, trt == 1), survfit(Surv(month, evntd) ~ trt)) #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>        n events median 0.95LCL 0.95UCL #> [1,] 240    132   7.66    6.54    9.48 with(subset(Ex1delayedEffect, trt == 0), survfit(Surv(month, evntd) ~ trt)) #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>        n events median 0.95LCL 0.95UCL #> [1,] 121     86   5.04    4.18    6.21"},{"path":"https://merck.github.io/simtrial/reference/Ex2delayedEffect.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-to-event data example 2 for non-proportional hazards working group — Ex2delayedEffect","title":"Time-to-event data example 2 for non-proportional hazards working group — Ex2delayedEffect","text":"Survival objects reverse-engineered datasets published Kaplan-Meier curves. Individual trials de-identified since data approximations actual data. Data intended evaluate methods designs trials non-proportional hazards may anticipated outcome data.","code":""},{"path":"https://merck.github.io/simtrial/reference/Ex2delayedEffect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-to-event data example 2 for non-proportional hazards working group — Ex2delayedEffect","text":"","code":"data(Ex2delayedEffect)"},{"path":"https://merck.github.io/simtrial/reference/Ex2delayedEffect.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Time-to-event data example 2 for non-proportional hazards working group — Ex2delayedEffect","text":"Data frame 4 variables: id: Sequential numbering unique identifiers. month: Time--event. event: 1 event, 0 censored. trt: 1 experimental, 0 control.","code":""},{"path":"https://merck.github.io/simtrial/reference/Ex2delayedEffect.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Time-to-event data example 2 for non-proportional hazards working group — Ex2delayedEffect","text":"TBD","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/reference/Ex2delayedEffect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-to-event data example 2 for non-proportional hazards working group — Ex2delayedEffect","text":"","code":"library(survival)  data(Ex2delayedEffect) km1 <- with(Ex2delayedEffect, survfit(Surv(month, evntd) ~ trt)) km1 #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>         n events median 0.95LCL 0.95UCL #> trt=0 137    123   2.84    2.18    3.50 #> trt=1 135    105   3.45    2.13    5.07 plot(km1)  with(subset(Ex2delayedEffect, trt == 1), survfit(Surv(month, evntd) ~ trt)) #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>        n events median 0.95LCL 0.95UCL #> [1,] 135    105   3.45    2.13    5.07 with(subset(Ex2delayedEffect, trt == 0), survfit(Surv(month, evntd) ~ trt)) #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>        n events median 0.95LCL 0.95UCL #> [1,] 137    123   2.84    2.18     3.5"},{"path":"https://merck.github.io/simtrial/reference/Ex3curewithph.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-to-event data example 3 for non-proportional hazards working group — Ex3curewithph","title":"Time-to-event data example 3 for non-proportional hazards working group — Ex3curewithph","text":"Survival objects reverse-engineered datasets published Kaplan-Meier curves. Individual trials de-identified since data approximations actual data. Data intended evaluate methods designs trials non-proportional hazards may anticipated outcome data.","code":""},{"path":"https://merck.github.io/simtrial/reference/Ex3curewithph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-to-event data example 3 for non-proportional hazards working group — Ex3curewithph","text":"","code":"data(Ex3curewithph)"},{"path":"https://merck.github.io/simtrial/reference/Ex3curewithph.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Time-to-event data example 3 for non-proportional hazards working group — Ex3curewithph","text":"Data frame 4 variables: id: Sequential numbering unique identifiers. month: Time--event. event: 1 event, 0 censored. trt: 1 experimental, 0 control.","code":""},{"path":"https://merck.github.io/simtrial/reference/Ex3curewithph.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Time-to-event data example 3 for non-proportional hazards working group — Ex3curewithph","text":"TBD","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/reference/Ex3curewithph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-to-event data example 3 for non-proportional hazards working group — Ex3curewithph","text":"","code":"library(survival)  data(Ex3curewithph) km1 <- with(Ex3curewithph, survfit(Surv(month, evntd) ~ trt)) km1 #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>         n events median 0.95LCL 0.95UCL #> trt=0 137    101   1.05   0.523    1.74 #> trt=1 143     86   1.74   1.158    3.13 plot(km1)"},{"path":"https://merck.github.io/simtrial/reference/Ex4belly.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-to-event data example 4 for non-proportional hazards working group — Ex4belly","title":"Time-to-event data example 4 for non-proportional hazards working group — Ex4belly","text":"Survival objects reverse-engineered datasets published Kaplan-Meier curves. Individual trials de-identified since data approximations actual data. Data intended evaluate methods designs trials non-proportional hazards may anticipated outcome data.","code":""},{"path":"https://merck.github.io/simtrial/reference/Ex4belly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-to-event data example 4 for non-proportional hazards working group — Ex4belly","text":"","code":"data(Ex4belly)"},{"path":"https://merck.github.io/simtrial/reference/Ex4belly.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Time-to-event data example 4 for non-proportional hazards working group — Ex4belly","text":"Data frame 4 variables: id: Sequential numbering unique identifiers. month: Time--event. event: 1 event, 0 censored. trt: 1 experimental, 0 control.","code":""},{"path":"https://merck.github.io/simtrial/reference/Ex4belly.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Time-to-event data example 4 for non-proportional hazards working group — Ex4belly","text":"TBD","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/reference/Ex4belly.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-to-event data example 4 for non-proportional hazards working group — Ex4belly","text":"","code":"library(survival)  data(Ex4belly) km1 <- with(Ex4belly, survfit(Surv(month, evntd) ~ trt)) km1 #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>         n events median 0.95LCL 0.95UCL #> trt=0 387    339   5.40    4.61    5.55 #> trt=1 387    327   6.42    5.81    6.91 plot(km1)"},{"path":"https://merck.github.io/simtrial/reference/Ex5widening.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-to-event data example 5 for non-proportional hazards working group — Ex5widening","title":"Time-to-event data example 5 for non-proportional hazards working group — Ex5widening","text":"Survival objects reverse-engineered datasets published Kaplan-Meier curves. Individual trials de-identified since data approximations actual data. Data intended evaluate methods designs trials non-proportional hazards may anticipated outcome data.","code":""},{"path":"https://merck.github.io/simtrial/reference/Ex5widening.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-to-event data example 5 for non-proportional hazards working group — Ex5widening","text":"","code":"data(Ex5widening)"},{"path":"https://merck.github.io/simtrial/reference/Ex5widening.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Time-to-event data example 5 for non-proportional hazards working group — Ex5widening","text":"Data frame 4 variables: id: Sequential numbering unique identifiers. month: Time--event. event: 1 event, 0 censored. trt: 1 experimental, 0 control.","code":""},{"path":"https://merck.github.io/simtrial/reference/Ex5widening.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Time-to-event data example 5 for non-proportional hazards working group — Ex5widening","text":"TBD","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/reference/Ex5widening.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-to-event data example 5 for non-proportional hazards working group — Ex5widening","text":"","code":"library(survival)  data(Ex5widening) km1 <- with(Ex5widening, survfit(Surv(month, evntd) ~ trt)) km1 #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>        n events median 0.95LCL 0.95UCL #> trt=0 79     65   8.16    6.65    10.3 #> trt=1 86     48  19.97   17.07    26.6 plot(km1)"},{"path":"https://merck.github.io/simtrial/reference/Ex6crossing.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-to-event data example 6 for non-proportional hazards working group — Ex6crossing","title":"Time-to-event data example 6 for non-proportional hazards working group — Ex6crossing","text":"Survival objects reverse-engineered datasets published Kaplan-Meier curves. Individual trials de-identified since data approximations actual data. Data intended evaluate methods designs trials non-proportional hazards may anticipated outcome data.","code":""},{"path":"https://merck.github.io/simtrial/reference/Ex6crossing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-to-event data example 6 for non-proportional hazards working group — Ex6crossing","text":"","code":"data(Ex6crossing)"},{"path":"https://merck.github.io/simtrial/reference/Ex6crossing.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Time-to-event data example 6 for non-proportional hazards working group — Ex6crossing","text":"Data frame 4 variables: id: Sequential numbering unique identifiers. month: Time--event. event: 1 event, 0 censored. trt: 1 experimental, 0 control.","code":""},{"path":"https://merck.github.io/simtrial/reference/Ex6crossing.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Time-to-event data example 6 for non-proportional hazards working group — Ex6crossing","text":"TBD","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/reference/Ex6crossing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-to-event data example 6 for non-proportional hazards working group — Ex6crossing","text":"","code":"library(survival)  data(Ex6crossing) km1 <- with(Ex6crossing, survfit(Surv(month, evntd) ~ trt)) km1 #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>         n events median 0.95LCL 0.95UCL #> trt=0 145    111  10.66    8.83    12.5 #> trt=1 145    113   9.92    7.38    14.3 plot(km1)"},{"path":"https://merck.github.io/simtrial/reference/MBdelayed.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated survival dataset with delayed treatment effect — MBdelayed","title":"Simulated survival dataset with delayed treatment effect — MBdelayed","text":"Magirr Burman (2019) considered several scenarios modestly weighted logrank test. One delayed treatment effect hazard ratio 1 6 months followed hazard ratio 1/2 thereafter. scenario enrolled 200 patients uniformly 12 months cut data analysis 36 months enrollment opened. dataset generated sim_pw_surv() function scenario.","code":""},{"path":"https://merck.github.io/simtrial/reference/MBdelayed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated survival dataset with delayed treatment effect — MBdelayed","text":"","code":"MBdelayed"},{"path":"https://merck.github.io/simtrial/reference/MBdelayed.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated survival dataset with delayed treatment effect — MBdelayed","text":"tibble 200 rows xx columns: tte: Time event.","code":""},{"path":"https://merck.github.io/simtrial/reference/MBdelayed.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulated survival dataset with delayed treatment effect — MBdelayed","text":"Magirr, Dominic, Carl‐Fredrik Burman. 2019. \"Modestly weighted logrank tests.\" Statistics Medicine 38 (20): 3782--3790.","code":""},{"path":"https://merck.github.io/simtrial/reference/MBdelayed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated survival dataset with delayed treatment effect — MBdelayed","text":"","code":"library(survival) library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union  fit <- survfit(Surv(tte, event) ~ treatment, data = MBdelayed)  # Plot survival plot(fit, lty = 1:2) legend(\"topright\", legend = c(\"control\", \"experimental\"), lty = 1:2)   # Set up time, event, number of event dataset for testing # with arbitrary weights ten <- MBdelayed %>% counting_process(arm = \"experimental\") head(ten) #> # A tibble: 6 × 9 #> # Groups:   stratum [1] #>   stratum events n_event_tol    tte n_risk_tol n_risk_trt     s o_minus_e #>   <chr>    <dbl>       <dbl>  <dbl>      <dbl>      <int> <dbl>     <dbl> #> 1 All          1           1 0.0917        200        100 1         0.5   #> 2 All          1           1 0.181         199         99 0.995     0.503 #> 3 All          1           1 0.322         198         98 0.99      0.505 #> 4 All          1           0 0.330         197         97 0.985    -0.492 #> 5 All          1           0 0.597         196         97 0.98     -0.495 #> 6 All          1           0 0.755         195         97 0.975    -0.497 #> # ℹ 1 more variable: var_o_minus_e <dbl>  # MaxCombo with logrank, FH(0,1), FH(1,1) ten %>%   tenFHcorr(rho_gamma = tibble(rho = c(0, 0, 1), gamma = c(0, 1, 1))) %>%   pvalue_maxcombo() #> [1] 0.001041221  # Magirr-Burman modestly down-weighted rank test with 6 month delay # First, add weights ten <- ten %>% mb_weight(6) head(ten) #> # A tibble: 6 × 10 #>   stratum events n_event_tol    tte n_risk_tol n_risk_trt     s o_minus_e #>   <chr>    <dbl>       <dbl>  <dbl>      <dbl>      <int> <dbl>     <dbl> #> 1 All          1           1 0.0917        200        100 1         0.5   #> 2 All          1           1 0.181         199         99 0.995     0.503 #> 3 All          1           1 0.322         198         98 0.99      0.505 #> 4 All          1           0 0.330         197         97 0.985    -0.492 #> 5 All          1           0 0.597         196         97 0.98     -0.495 #> 6 All          1           0 0.755         195         97 0.975    -0.497 #> # ℹ 2 more variables: var_o_minus_e <dbl>, mb_weight <dbl>  # Now compute test based on these weights ten %>%   summarize(     S = sum(o_minus_e * mb_weight),     V = sum(var_o_minus_e * mb_weight^2),     Z = S / sqrt(V)   ) %>%   mutate(p = pnorm(Z)) #> # A tibble: 1 × 4 #>       S     V     Z       p #>   <dbl> <dbl> <dbl>   <dbl> #> 1 -20.4  55.3 -2.74 0.00304  # Create 0 weights for first 6 months ten <- ten %>% mutate(w6 = 1 * (tte >= 6)) ten %>%   summarize(     S = sum(o_minus_e * w6),     V = sum(var_o_minus_e * w6^2),     Z = S / sqrt(V)   ) %>%   mutate(p = pnorm(Z)) #> # A tibble: 1 × 4 #>       S     V     Z        p #>   <dbl> <dbl> <dbl>    <dbl> #> 1 -16.8  21.5 -3.62 0.000147  # Generate another dataset ds <- sim_pw_surv(   n = 200,   enroll_rate = tibble(rate = 200 / 12, duration = 12),   fail_rate = tribble(     ~stratum, ~Period, ~treatment, ~duration, ~rate,     \"All\", 1, \"control\", 42, log(2) / 15,     \"All\", 1, \"experimental\", 6, log(2) / 15,     \"All\", 2, \"experimental\", 36, log(2) / 15 * 0.6   ),   dropout_rate = tribble(     ~stratum, ~Period, ~treatment, ~duration, ~rate,     \"All\", 1, \"control\", 42, 0,     \"All\", 1, \"experimental\", 42, 0   ) ) # Cut data at 24 months after final enrollment MBdelayed2 <- ds %>% cut_data_by_date(max(ds$enroll_time) + 24)"},{"path":"https://merck.github.io/simtrial/reference/counting_process.html","id":null,"dir":"Reference","previous_headings":"","what":"Process survival data into counting process format — counting_process","title":"Process survival data into counting process format — counting_process","text":"Produces tibble sorted stratum time. Included times one event occurs. output dataset contains stratum, tte (time--event), risk count count events specified tte sorted stratum tte.","code":""},{"path":"https://merck.github.io/simtrial/reference/counting_process.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process survival data into counting process format — counting_process","text":"","code":"counting_process(x, arm)"},{"path":"https://merck.github.io/simtrial/reference/counting_process.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process survival data into counting process format — counting_process","text":"x tibble missing values contain variables: stratum: Stratum. treatment: Treatment group. tte: Observed time. event: Binary event indicator, 1 represents event, 0 represents censoring. arm Value input treatment column indicates treatment group value.","code":""},{"path":"https://merck.github.io/simtrial/reference/counting_process.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process survival data into counting process format — counting_process","text":"tibble grouped stratum sorted within stratum tte. Remain rows least one event population, least one subject risk treatment group control group. variables represent following within stratum time one events observed: events: Total number events n_event_tol: Total number events treatment group n_risk_tol: Number subjects risk n_risk_trt: Number subjects risk treatment group S: Left-continuous Kaplan-Meier survival estimate o_minus_e: treatment group, observed number events minus expected number events. expected number events estimated assuming treatment effect hypergeometric distribution parameters total number events, total number events treatment group number events time. (assumption log-rank test null hypothesis) var_o_minus_e: Variance o_minus_e assumption.","code":""},{"path":"https://merck.github.io/simtrial/reference/counting_process.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Process survival data into counting process format — counting_process","text":"function considered two group situation. tie handled Breslow's Method.","code":""},{"path":"https://merck.github.io/simtrial/reference/counting_process.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process survival data into counting process format — counting_process","text":"","code":"library(tibble)  # Example 1 x <- tibble(   stratum = c(rep(1, 10), rep(2, 6)),   treatment = rep(c(1, 1, 0, 0), 4),   tte = 1:16,   event = rep(c(0, 1), 8) ) counting_process(x, arm = 1) #> # A tibble: 6 × 9 #> # Groups:   stratum [2] #>   stratum events n_event_tol   tte n_risk_tol n_risk_trt     s o_minus_e #>     <dbl>  <dbl>       <dbl> <int>      <dbl>      <int> <dbl>     <dbl> #> 1       1      1           1     2          9          5 1         0.444 #> 2       1      1           0     4          7          4 0.889    -0.571 #> 3       1      1           1     6          5          3 0.762     0.4   #> 4       1      1           0     8          3          2 0.610    -0.667 #> 5       2      1           0    12          5          2 1        -0.4   #> 6       2      1           1    14          3          1 0.8       0.667 #> # ℹ 1 more variable: var_o_minus_e <dbl>  # Example 2 x <- sim_pw_surv(n = 400) y <- cut_data_by_event(x, 150) %>% counting_process(arm = \"experimental\") # Weighted logrank test (Z-value and 1-sided p-value) z <- sum(y$o_minus_e) / sqrt(sum(y$var_o_minus_e)) c(z, pnorm(z)) #> [1] -3.3036525352  0.0004771702"},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Cut a dataset for analysis at a specified date — cut_data_by_date","title":"Cut a dataset for analysis at a specified date — cut_data_by_date","text":"Cut dataset analysis specified date","code":""},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cut a dataset for analysis at a specified date — cut_data_by_date","text":"","code":"cut_data_by_date(x, cut_date)"},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cut a dataset for analysis at a specified date — cut_data_by_date","text":"x time--event dataset, example, generated sim_pw_surv(). cut_date Date relative start randomization (cte input dataset) dataset cut analysis.","code":""},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cut a dataset for analysis at a specified date — cut_data_by_date","text":"dataset ready survival analysis.","code":""},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cut a dataset for analysis at a specified date — cut_data_by_date","text":"","code":"# Use default enrollment and event rates and # cut at calendar time 5 after start of randomization sim_pw_surv(n = 20) %>% cut_data_by_date(5) #> # A tibble: 20 × 4 #> # Groups:   stratum, treatment [2] #>       tte event stratum treatment    #>     <dbl> <dbl> <chr>   <chr>        #>  1 0.0902     1 All     experimental #>  2 4.86       0 All     experimental #>  3 4.48       0 All     control      #>  4 0.106      1 All     control      #>  5 3.77       0 All     control      #>  6 0.205      1 All     experimental #>  7 3.51       0 All     control      #>  8 0.114      1 All     experimental #>  9 3.09       0 All     control      #> 10 2.59       0 All     experimental #> 11 2.59       0 All     control      #> 12 2.57       0 All     experimental #> 13 1.71       1 All     experimental #> 14 2.47       0 All     experimental #> 15 2.47       0 All     control      #> 16 2.45       0 All     control      #> 17 2.38       0 All     experimental #> 18 2.16       0 All     experimental #> 19 2.12       0 All     control      #> 20 2.05       0 All     control"},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_event.html","id":null,"dir":"Reference","previous_headings":"","what":"Cut a dataset for analysis at a specified event count — cut_data_by_event","title":"Cut a dataset for analysis at a specified event count — cut_data_by_event","text":"Takes time--event data set cuts data event count reached.","code":""},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_event.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cut a dataset for analysis at a specified event count — cut_data_by_event","text":"","code":"cut_data_by_event(x, event)"},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_event.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cut a dataset for analysis at a specified event count — cut_data_by_event","text":"x time--event dataset, example, generated sim_pw_surv(). event Event count data cutoff made.","code":""},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_event.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cut a dataset for analysis at a specified event count — cut_data_by_event","text":"tibble ready survival analysis, including columns time event (tte), event, stratum, treatment.","code":""},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_event.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cut a dataset for analysis at a specified event count — cut_data_by_event","text":"","code":"# Use default enrollment and event rates at cut at 100 events x <- sim_pw_surv(n = 200) %>% cut_data_by_event(100) table(x$event, x$treatment) #>     #>     control experimental #>   0      47           53 #>   1      53           47"},{"path":"https://merck.github.io/simtrial/reference/fit_pwexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Piecewise exponential survival estimation — fit_pwexp","title":"Piecewise exponential survival estimation — fit_pwexp","text":"Computes survival function, density function, -2 * log-likelihood based input dataset intervals piecewise constant failure rates. Initial version assumes observations right censored events .","code":""},{"path":"https://merck.github.io/simtrial/reference/fit_pwexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Piecewise exponential survival estimation — fit_pwexp","text":"","code":"fit_pwexp(   srv = Surv(time = Ex1delayedEffect$month, event = Ex1delayedEffect$evntd),   intervals = array(3, 3) )"},{"path":"https://merck.github.io/simtrial/reference/fit_pwexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Piecewise exponential survival estimation — fit_pwexp","text":"srv Input survival object (see survival::Surv()); note 0 = censored, 1 = event survival::Surv(). intervals Vector containing positive values indicating interval lengths exponential rates assumed. Note final infinite interval added events occur final interval specified.","code":""},{"path":"https://merck.github.io/simtrial/reference/fit_pwexp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Piecewise exponential survival estimation — fit_pwexp","text":"matrix rows containing interval length, estimated rate, -2 * log-likelihood interval.","code":""},{"path":"https://merck.github.io/simtrial/reference/fit_pwexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Piecewise exponential survival estimation — fit_pwexp","text":"","code":"# Use default arguments for delayed effect example dataset (Ex1delayedEffect) library(survival)  # Example 1 rateall <- fit_pwexp() rateall #>   intervals     ttot event       rate     m2ll #> 1         3 937.1785    97 0.10350216 634.0236 #> 2         3 605.3572    71 0.11728612 446.3257 #> 3         3 346.8482    30 0.08649317 206.8614 #> 4       Inf 254.1148    20 0.07870458 141.6822  # Example 2 # Estimate by treatment effect rate1 <- with(subset(Ex1delayedEffect, trt == 1), fit_pwexp(Surv(month, evntd))) rate0 <- with(subset(Ex1delayedEffect, trt == 0), fit_pwexp(Surv(month, evntd)))  rate1 #>   intervals     ttot event       rate      m2ll #> 1         3 620.4375    64 0.10315302 418.75734 #> 2         3 415.8482    36 0.08657005 248.16970 #> 3         3 256.2053    19 0.07415927 136.85853 #> 4       Inf 205.4186    13 0.06328542  97.76261 rate0 #>   intervals      ttot event      rate      m2ll #> 1         3 316.74106    33 0.1041861 215.26408 #> 2         3 189.50899    35 0.1846878 188.23619 #> 3         3  90.64288    11 0.1213554  68.39871 #> 4       Inf  48.69624     7 0.1437483  41.15568 rate1$rate / rate0$rate #> [1] 0.9900847 0.4687372 0.6110917 0.4402517  # Chi-square test for (any) treatment effect (8 - 4 parameters = 4 df) pchisq(sum(rateall$m2ll) - sum(rate1$m2ll + rate0$m2ll),   df = 4,   lower.tail = FALSE ) #> [1] 0.006424744  # Compare with logrank survdiff(formula = Surv(month, evntd) ~ trt, data = Ex1delayedEffect) #> Call: #> survdiff(formula = Surv(month, evntd) ~ trt, data = Ex1delayedEffect) #>  #>         N Observed Expected (O-E)^2/E (O-E)^2/V #> trt=0 121       86     67.7      4.97      7.35 #> trt=1 240      132    150.3      2.24      7.35 #>  #>  Chisq= 7.3  on 1 degrees of freedom, p= 0.007   # Example 3 # Simple model with 3 rates same for each for 3 months, # different for each treatment after months rate1a <- with(subset(Ex1delayedEffect, trt == 1), fit_pwexp(Surv(month, evntd), 3)) rate0a <- with(subset(Ex1delayedEffect, trt == 0), fit_pwexp(Surv(month, evntd), 3)) rate1a$rate / rate0a$rate #> [1] 0.9900847 0.4808339  m2ll0 <- rateall$m2ll[1] + rate1a$m2ll[2] + rate0a$m2ll[2] m2ll1 <- sum(rate0$m2ll) + sum(rate1$m2ll)  # As a measure of strength, chi-square examines improvement in likelihood pchisq(m2ll0 - m2ll1, df = 5, lower.tail = FALSE) #> [1] 0.741822"},{"path":"https://merck.github.io/simtrial/reference/get_cut_date_by_event.html","id":null,"dir":"Reference","previous_headings":"","what":"Get date at which an event count is reached — get_cut_date_by_event","title":"Get date at which an event count is reached — get_cut_date_by_event","text":"Get date event count reached","code":""},{"path":"https://merck.github.io/simtrial/reference/get_cut_date_by_event.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get date at which an event count is reached — get_cut_date_by_event","text":"","code":"get_cut_date_by_event(x, event)"},{"path":"https://merck.github.io/simtrial/reference/get_cut_date_by_event.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get date at which an event count is reached — get_cut_date_by_event","text":"x time--event dataset, example, generated sim_pw_surv(). event Event count dataset cut analysis.","code":""},{"path":"https://merck.github.io/simtrial/reference/get_cut_date_by_event.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get date at which an event count is reached — get_cut_date_by_event","text":"numeric value cte input dataset targeted event count reached, final event count never reached, final cte event occurs.","code":""},{"path":"https://merck.github.io/simtrial/reference/get_cut_date_by_event.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get date at which an event count is reached — get_cut_date_by_event","text":"","code":"library(tibble) library(dplyr)  # Use default enrollment and calendar cut date # for 50 events in the \"Positive\" stratum x <- sim_pw_surv(   n = 200,   stratum = tibble(     stratum = c(\"Positive\", \"Negative\"),     p = c(.5, .5)   ),   fail_rate = tibble(     stratum = rep(c(\"Positive\", \"Negative\"), 2),     period = rep(1, 4),     treatment = c(rep(\"control\", 2), rep(\"experimental\", 2)),     duration = rep(1, 4),     rate = log(2) / c(6, 9, 9, 12)   ),   dropout_rate = tibble(     stratum = rep(c(\"Positive\", \"Negative\"), 2),     period = rep(1, 4),     treatment = c(rep(\"control\", 2), rep(\"experimental\", 2)),     duration = rep(1, 4),     rate = rep(.001, 4)   ) )  d <- get_cut_date_by_event(x %>% filter(stratum == \"Positive\"), event = 50)  y <- cut_data_by_date(x, cut_date = d) table(y$stratum, y$event) #>            #>             0  1 #>   Negative 49 60 #>   Positive 41 50"},{"path":"https://merck.github.io/simtrial/reference/mb_weight.html","id":null,"dir":"Reference","previous_headings":"","what":"Magirr and Burman modestly weighted logrank tests — mb_weight","title":"Magirr and Burman modestly weighted logrank tests — mb_weight","text":"Magirr Burman (2019) proposed weighted logrank test better power logrank test treatment effect delayed, still maintain good power proportional hazards assumption. Magirr (2021), (equivalent ) maximum weight proposed opposed fixed time duration weights increase. weights early interval specified user inverse combined treatment group empirical survival distribution; see details. initial period, weights constant maximum previous weights. Another advantage test strong null hypothesis underlying survival control group greater equal underlying survival experimental group, Type error controlled specified level.","code":""},{"path":"https://merck.github.io/simtrial/reference/mb_weight.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Magirr and Burman modestly weighted logrank tests — mb_weight","text":"","code":"mb_weight(x, delay = 4, w_max = Inf)"},{"path":"https://merck.github.io/simtrial/reference/mb_weight.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Magirr and Burman modestly weighted logrank tests — mb_weight","text":"x counting_process()-class tibble counting process dataset. delay initial delay period weights increase; , weights constant final weight delay period. w_max Maximum weight returned. Set delay = Inf, w_max = 2 consistent recommendation Magirr (2021).","code":""},{"path":"https://merck.github.io/simtrial/reference/mb_weight.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Magirr and Burman modestly weighted logrank tests — mb_weight","text":"vector weights Magirr-Burman weighted logrank test data x.","code":""},{"path":"https://merck.github.io/simtrial/reference/mb_weight.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Magirr and Burman modestly weighted logrank tests — mb_weight","text":"Computes Magirr-Burman weights adds dataset created counting_process(). weights can used compute z-statistic modestly weighted logrank test proposed. define \\(t^*\\) input variable delay. specifies initial period weights increase. also set maximum weight \\(w_{\\max}\\). define specific weights, let \\(S(t)\\) denote Kaplan-Meier survival estimate time \\(t\\) combined data (control plus experimental treatment groups). weight time \\(t\\) defined $$w(t)=\\min(w_{\\max}, S(\\min(t, t^*))^{-1}).$$","code":""},{"path":"https://merck.github.io/simtrial/reference/mb_weight.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Magirr and Burman modestly weighted logrank tests — mb_weight","text":"Magirr, Dominic, Carl‐Fredrik Burman. 2019. \"Modestly weighted logrank tests.\" Statistics Medicine 38 (20): 3782--3790. Magirr, Dominic. 2021. \"Non‐proportional hazards immuno‐oncology: old perspective needed?\" Pharmaceutical Statistics 20 (3): 512--527.","code":""},{"path":"https://merck.github.io/simtrial/reference/mb_weight.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Magirr and Burman modestly weighted logrank tests — mb_weight","text":"","code":"library(dplyr)  # Use default enrollment and event rates at cut at 100 events # For transparency, may be good to set either `delay` or `w_max` to `Inf` x <- sim_pw_surv(n = 200) %>%   cut_data_by_event(125) %>%   counting_process(arm = \"experimental\")  # Example 1 # Compute Magirr-Burman weights with `delay = 6` ZMB <- x %>%   mb_weight(delay = 6, w_max = Inf) %>%   summarize(     S = sum(o_minus_e * mb_weight),     V = sum(var_o_minus_e * mb_weight^2),     z = S / sqrt(V)   )  # Compute p-value of modestly weighted logrank of Magirr-Burman pnorm(ZMB$z) #> [1] 0.0496102  # Example 2 # Now compute with maximum weight of 2 as recommended in Magirr, 2021 ZMB2 <- x %>%   mb_weight(delay = Inf, w_max = 2) %>%   summarize(     S = sum(o_minus_e * mb_weight),     V = sum(var_o_minus_e * mb_weight^2),     z = S / sqrt(V)   )  # Compute p-value of modestly weighted logrank of Magirr-Burman pnorm(ZMB2$z) #> [1] 0.06131883"},{"path":"https://merck.github.io/simtrial/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://merck.github.io/simtrial/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://merck.github.io/simtrial/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://merck.github.io/simtrial/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://merck.github.io/simtrial/reference/pvalue_maxcombo.html","id":null,"dir":"Reference","previous_headings":"","what":"MaxCombo p-value — pvalue_maxcombo","title":"MaxCombo p-value — pvalue_maxcombo","text":"Computes p-values MaxCombo test based output tenFHcorr(). still experimental stage intended use sim_fixed_n() trial simulation routine. However, can also used analyze clinical trial data provided ADaM ADTTE format.","code":""},{"path":"https://merck.github.io/simtrial/reference/pvalue_maxcombo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MaxCombo p-value — pvalue_maxcombo","text":"","code":"pvalue_maxcombo(   z,   dummy_var,   algorithm = mvtnorm::GenzBretz(maxpts = 50000, abseps = 1e-05) )"},{"path":"https://merck.github.io/simtrial/reference/pvalue_maxcombo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MaxCombo p-value — pvalue_maxcombo","text":"z dataset output tenFHcorr(); see examples. dummy_var dummy input allows dplyr::group_map() used compute p-values multiple simulations. algorithm passed directly algorithm argument mvtnorm::pmvnorm().","code":""},{"path":"https://merck.github.io/simtrial/reference/pvalue_maxcombo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MaxCombo p-value — pvalue_maxcombo","text":"numeric p-value.","code":""},{"path":"https://merck.github.io/simtrial/reference/pvalue_maxcombo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MaxCombo p-value — pvalue_maxcombo","text":"","code":"library(tibble) library(dplyr)  # Example 1 x <- sim_fixed_n(   n_sim = 1,   timing_type = 5,   rho_gamma = tibble(     rho = c(0, 0, 1),     gamma = c(0, 1, 1)   ) ) head(x) #>   event      ln_hr rho gamma         z        v1        v2        v3 #> 1   359 -0.5618927   0     0 -5.309830 1.0000000 0.8519335 0.9329564 #> 2   359 -0.5618927   0     1 -4.473371 0.8519335 1.0000000 0.9282834 #> 3   359 -0.5618927   1     1 -5.387395 0.9329564 0.9282834 1.0000000 #>                             cut duration sim #> 1 Max(min follow-up, event cut) 73.21699   1 #> 2 Max(min follow-up, event cut) 73.21699   1 #> 3 Max(min follow-up, event cut) 73.21699   1 pvalue_maxcombo(x) #> [1] 3.574388e-08  # Example 2 # Only use cuts for events, events + min follow-up xx <- sim_fixed_n(   n_sim = 100,   timing_type = 5,   rho_gamma = tibble(     rho = c(0, 0, 1),     gamma = c(0, 1, 1)   ) ) head(xx) #>   event      ln_hr rho gamma         z        v1        v2        v3 #> 1   357 -0.3952875   0     0 -3.722052 1.0000000 0.8527159 0.9334467 #> 2   357 -0.3952875   0     1 -3.695831 0.8527159 1.0000000 0.9293829 #> 3   357 -0.3952875   1     1 -4.086476 0.9334467 0.9293829 1.0000000 #> 4   369 -0.3212441   0     0 -3.082011 1.0000000 0.8567473 0.9357858 #> 5   369 -0.3212441   0     1 -2.643328 0.8567473 1.0000000 0.9291645 #> 6   369 -0.3212441   1     1 -3.018657 0.9357858 0.9291645 1.0000000 #>                             cut duration sim #> 1 Max(min follow-up, event cut) 75.18111   1 #> 2 Max(min follow-up, event cut) 75.18111   1 #> 3 Max(min follow-up, event cut) 75.18111   1 #> 4 Max(min follow-up, event cut) 74.26927   2 #> 5 Max(min follow-up, event cut) 74.26927   2 #> 6 Max(min follow-up, event cut) 74.26927   2  # MaxCombo power estimate for cutoff at max of targeted events, minimum follow-up p <- xx %>%   group_by(sim) %>%   group_map(pvalue_maxcombo) %>%   unlist() mean(p < .025) #> [1] 0.98"},{"path":"https://merck.github.io/simtrial/reference/randomize_by_fixed_block.html","id":null,"dir":"Reference","previous_headings":"","what":"Permuted fixed block randomization — randomize_by_fixed_block","title":"Permuted fixed block randomization — randomize_by_fixed_block","text":"Fixed block randomization. block input repeat treatment code number times included within block. final block partial block n exact multiple block length.","code":""},{"path":"https://merck.github.io/simtrial/reference/randomize_by_fixed_block.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Permuted fixed block randomization — randomize_by_fixed_block","text":"","code":"randomize_by_fixed_block(n = 10, block = c(0, 0, 1, 1))"},{"path":"https://merck.github.io/simtrial/reference/randomize_by_fixed_block.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Permuted fixed block randomization — randomize_by_fixed_block","text":"n Sample size randomized. block Vector treatments included block.","code":""},{"path":"https://merck.github.io/simtrial/reference/randomize_by_fixed_block.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Permuted fixed block randomization — randomize_by_fixed_block","text":"treatment group sequence (vector) length n treatments block permuted within block block size equal length block.","code":""},{"path":"https://merck.github.io/simtrial/reference/randomize_by_fixed_block.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Permuted fixed block randomization — randomize_by_fixed_block","text":"","code":"library(tibble) library(dplyr)  # Example 1 # 2:1 randomization with block size 3, treatments \"A\" and \"B\" tibble(x = 1:10) %>% mutate(Treatment = randomize_by_fixed_block(block = c(\"A\", \"B\", \"B\"))) #> # A tibble: 10 × 2 #>        x Treatment #>    <int> <chr>     #>  1     1 A         #>  2     2 B         #>  3     3 B         #>  4     4 B         #>  5     5 B         #>  6     6 A         #>  7     7 A         #>  8     8 B         #>  9     9 B         #> 10    10 B          # Example 2 # Stratified randomization tibble(stratum = c(rep(\"A\", 10), rep(\"B\", 10))) %>%   group_by(stratum) %>%   mutate(Treatment = randomize_by_fixed_block()) #> # A tibble: 20 × 2 #> # Groups:   stratum [2] #>    stratum Treatment #>    <chr>       <dbl> #>  1 A               0 #>  2 A               0 #>  3 A               1 #>  4 A               1 #>  5 A               0 #>  6 A               1 #>  7 A               0 #>  8 A               1 #>  9 A               1 #> 10 A               1 #> 11 B               1 #> 12 B               1 #> 13 B               0 #> 14 B               0 #> 15 B               0 #> 16 B               1 #> 17 B               1 #> 18 B               0 #> 19 B               0 #> 20 B               0"},{"path":"https://merck.github.io/simtrial/reference/rpw_enroll.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate piecewise exponential enrollment — rpw_enroll","title":"Generate piecewise exponential enrollment — rpw_enroll","text":"piecewise exponential enrollment rate generation enrollment rate distribution can easily approximated. rpw_enroll() support simulation Lachin Foulkes (1986) sample size method (fixed trial duration) well Kim Tsiatis(1990) method (fixed enrollment rates either fixed enrollment duration fixed minimum follow-); see gsDesign::nSurv().","code":""},{"path":"https://merck.github.io/simtrial/reference/rpw_enroll.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate piecewise exponential enrollment — rpw_enroll","text":"","code":"rpw_enroll(n = NULL, enroll_rate = tibble(duration = c(1, 2), rate = c(2, 5)))"},{"path":"https://merck.github.io/simtrial/reference/rpw_enroll.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate piecewise exponential enrollment — rpw_enroll","text":"n Number observations. Default NULL yields random enrollment size. enroll_rate tibble containing period duration (duration) enrollment rate (rate). specified enrollment periods. necessary, last period extended ensure enrollment specified n.","code":""},{"path":"https://merck.github.io/simtrial/reference/rpw_enroll.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate piecewise exponential enrollment — rpw_enroll","text":"vector random enrollment times.","code":""},{"path":"https://merck.github.io/simtrial/reference/rpw_enroll.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate piecewise exponential enrollment — rpw_enroll","text":"","code":"library(tibble)  # Example 1 # Piecewise uniform (piecewise exponential inter-arrival times) for 10k patients enrollment # Enrollment rates of 5 for time 0-100, 15 for 100-300, and 30 thereafter x <- rpw_enroll(   n = 1e5,   enroll_rate = tibble(     rate = c(5, 15, 30),     duration = c(100, 200, 100)   ) ) plot(x, 1:1e5,   main = \"Piecewise uniform enrollment simulation\",   xlab = \"Time\",   ylab = \"Enrollment\" )   # Example 2 # Exponential enrollment x <- rpw_enroll(   n = 1e5,   enroll_rate = tibble(rate = .03, duration = 1) ) plot(x, 1:1e5,   main = \"Simulated exponential inter-arrival times\",   xlab = \"Time\",   ylab = \"Enrollment\" )"},{"path":"https://merck.github.io/simtrial/reference/rpwexp.html","id":null,"dir":"Reference","previous_headings":"","what":"The piecewise exponential distribution — rpwexp","title":"The piecewise exponential distribution — rpwexp","text":"piecewise exponential distribution allows simple method specify distribution hazard rate changes time. likely useful conditions failure rates change, also simulations may delayed treatment effect treatment effect otherwise changing (example, decreasing) time. rpwexp() support simulation Lachin Foulkes (1986) sample size method (fixed trial duration) well Kim Tsiatis(1990) method (fixed enrollment rates either fixed enrollment duration fixed minimum follow-); see gsDesign::nSurv().","code":""},{"path":"https://merck.github.io/simtrial/reference/rpwexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The piecewise exponential distribution — rpwexp","text":"","code":"rpwexp(n = 100, fail_rate = tibble(duration = c(1, 1), rate = c(10, 20)))"},{"path":"https://merck.github.io/simtrial/reference/rpwexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The piecewise exponential distribution — rpwexp","text":"n Number observations generated. fail_rate tibble containing duration rate variables. rate specifies failure rates corresponding interval duration specified duration. final interval extended infinite ensure observations generated.","code":""},{"path":"https://merck.github.io/simtrial/reference/rpwexp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The piecewise exponential distribution — rpwexp","text":"Using cumulative = TRUE option, enrollment times piecewise constant time can generated.","code":""},{"path":"https://merck.github.io/simtrial/reference/rpwexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The piecewise exponential distribution — rpwexp","text":"","code":"library(tibble)  # Example 1 # Exponential failure times x <- rpwexp(   n = 10000,   fail_rate = tibble(rate = 5, duration = 1) ) plot(sort(x), (10000:1) / 10001,   log = \"y\", main = \"Exponential simulated survival curve\",   xlab = \"Time\", ylab = \"P{Survival}\" )   # Example 2  # Get 10k piecewise exponential failure times. # Failure rates are 1 for time 0 to 0.5, 3 for time 0.5 to 1, and 10 for > 1. # Intervals specifies duration of each failure rate interval # with the final interval running to infinity. x <- rpwexp(   n = 1e4,   fail_rate = tibble(rate = c(1, 3, 10), duration = c(.5, .5, 1)) ) plot(sort(x), (1e4:1) / 10001,   log = \"y\", main = \"PW Exponential simulated survival curve\",   xlab = \"Time\", ylab = \"P{Survival}\" )"},{"path":"https://merck.github.io/simtrial/reference/rpwexpRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"The piecewise exponential distribution in C++ — rpwexpRcpp","title":"The piecewise exponential distribution in C++ — rpwexpRcpp","text":"piecewise exponential distribution C++","code":""},{"path":"https://merck.github.io/simtrial/reference/rpwexpRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The piecewise exponential distribution in C++ — rpwexpRcpp","text":"","code":"rpwexpRcpp(n, fail_rate)"},{"path":"https://merck.github.io/simtrial/reference/rpwexpRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The piecewise exponential distribution in C++ — rpwexpRcpp","text":"n Number observations generated. fail_rate data frame containing duration rate variables.","code":""},{"path":"https://merck.github.io/simtrial/reference/rpwexpinvRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"The piecewise exponential distribution using inverse CDF method in C++ — rpwexpinvRcpp","title":"The piecewise exponential distribution using inverse CDF method in C++ — rpwexpinvRcpp","text":"piecewise exponential distribution using inverse CDF method C++","code":""},{"path":"https://merck.github.io/simtrial/reference/rpwexpinvRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The piecewise exponential distribution using inverse CDF method in C++ — rpwexpinvRcpp","text":"","code":"rpwexpinvRcpp(n, fail_rate)"},{"path":"https://merck.github.io/simtrial/reference/rpwexpinvRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The piecewise exponential distribution using inverse CDF method in C++ — rpwexpinvRcpp","text":"n Number observations generated. fail_rate data frame containing duration rate variables.","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_fixed_n.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulation of fixed sample size design for time-to-event endpoint — sim_fixed_n","title":"Simulation of fixed sample size design for time-to-event endpoint — sim_fixed_n","text":"sim_fixed_n() provides simulations single endpoint two-arm trial enrollment, hazard ratio, failure dropout rates change time.","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_fixed_n.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulation of fixed sample size design for time-to-event endpoint — sim_fixed_n","text":"","code":"sim_fixed_n(   n_sim = 1000,   sample_size = 500,   target_event = 350,   stratum = tibble(stratum = \"All\", p = 1),   enroll_rate = tibble(duration = c(2, 2, 10), rate = c(3, 6, 9)),   fail_rate = tibble(stratum = \"All\", duration = c(3, 100), fail_rate = log(2)/c(9, 18),     hr = c(0.9, 0.6), dropout_rate = rep(0.001, 2)),   total_duration = 30,   block = rep(c(\"experimental\", \"control\"), 2),   timing_type = 1:5,   rho_gamma = tibble(rho = 0, gamma = 0),   seed = NULL )"},{"path":"https://merck.github.io/simtrial/reference/sim_fixed_n.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulation of fixed sample size design for time-to-event endpoint — sim_fixed_n","text":"n_sim Number simulations perform. sample_size Total sample size per simulation. target_event Targeted event count analysis. stratum tibble stratum specified stratum, probability (incidence) stratum p. enroll_rate Piecewise constant enrollment rates time period. Note overall population enrollment rates stratum argument controls random distribution stratum. fail_rate Piecewise constant control group failure rates, hazard ratio experimental vs. control, dropout rates stratum time period. total_duration Total follow-start enrollment data cutoff. block sim_pw_surv(). Vector treatments included block. timing_type numeric vector determining data cutoffs used; see details. Default include available cutoff methods. rho_gamma tenFHcorr(). tibble variables rho gamma, greater equal zero, specify one Fleming-Harrington weighted logrank test per row. seed Optional. Initial seed simulations.","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_fixed_n.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulation of fixed sample size design for time-to-event endpoint — sim_fixed_n","text":"tibble including columns: event: Event count. ln_hr: Log-hazard ratio. z: Normal test statistic; < 0 favors experimental. cut: Text describing cutoff used. duration: Duration trial cutoff analysis. sim: Sequential simulation ID. One row per simulated dataset per cutoff specified timing_type, per test statistic specified. multiple Fleming-Harrington tests specified rho_gamma, columns rho gamma also included.","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_fixed_n.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulation of fixed sample size design for time-to-event endpoint — sim_fixed_n","text":"timing_type 5 elements indicating different options data cutoff: 1: Uses planned study duration. 2: time targeted event count achieved. 3: planned minimum follow-enrollment complete. 4: maximum planned study duration targeted event count cuts (1 2). 5: maximum targeted event count minimum follow-cuts (2 3).","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_fixed_n.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulation of fixed sample size design for time-to-event endpoint — sim_fixed_n","text":"","code":"library(tibble) library(dplyr) library(doParallel) #> Loading required package: foreach #> Loading required package: iterators #> Loading required package: parallel  # Example 1 # Show output structure sim_fixed_n(n_sim = 3) #>    event      ln_hr         z                              cut duration sim #> 1    101 -0.3522511 -1.752126                 Planned duration 30.00000   1 #> 2    350 -0.5168667 -4.790643                  Targeted events 69.59328   1 #> 3    379 -0.5189904 -4.995066                Minimum follow-up 75.69277   1 #> 4    350 -0.5168667 -4.790643 Max(planned duration, event cut) 69.59328   1 #> 5    379 -0.5189904 -4.995066    Max(min follow-up, event cut) 75.69277   1 #> 6    107 -0.2975686 -1.535520                 Planned duration 30.00000   2 #> 7    350 -0.4052431 -3.765199                  Targeted events 68.12223   2 #> 8    368 -0.3825953 -3.644183                Minimum follow-up 72.29147   2 #> 9    350 -0.4052431 -3.765199 Max(planned duration, event cut) 68.12223   2 #> 10   368 -0.3825953 -3.644183    Max(min follow-up, event cut) 72.29147   2 #> 11    95 -0.6520075 -3.130770                 Planned duration 30.00000   3 #> 12   350 -0.3989916 -3.727074                  Targeted events 72.02823   3 #> 13   362 -0.3804652 -3.615067                Minimum follow-up 75.90926   3 #> 14   350 -0.3989916 -3.727074 Max(planned duration, event cut) 72.02823   3 #> 15   362 -0.3804652 -3.615067    Max(min follow-up, event cut) 75.90926   3  # Example 2 # Example with 2 tests: logrank and FH(0,1) sim_fixed_n(n_sim = 1, rho_gamma = tibble(rho = 0, gamma = c(0, 1))) #>    event      ln_hr rho gamma         z        v1        v2 #> 1    100 -0.3009676   0     0 -1.494528 1.0000000 0.8287654 #> 2    100 -0.3009676   0     1 -2.278357 0.8287654 1.0000000 #> 3    350 -0.5613950   0     0 -5.227084 1.0000000 0.8515610 #> 4    350 -0.5613950   0     1 -5.362806 0.8515610 1.0000000 #> 5    348 -0.5468179   0     0 -5.078747 1.0000000 0.8516328 #> 6    348 -0.5468179   0     1 -5.122347 0.8516328 1.0000000 #> 7    350 -0.5613950   0     0 -5.227084 1.0000000 0.8515610 #> 8    350 -0.5613950   0     1 -5.362806 0.8515610 1.0000000 #> 9    350 -0.5613950   0     0 -5.227084 1.0000000 0.8515610 #> 10   350 -0.5613950   0     1 -5.362806 0.8515610 1.0000000 #>                                 cut duration sim #> 1                  Planned duration 30.00000   1 #> 2                  Planned duration 30.00000   1 #> 3                   Targeted events 75.36799   1 #> 4                   Targeted events 75.36799   1 #> 5                 Minimum follow-up 75.10971   1 #> 6                 Minimum follow-up 75.10971   1 #> 7  Max(planned duration, event cut) 75.36799   1 #> 8  Max(planned duration, event cut) 75.36799   1 #> 9     Max(min follow-up, event cut) 75.36799   1 #> 10    Max(min follow-up, event cut) 75.36799   1  # Example 3 # Power by test # Only use cuts for events, events + min follow-up xx <- sim_fixed_n(   n_sim = 100,   timing_type = c(2, 5),   rho_gamma = tibble(rho = 0, gamma = c(0, 1)) ) # Get power approximation for FH, data cutoff combination xx %>%   group_by(cut, rho, gamma) %>%   summarize(mean(z <= qnorm(.025))) #> `summarise()` has grouped output by 'cut', 'rho'. You can override using the #> `.groups` argument. #> # A tibble: 4 × 4 #> # Groups:   cut, rho [2] #>   cut                             rho gamma `mean(z <= qnorm(0.025))` #>   <chr>                         <dbl> <dbl>                     <dbl> #> 1 Max(min follow-up, event cut)     0     0                      0.99 #> 2 Max(min follow-up, event cut)     0     1                      0.98 #> 3 Targeted events                   0     0                      0.97 #> 4 Targeted events                   0     1                      0.98  # MaxCombo power estimate for cutoff at max of targeted events, minimum follow-up p <- xx %>%   filter(cut != \"Targeted events\") %>%   group_by(sim) %>%   group_map(pvalue_maxcombo) %>%   unlist()  mean(p < .025) #> [1] 0.98  # MaxCombo estimate for targeted events cutoff p <- xx %>%   filter(cut == \"Targeted events\") %>%   group_by(sim) %>%   group_map(pvalue_maxcombo) %>%   unlist()  mean(p < .025) #> [1] 0.97  # Example 3 # Use two cores registerDoParallel(2) sim_fixed_n(n_sim = 10, seed = 2022) #> Using 2 cores with backend doParallelMC #>    event       ln_hr           z                              cut duration sim #> 1    109 -0.39889743 -2.06986755                 Planned duration 30.00000   1 #> 2    350 -0.49422311 -4.60390065                  Targeted events 68.10765   1 #> 3    361 -0.46996411 -4.44698855                Minimum follow-up 70.94601   1 #> 4    350 -0.49422311 -4.60390065 Max(planned duration, event cut) 68.10765   1 #> 5    361 -0.46996411 -4.44698855    Max(min follow-up, event cut) 70.94601   1 #> 6     92  0.13030304  0.62455481                 Planned duration 30.00000   2 #> 7    350 -0.06380056 -0.59576098                  Targeted events 71.15880   2 #> 8    369 -0.12986489 -1.24394980                Minimum follow-up 74.20194   2 #> 9    350 -0.06380056 -0.59576098 Max(planned duration, event cut) 71.15880   2 #> 10   369 -0.12986489 -1.24394980    Max(min follow-up, event cut) 74.20194   2 #> 11   109 -0.35042569 -1.81806443                 Planned duration 30.00000   3 #> 12   350 -0.30340153 -2.82469678                  Targeted events 69.68286   3 #> 13   353 -0.30661159 -2.86687105                Minimum follow-up 71.40394   3 #> 14   350 -0.30340153 -2.82469678 Max(planned duration, event cut) 69.68286   3 #> 15   353 -0.30661159 -2.86687105    Max(min follow-up, event cut) 71.40394   3 #> 16   107 -0.32400212 -1.66943391                 Planned duration 30.00000   4 #> 17   350 -0.38322625 -3.56929885                  Targeted events 70.15615   4 #> 18   361 -0.40035000 -3.78355568                Minimum follow-up 73.04033   4 #> 19   350 -0.38322625 -3.56929885 Max(planned duration, event cut) 70.15615   4 #> 20   361 -0.40035000 -3.78355568    Max(min follow-up, event cut) 73.04033   4 #> 21    99 -0.13790150 -0.68382782                 Planned duration 30.00000   5 #> 22   350 -0.43925467 -4.08974448                  Targeted events 71.52825   5 #> 23   369 -0.44486563 -4.25463983                Minimum follow-up 76.21111   5 #> 24   350 -0.43925467 -4.08974448 Max(planned duration, event cut) 71.52825   5 #> 25   369 -0.44486563 -4.25463983    Max(min follow-up, event cut) 76.21111   5 #> 26   105 -0.18871020 -0.96580373                 Planned duration 30.00000   6 #> 27   350 -0.32895353 -3.07323368                  Targeted events 68.56574   6 #> 28   358 -0.33990896 -3.21127927                Minimum follow-up 69.61403   6 #> 29   350 -0.32895353 -3.07323368 Max(planned duration, event cut) 68.56574   6 #> 30   358 -0.33990896 -3.21127927    Max(min follow-up, event cut) 69.61403   6 #> 31    91 -0.32023796 -1.51269632                 Planned duration 30.00000   7 #> 32   350 -0.30003853 -2.79088836                  Targeted events 74.43009   7 #> 33   348 -0.30041840 -2.78367764                Minimum follow-up 73.88934   7 #> 34   350 -0.30003853 -2.79088836 Max(planned duration, event cut) 74.43009   7 #> 35   350 -0.30003853 -2.79088836    Max(min follow-up, event cut) 74.43009   7 #> 36   108 -0.06740129 -0.34998515                 Planned duration 30.00000   8 #> 37   350 -0.34760754 -3.23571976                  Targeted events 70.79181   8 #> 38   360 -0.36258193 -3.42179494                Minimum follow-up 73.10338   8 #> 39   350 -0.34760754 -3.23571976 Max(planned duration, event cut) 70.79181   8 #> 40   360 -0.36258193 -3.42179494    Max(min follow-up, event cut) 73.10338   8 #> 41   101 -0.51016154 -2.54286277                 Planned duration 30.00000   9 #> 42   350 -0.37603601 -3.50384516                  Targeted events 68.74117   9 #> 43   364 -0.37361232 -3.55001459                Minimum follow-up 74.54110   9 #> 44   350 -0.37603601 -3.50384516 Max(planned duration, event cut) 68.74117   9 #> 45   364 -0.37361232 -3.55001459    Max(min follow-up, event cut) 74.54110   9 #> 46    79  0.01209188  0.05336003                 Planned duration 30.00000  10 #> 47   350 -0.18922477 -1.76159151                  Targeted events 73.00188  10 #> 48   361 -0.19779690 -1.86989858                Minimum follow-up 76.39085  10 #> 49   350 -0.18922477 -1.76159151 Max(planned duration, event cut) 73.00188  10 #> 50   361 -0.19779690 -1.86989858    Max(min follow-up, event cut) 76.39085  10 stopImplicitCluster() registerDoSEQ()"},{"path":"https://merck.github.io/simtrial/reference/sim_pw_surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate a stratified time-to-event outcome randomized trial — sim_pw_surv","title":"Simulate a stratified time-to-event outcome randomized trial — sim_pw_surv","text":"sim_pw_surv() enables simulation clinical trial essentially arbitrary patterns enrollment, failure rates censoring. piecewise exponential distribution allows simple method specify distribution enrollment pattern enrollment, failure, dropout rate changes time. main purpose may generate trial can analyzed single point time using group sequential methods, routine can also used simulate adaptive trial design. Enrollment, failure, dropout rates specified treatment group, stratum time period. Fixed block randomization used; blocks must include treatments provided failure dropout specification. Default arguments set allow simple implementation non-proportional hazards assumption unstratified design.","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_pw_surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate a stratified time-to-event outcome randomized trial — sim_pw_surv","text":"","code":"sim_pw_surv(   n = 100,   stratum = tibble(stratum = \"All\", p = 1),   block = c(rep(\"control\", 2), rep(\"experimental\", 2)),   enroll_rate = tibble(rate = 9, duration = 1),   fail_rate = tibble(stratum = rep(\"All\", 4), period = rep(1:2, 2), treatment =     c(rep(\"control\", 2), rep(\"experimental\", 2)), duration = rep(c(3, 1), 2), rate =     log(2)/c(9, 9, 9, 18)),   dropout_rate = tibble(stratum = rep(\"All\", 2), period = rep(1, 2), treatment =     c(\"control\", \"experimental\"), duration = rep(100, 2), rate = rep(0.001, 2)) )"},{"path":"https://merck.github.io/simtrial/reference/sim_pw_surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate a stratified time-to-event outcome randomized trial — sim_pw_surv","text":"n Number observations. length(n) > 1, length taken number required. stratum tibble stratum specified stratum, probability (incidence) stratum p. block Vector treatments included block. enroll_rate Enrollment rates; see details examples. fail_rate Failure rates; see details examples; note treatments need input block. dropout_rate Dropout rates; see details examples; note treatments need input block.","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_pw_surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate a stratified time-to-event outcome randomized trial — sim_pw_surv","text":"tibble following variables observation: stratum. enroll_time: Enrollment time observation. Treatment: Treatment group; one values input block. fail_time: Failure time generated using rpwexp(). dropout_time: Dropout time generated using rpwexp(). cte: Calendar time enrollment plot minimum failure time dropout time. fail: Indicator cte set using failure time; .e., 1 failure, 0 dropout.","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_pw_surv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate a stratified time-to-event outcome randomized trial — sim_pw_surv","text":"","code":"library(tibble) library(dplyr)  # Example 1 sim_pw_surv(n = 20) #> # A tibble: 20 × 7 #> # Groups:   stratum, treatment [2] #>    stratum enroll_time treatment    fail_time dropout_time    cte  fail #>    <chr>         <dbl> <chr>            <dbl>        <dbl>  <dbl> <dbl> #>  1 All          0.0143 experimental   21.3           127.  21.3       1 #>  2 All          0.0512 experimental   49.9           619.  50.0       1 #>  3 All          0.217  control         1.07          652.   1.29      1 #>  4 All          0.221  control         0.0356        526.   0.257     1 #>  5 All          0.236  control        50.7          1490.  50.9       1 #>  6 All          0.312  experimental   23.8          1562.  24.1       1 #>  7 All          0.400  control         0.658        2970.   1.06      1 #>  8 All          0.412  experimental   14.6           362.  15.0       1 #>  9 All          0.490  experimental   43.7          1500.  44.2       1 #> 10 All          0.528  control         7.43           26.2  7.95      1 #> 11 All          0.558  experimental   19.0           204.  19.5       1 #> 12 All          0.648  control         0.235         793.   0.883     1 #> 13 All          0.806  experimental    2.88         3127.   3.68      1 #> 14 All          0.826  control         2.82         3787.   3.65      1 #> 15 All          1.05   control        14.1           325.  15.1       1 #> 16 All          1.12   experimental   70.4           446.  71.5       1 #> 17 All          1.13   experimental   22.0           252.  23.1       1 #> 18 All          1.16   control         3.87           26.0  5.03      1 #> 19 All          1.16   experimental   10.5            69.3 11.7       1 #> 20 All          1.19   control         3.11          994.   4.30      1  # Example 2 # 3:1 randomization sim_pw_surv(   n = 20,   block = c(rep(\"experimental\", 3), \"control\") ) #> # A tibble: 20 × 7 #> # Groups:   stratum, treatment [2] #>    stratum enroll_time treatment    fail_time dropout_time    cte  fail #>    <chr>         <dbl> <chr>            <dbl>        <dbl>  <dbl> <dbl> #>  1 All          0.0383 experimental   13.2          1191.  13.3       1 #>  2 All          0.156  experimental    0.0719        566.   0.228     1 #>  3 All          0.196  control         1.04         1261.   1.24      1 #>  4 All          0.421  experimental   12.8           596.  13.2       1 #>  5 All          0.442  experimental   19.2           330.  19.7       1 #>  6 All          0.557  control         9.22          515.   9.78      1 #>  7 All          0.631  experimental   37.2            27.0 27.6       0 #>  8 All          0.670  experimental   30.9          2148.  31.6       1 #>  9 All          0.810  experimental    5.43          661.   6.24      1 #> 10 All          0.876  control         6.89          787.   7.77      1 #> 11 All          0.898  experimental   17.0          4110.  17.9       1 #> 12 All          0.934  experimental   41.7           835.  42.7       1 #> 13 All          1.26   control        27.3           660.  28.6       1 #> 14 All          1.31   experimental   16.2           312.  17.6       1 #> 15 All          1.59   experimental   66.2           529.  67.8       1 #> 16 All          1.95   experimental   14.1            50.0 16.0       1 #> 17 All          2.15   experimental    0.823         218.   2.98      1 #> 18 All          2.18   control         7.66          230.   9.84      1 #> 19 All          2.36   experimental    1.11          360.   3.47      1 #> 20 All          2.50   experimental   19.8           313.  22.3       1  # Example 3 # Simulate 2 stratum; will use defaults for blocking and enrollRates sim_pw_surv(   n = 20,   # 2 stratum,30% and 70% prevalence   stratum = tibble(stratum = c(\"Low\", \"High\"), p = c(.3, .7)),   fail_rate = tibble(     stratum = c(rep(\"Low\", 4), rep(\"High\", 4)),     period = rep(1:2, 4),     treatment = rep(c(       rep(\"control\", 2),       rep(\"experimental\", 2)     ), 2),     duration = rep(c(3, 1), 4),     rate = c(.03, .05, .03, .03, .05, .08, .07, .04)   ),   dropout_rate = tibble(     stratum = c(rep(\"Low\", 2), rep(\"High\", 2)),     period = rep(1, 4),     treatment = rep(c(\"control\", \"experimental\"), 2),     duration = rep(1, 4),     rate = rep(.001, 4)   ) ) #> # A tibble: 20 × 7 #> # Groups:   stratum, treatment [4] #>    stratum enroll_time treatment    fail_time dropout_time     cte  fail #>    <chr>         <dbl> <chr>            <dbl>        <dbl>   <dbl> <dbl> #>  1 High         0.0186 control         0.0538        353.   0.0724     1 #>  2 High         0.802  experimental    2.23          891.   3.03       1 #>  3 High         0.805  control        47.4          3400.  48.2        1 #>  4 High         0.879  experimental    6.86          528.   7.74       1 #>  5 High         0.972  control        21.0            85.5 22.0        1 #>  6 Low          1.25   experimental    5.27         6867.   6.52       1 #>  7 High         1.40   experimental    7.36         1703.   8.75       1 #>  8 High         1.41   experimental    7.15           57.6  8.56       1 #>  9 High         1.43   control         1.04         1785.   2.47       1 #> 10 High         1.46   control        25.6          1229.  27.1        1 #> 11 High         1.47   experimental   31.7           582.  33.1        1 #> 12 High         1.52   control        17.0           599.  18.5        1 #> 13 High         1.67   experimental   34.6           664.  36.3        1 #> 14 Low          1.75   experimental    2.02          647.   3.77       1 #> 15 High         1.92   experimental   40.1           323.  42.0        1 #> 16 Low          1.95   control        39.5           412.  41.5        1 #> 17 High         2.05   control        13.6           777.  15.7        1 #> 18 Low          2.11   control        79.4           756.  81.5        1 #> 19 High         2.14   experimental    8.63           73.9 10.8        1 #> 20 High         2.28   control         3.17          139.   5.44       1 # Example 4 # If you want a more rectangular entry for a tibble fail_rate <- bind_rows(   tibble(stratum = \"Low\", period = 1, treatment = \"control\", duration = 3, rate = .03),   tibble(stratum = \"Low\", period = 1, treatment = \"experimental\", duration = 3, rate = .03),   tibble(stratum = \"Low\", period = 2, treatment = \"experimental\", duration = 3, rate = .02),   tibble(stratum = \"High\", period = 1, treatment = \"control\", duration = 3, rate = .05),   tibble(stratum = \"High\", period = 1, treatment = \"experimental\", duration = 3, rate = .06),   tibble(stratum = \"High\", period = 2, treatment = \"experimental\", duration = 3, rate = .03) )  dropout_rate <- bind_rows(   tibble(stratum = \"Low\", period = 1, treatment = \"control\", duration = 3, rate = .001),   tibble(stratum = \"Low\", period = 1, treatment = \"experimental\", duration = 3, rate = .001),   tibble(stratum = \"High\", period = 1, treatment = \"control\", duration = 3, rate = .001),   tibble(stratum = \"High\", period = 1, treatment = \"experimental\", duration = 3, rate = .001) )  sim_pw_surv(   n = 12,   stratum = tibble(stratum = c(\"Low\", \"High\"), p = c(.3, .7)),   fail_rate = fail_rate,   dropout_rate = dropout_rate ) #> # A tibble: 12 × 7 #> # Groups:   stratum, treatment [4] #>    stratum enroll_time treatment    fail_time dropout_time     cte  fail #>    <chr>         <dbl> <chr>            <dbl>        <dbl>   <dbl> <dbl> #>  1 High         0.0195 control          0.336         55.4   0.356     1 #>  2 High         0.0240 control          1.11        3340.    1.14      1 #>  3 High         0.0766 experimental     9.01         149.    9.08      1 #>  4 High         0.370  experimental    41.4          329.   41.7       1 #>  5 High         0.463  control         15.0          392.   15.5       1 #>  6 High         0.489  experimental    75.5          815.   75.9       1 #>  7 Low          0.512  control         17.0           79.9  17.5       1 #>  8 High         0.519  experimental    30.7          147.   31.3       1 #>  9 High         0.605  control          0.552        423.    1.16      1 #> 10 High         0.926  experimental    25.6         2204.   26.5       1 #> 11 Low          0.999  experimental   123.          4176.  124.        1 #> 12 High         1.34   control         25.4          315.   26.7       1"},{"path":"https://merck.github.io/simtrial/reference/simfix2simpwsurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Conversion of enrollment and failure rates from sim_fixed_n() to\nsim_pw_surv() format — simfix2simpwsurv","title":"Conversion of enrollment and failure rates from sim_fixed_n() to\nsim_pw_surv() format — simfix2simpwsurv","text":"simfix2simpwsurv() converts failure rates dropout rates entered simpler format sim_fixed_n() used sim_pw_surv(). fail_rate argument sim_fixed_n() requires enrollment rates, failure rates hazard ratios dropout rates stratum 2-arm trial, sim_pw_surv() flexible less obvious flexible format. Since sim_fixed_n() automatically analyzes data sim_pw_surv() just produces simulation dataset, latter provides additional options analyze otherwise evaluate individual simulations ways sim_fixed_n() .","code":""},{"path":"https://merck.github.io/simtrial/reference/simfix2simpwsurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conversion of enrollment and failure rates from sim_fixed_n() to\nsim_pw_surv() format — simfix2simpwsurv","text":"","code":"simfix2simpwsurv(   fail_rate = tibble(stratum = \"All\", duration = c(3, 100), fail_rate = log(2)/c(9, 18),     hr = c(0.9, 0.6), dropout_rate = rep(0.001, 2)) )"},{"path":"https://merck.github.io/simtrial/reference/simfix2simpwsurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conversion of enrollment and failure rates from sim_fixed_n() to\nsim_pw_surv() format — simfix2simpwsurv","text":"fail_rate Piecewise constant control group failure rates, hazard ratio experimental vs. control, dropout rates stratum time period.","code":""},{"path":"https://merck.github.io/simtrial/reference/simfix2simpwsurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conversion of enrollment and failure rates from sim_fixed_n() to\nsim_pw_surv() format — simfix2simpwsurv","text":"list two tibble components formatted sim_pw_surv(): fail_rate dropout_rate.","code":""},{"path":"https://merck.github.io/simtrial/reference/simfix2simpwsurv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conversion of enrollment and failure rates from sim_fixed_n() to\nsim_pw_surv() format — simfix2simpwsurv","text":"","code":"library(tidyr) library(dplyr) library(tibble)  # Example 1 # Convert standard input simfix2simpwsurv() #> $fail_rate #> # A tibble: 4 × 5 #>   stratum period treatment    duration   rate #>   <chr>    <int> <chr>           <dbl>  <dbl> #> 1 All          1 control             3 0.0770 #> 2 All          2 control           100 0.0385 #> 3 All          1 experimental        3 0.0693 #> 4 All          2 experimental      100 0.0231 #>  #> $dropout_rate #> # A tibble: 4 × 5 #>   stratum period treatment    duration  rate #>   <chr>    <int> <chr>           <dbl> <dbl> #> 1 All          1 control             3 0.001 #> 2 All          2 control           100 0.001 #> 3 All          1 experimental        3 0.001 #> 4 All          2 experimental      100 0.001 #>   # Stratified example fail_rate <- tibble(   stratum = c(rep(\"Low\", 3), rep(\"High\", 3)),   duration = rep(c(4, 10, 100), 2),   fail_rate = c(     .04, .1, .06,     .08, .16, .12   ),   hr = c(     1.5, .5, 2 / 3,     2, 10 / 16, 10 / 12   ),   dropout_rate = .01 )  x <- simfix2simpwsurv(fail_rate)  # Do a single simulation with the above rates # Enroll 300 patients in ~12 months at constant rate sim <- sim_pw_surv(   n = 300,   stratum = tibble(stratum = c(\"Low\", \"High\"), p = c(.6, .4)),   enroll_rate = tibble(duration = 12, rate = 300 / 12),   fail_rate = x$fail_rate,   dropout_rate = x$dropout_rate )  # Cut after 200 events and do a stratified logrank test dat <- sim %>%   cut_data_by_event(200) %>% # cut data   counting_process(arm = \"experimental\") %>% # convert format for tenFH   wlr(rho_gamma = tibble(rho = 0, gamma = 0)) # stratified logrank"},{"path":"https://merck.github.io/simtrial/reference/simtrial-package.html","id":null,"dir":"Reference","previous_headings":"","what":"simtrial: Clinical Trial Simulation — simtrial-package","title":"simtrial: Clinical Trial Simulation — simtrial-package","text":"simtrial provides basic routines simulating clinical trial. primary intent provide tools generate trial simulations trials time event outcomes. Piecewise exponential failure rates piecewise constant enrollment rates underlying mechanism used simulate broad range scenarios. However, basic generation data done using pipes allow maximum flexibility users meet different needs.","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/reference/simtrial-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"simtrial: Clinical Trial Simulation — simtrial-package","text":"Maintainer: Yujie Zhao yujie.zhao@merck.com [contributor] Authors: Keaven Anderson keaven_anderson@merck.com Yilong Zhang elong0527@gmail.com contributors: Nan Xiao [contributor] Jianxiao Yang [contributor] Lili Ling [contributor] Xintong Li [contributor] Ruixue Wang [contributor] Yi Cui [contributor] Ping Yang [contributor] Yalin Zhu [contributor] Heng Zhou [contributor] Amin Shirazi [contributor] Merck & Co., Inc., Rahway, NJ, USA affiliates [copyright holder]","code":""},{"path":"https://merck.github.io/simtrial/reference/tenFHcorr.html","id":null,"dir":"Reference","previous_headings":"","what":"Fleming-Harrington weighted logrank tests plus correlations — tenFHcorr","title":"Fleming-Harrington weighted logrank tests plus correlations — tenFHcorr","text":"Correlations can used mvtnorm::pmvnorm() compute p-value MaxCombo, maximum specified Fleming-Harrington tests.","code":""},{"path":"https://merck.github.io/simtrial/reference/tenFHcorr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fleming-Harrington weighted logrank tests plus correlations — tenFHcorr","text":"","code":"tenFHcorr(   x = sim_pw_surv(n = 200) %>% cut_data_by_event(100) %>% counting_process(arm =     \"experimental\"),   rho_gamma = tibble(rho = c(0, 0, 1, 1), gamma = c(0, 1, 0, 1)),   corr = TRUE )"},{"path":"https://merck.github.io/simtrial/reference/tenFHcorr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fleming-Harrington weighted logrank tests plus correlations — tenFHcorr","text":"x counting_process()-class tibble counting process dataset. rho_gamma tibble variables rho gamma, greater equal zero, specify one Fleming-Harrington weighted logrank test per row. corr Logical; TRUE (default), return correlation matrix; otherwise, return covariance matrix.","code":""},{"path":"https://merck.github.io/simtrial/reference/tenFHcorr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fleming-Harrington weighted logrank tests plus correlations — tenFHcorr","text":"tibble rho_gamma input, FH test statistics specified data z, correlation covariance matrix tests variables starting v.","code":""},{"path":"https://merck.github.io/simtrial/reference/tenFHcorr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fleming-Harrington weighted logrank tests plus correlations — tenFHcorr","text":"","code":"library(tibble) library(dplyr)  # Use default enrollment and event rates at cut of 100 events x <- sim_pw_surv(n = 200) %>%   cut_data_by_event(100) %>%   counting_process(arm = \"experimental\")  # Compute logrank (FH(0,0)) and FH(0,1) x <- x %>% tenFHcorr(rho_gamma = tibble(   rho = c(0, 0),   gamma = c(0, 1) ))  # Compute p-value for MaxCombo library(mvtnorm) 1 - pmvnorm(   lower = rep(min(x$z), nrow(x)),   corr = data.matrix(select(x, -c(rho, gamma, z))),   algorithm = GenzBretz(maxpts = 50000, abseps = 0.00001) )[1] #> [1] 0.02383219  # Check that covariance is as expected x <- sim_pw_surv(n = 200) %>%   cut_data_by_event(100) %>%   counting_process(arm = \"experimental\")  x %>% tenFHcorr(   rho_gamma = tibble(     rho = c(0, 0),     gamma = c(0, 1)   ),   corr = FALSE ) #>   rho gamma         z        v1       v2 #> 1   0     0 -3.081887 24.604353 6.506051 #> 2   0     1 -4.355229  6.506051 2.416741  # Off-diagonal element should be variance in following x %>% tenFHcorr(   rho_gamma = tibble(     rho = 0,     gamma = .5   ),   corr = FALSE ) #>   rho gamma         z       v1 #> 1   0   0.5 -4.034432 6.506051  # Compare off diagonal result with wlr() x %>% wlr(rho_gamma = tibble(rho = 0, gamma = .5)) #> # A tibble: 1 × 3 #>     rho gamma     z #>   <dbl> <dbl> <dbl> #> 1     0   0.5 -4.03"},{"path":"https://merck.github.io/simtrial/reference/wlr.html","id":null,"dir":"Reference","previous_headings":"","what":"Fleming-Harrington weighted logrank tests — wlr","title":"Fleming-Harrington weighted logrank tests — wlr","text":"output function counting_process().","code":""},{"path":"https://merck.github.io/simtrial/reference/wlr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fleming-Harrington weighted logrank tests — wlr","text":"","code":"wlr(   x = sim_pw_surv(n = 200) %>% cut_data_by_event(150) %>% counting_process(arm =     \"experimental\"),   rho_gamma = tibble(rho = c(0, 0, 1, 1), gamma = c(0, 1, 0, 1)),   return_variance = FALSE )"},{"path":"https://merck.github.io/simtrial/reference/wlr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fleming-Harrington weighted logrank tests — wlr","text":"x counting_process()-class tibble counting process dataset. rho_gamma tibble variables rho gamma, greater equal zero, specify one Fleming-Harrington weighted logrank test per row; Default: tibble(rho = c(0, 0, 1, 1), gamma = c(0, 1, 0, 1)). return_variance logical flag , TRUE, adds columns estimated variance weighted sum observed minus expected; see details; Default: FALSE.","code":""},{"path":"https://merck.github.io/simtrial/reference/wlr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fleming-Harrington weighted logrank tests — wlr","text":"tibble rho_gamma input FH test statistic data x. (z, directional square root usual weighted logrank test); variance calculations specified (example, used covariances combination test), returned column Var.","code":""},{"path":"https://merck.github.io/simtrial/reference/wlr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fleming-Harrington weighted logrank tests — wlr","text":"input value x produced counting_process() produces counting process dataset grouped stratum sorted within stratum increasing times events occur. \\(z\\) - Standardized normal Fleming-Harrington weighted logrank test. \\(\\) - Stratum index. \\(d_i\\) - Number distinct times events occurred stratum \\(\\). \\(t_{ij}\\) - Ordered times events stratum \\(\\), \\(j = 1, 2, \\ldots, d_i\\) observed; observation, \\(t_{ij}\\) represents time post study entry. \\(O_{ij.}\\) - Total number events stratum \\(\\) occurred time \\(t_{ij}\\). \\(O_{ije}\\) - Total number events stratum \\(\\) experimental treatment group occurred time \\(t_{ij}\\). \\(N_{ij.}\\) - Total number study subjects stratum \\(\\) followed least duration. \\(E_{ije}\\) - Expected observations experimental treatment group given random selection \\(O_{ij.}\\) stratum \\(\\) risk time \\(t_{ij}\\). \\(V_{ije}\\) - Hypergeometric variance \\(E_{ije}\\) produced Var counting_process(). \\(N_{ije}\\) - Total number study subjects stratum \\(\\) experimental treatment group followed least duration \\(t_{ij}\\). \\(E_{ije}\\) - Expected observations experimental group stratum \\(\\) time \\(t_{ij}\\) conditioning overall number events risk populations time sampling risk observations without replacement: $$E_{ije} = O_{ij.} N_{ije}/N_{ij.}$$ \\(S_{ij}\\) - Kaplan-Meier estimate survival combined treatment groups immediately prior time \\(t_{ij}\\). \\(\\rho, \\gamma\\) - Real parameters Fleming-Harrington test. \\(X_i\\) - Numerator signed logrank test stratum \\(\\) $$X_i = \\sum_{j=1}^{d_{}} S_{ij}^\\rho(1-S_{ij}^\\gamma)(O_{ije}-E_{ije})$$ \\(V_{ij}\\) - Variance used denominator Fleming-Harrington weighted logrank tests $$V_i = \\sum_{j=1}^{d_{}} (S_{ij}^\\rho(1-S_{ij}^\\gamma))^2V_{ij})$$ stratified Fleming-Harrington weighted logrank test computed : $$z = \\sum_i X_i/\\sqrt{\\sum_i V_i}.$$","code":""},{"path":"https://merck.github.io/simtrial/reference/wlr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fleming-Harrington weighted logrank tests — wlr","text":"","code":"library(tidyr)  # Use default enrollment and event rates at cut at 100 events x <- sim_pw_surv(n = 200) %>%   cut_data_by_event(100) %>%   counting_process(arm = \"experimental\")  # Compute logrank (FH(0,0)) and FH(0,1) wlr(x, rho_gamma = tibble(rho = c(0, 0), gamma = c(0, 1))) #> # A tibble: 2 × 3 #>     rho gamma     z #>   <dbl> <dbl> <dbl> #> 1     0     0 -1.66 #> 2     0     1 -1.22"},{"path":"https://merck.github.io/simtrial/news/index.html","id":"simtrial-020-august-2020","dir":"Changelog","previous_headings":"","what":"simtrial 0.2.0, August, 2020","title":"simtrial 0.2.0, August, 2020","text":"Updated vignettes web site Prepared Regulatory/Industry Training session September","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"simtrial-0179004-february-2020","dir":"Changelog","previous_headings":"","what":"simtrial 0.1.7.9004, February, 2020","title":"simtrial 0.1.7.9004, February, 2020","text":"Added wMB() compute Magirr-Burman weights Added vignette demonstrate working different weighting schemes Replaced Depends Imports DESCRIPTION","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"simtrial-0179003-november-2019","dir":"Changelog","previous_headings":"","what":"simtrial 0.1.7.9003, November, 2019","title":"simtrial 0.1.7.9003, November, 2019","text":"Incorporated new functions simplify use (simfix, simfix2simPWSurv, pMaxCombo) Removed hgraph intent put release gsDesign Limited 2 essential vignettes Added continuous integration/continuous deployment (yaml) pkgdown web site development Limited dependencies essential; removed convenience functions related core package functionality","code":""}]
