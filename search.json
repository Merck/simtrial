[{"path":"https://merck.github.io/simtrial/articles/discrepancy-between-simtrial-and-survival.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Note on potential discrepancies between simtrial and survdiff","text":"survival (base R) package, log-rank Cox estimation procedures apply (default) correction “fix” roundoff errors. implemented timefix option (default timefix = TRUE) via aeqSurv() function. However, simtrial package, (also Hmisc), correction implemented; Consequently, can discrepancies simtrial base R survival (survdiff(), coxph(), survfit()). details aeqSurv() function, see Therneau, 2016 ?aeqSurv function documentation. following, describe simulation scenario discrepancy generated illustrate discrepancies can resolved (desired) pre-processing survival times aeqSurv() thus replicating survdiff() coxph() default calculations. simulated dataset, two observations generated: Observation \\(=464\\) survival time \\(Y=0.306132722582\\). Observation \\(=516\\) survival time \\(Y=0.306132604679\\). Per aeqSurv(), times tied set \\(Y=0.306132604679\\). log-rank Cox estimates can therefore differ approaches without “timefix” correction.","code":"library(gsDesign) library(gsDesign2) library(dplyr) library(gt) library(simtrial) library(tidyr) library(survival)"},{"path":"https://merck.github.io/simtrial/articles/discrepancy-between-simtrial-and-survival.html","id":"scenario-definitions","dir":"Articles","previous_headings":"","what":"Scenario definitions","title":"Note on potential discrepancies between simtrial and survdiff","text":"define various true data generating model scenarios convert use gsDesign2. , using single scenario discrepancies found. just illustration inform user simtrial discrepancies can occur resolve via aeqSurv(), desired.","code":"survival_at_24_months <- 0.35 hr <- log(.35) / log(.25) control_median <- 12 control_rate <- c(log(2) / control_median, (log(.25) - log(.2)) / 12)  scenarios <- tribble(   ~Scenario, ~Name,           ~Period, ~duration, ~Survival,   0,         \"Control\",       0,       0,         1,   0,         \"Control\",       1,       24,        .25,   0,         \"Control\",       2,       12,        .2,   1,         \"PH\",            0,       0,         1,   1,         \"PH\",            1,       24,        .35,   1,         \"PH\",            2,       12,        .2^hr,   2,         \"3-month delay\", 0,       0,         1,   2,         \"3-month delay\", 1,       3,         exp(-3 * control_rate[1]),   2,         \"3-month delay\", 2,       21,        .35,   2,         \"3-month delay\", 3,       12,        .2^hr,   3,         \"6-month delay\", 0,       0,         1,   3,         \"6-month delay\", 1,       6,         exp(-6 * control_rate[1]),   3,         \"6-month delay\", 2,       18,        .35,   3,         \"6-month delay\", 3,       12,        .2^hr,   4,         \"Crossing\",      0,       0,         1,   4,         \"Crossing\",      1,       3,         exp(-3 * control_rate[1] * 1.3),   4,         \"Crossing\",      2,       21,        .35,   4,         \"Crossing\",      3,       12,        .2^hr,   5,         \"Weak null\",     0,       0,         1,   5,         \"Weak null\",     1,       24,        .25,   5,         \"Weak null\",     2,       12,        .2,   6,         \"Strong null\",   0,       0,         1,   6,         \"Strong null\",   1,       3,         exp(-3 * control_rate[1] * 1.5),   6,         \"Strong null\",   2,       3,         exp(-6 * control_rate[1]),   6,         \"Strong null\",   3,       18,        .25,   6,         \"Strong null\",   4,       12,        .2, ) # scenarios |> gt() fr <- scenarios |>   group_by(Scenario) |>   #  filter(Scenario == 2) |>   mutate(     Month = cumsum(duration),     x_rate = -(log(Survival) - log(lag(Survival, default = 1))) /       duration,     rate = ifelse(Month > 24, control_rate[2], control_rate[1]),     hr = x_rate / rate   ) |>   select(-x_rate) |>   filter(Period > 0, Scenario > 0) |>   ungroup() # fr |> gt() |> fmt_number(columns = everything(), decimals = 2)  fr <- fr |> mutate(fail_rate = rate, dropout_rate = 0.001, stratum = \"All\")  # MWLR mwlr <- fixed_design_mb(   tau = 12,   enroll_rate = define_enroll_rate(duration = 12, rate = 1),   fail_rate = fr |> filter(Scenario == 2),   alpha = 0.025, power = .85, ratio = 1,   study_duration = 36 ) |> to_integer()  er <- mwlr$enroll_rate"},{"path":"https://merck.github.io/simtrial/articles/discrepancy-between-simtrial-and-survival.html","id":"a-scenario-that-generates-a-discrepancy","dir":"Articles","previous_headings":"","what":"A scenario that generates a discrepancy","title":"Note on potential discrepancies between simtrial and survdiff","text":"Simulated dataset discrepancy logrank test simtrial::wlr() survdiff() (also compare score test coxph() [survdiff() default timefix = TRUE]). Verify timefix = FALSE coxph() agrees wlr(): Pre-processing survival times aeqSurv() implement timefix = TRUE procedure. Verify wlr() survdiff() now agree. differ (tte2 times aeqSurv())? Verify coxph() (default) coxph() aeqSurv() pre-processing (using tte2 outcome setting timefix = FALSE) identical: Also note ties impact separate arms. difference tte tte2 times, impact ties Cox \"breslow\" \"efron\" ties (single tie tte2) separate arms. Lastly, artificially change treatment two observations tied within treatment arm generates difference \"breslow\" \"efron\" options ties: ","code":"set.seed(3219)  dgm <- fr[c(14:17), ]  fail_rate <- data.frame(   stratum = rep(\"All\", 2 * nrow(dgm)),   period = rep(dgm$Period, 2),   treatment = c(     rep(\"control\", nrow(dgm)),     rep(\"experimental\", nrow(dgm))   ),   duration = rep(dgm$duration, 2),   rate = c(dgm$rate, dgm$rate * dgm$hr) )  dgm$stratum <- \"All\" # Constant dropout rate for both treatment arms and all scenarios dropout_rate <- data.frame(   stratum = rep(\"All\", 2),   period = rep(1, 2),   treatment = c(\"control\", \"experimental\"),   duration = rep(100, 2),   rate = rep(.001, 2) ) ss <- 395  set.seed(8316951 + ss * 1000)  # Generate a dataset dat <- sim_pw_surv(   n = 698,   enroll_rate = er,   fail_rate = fail_rate,   dropout_rate = dropout_rate )  analysis_data <- cut_data_by_date(dat, 36)  dfa <- analysis_data  dfa$treat <- ifelse(dfa$treatment == \"experimental\", 1, 0)  z1 <- dfa |> wlr(weight = fh(rho = 0, gamma = 0))  check <- survdiff(Surv(tte, event) ~ treat, data = dfa)  # Note, for `coxph()`, use # cph.score <- summary(coxph(Surv(tte, event) ~ treat, data = dfa, control = coxph.control(timefix = TRUE)))$sctest  cat(\"Log-rank wlr() vs survdiff()\", c(z1$z^2, check$chisq), \"\\n\") ## Log-rank wlr() vs survdiff() 0.1577428 0.1577954 cph.score <- summary(coxph(   Surv(tte, event) ~ treat,   data = dfa,   control = coxph.control(timefix = FALSE) ))$sctest cat(\"Log-rank wlr() vs Cox score z^2\", c(z1$z^2, cph.score[\"test\"]), \"\\n\") ## Log-rank wlr() vs Cox score z^2 0.1577428 0.1577428 Y <- dfa[, \"tte\"] Delta <- dfa[, \"event\"]  tfixed <- aeqSurv(Surv(Y, Delta)) Y <- tfixed[, \"time\"] Delta <- tfixed[, \"status\"] # Use aeqSurv version dfa$tte2 <- Y dfa$event2 <- Delta  # wlr() after \"timefix\" dfa2 <- dfa dfa2$tte <- dfa2$tte2 dfa2$event <- dfa2$event2 z1new <- dfa2 |> wlr(weight = fh(rho = 0, gamma = 0)) cat(\"Log-rank wlr() with timefix vs survdiff() z^2\", c(z1new$z^2, check$chisq), \"\\n\") ## Log-rank wlr() with timefix vs survdiff() z^2 0.1577954 0.1577954 dfa <- dfa[order(dfa$tte2), ]  id <- seq(1, nrow(dfa))  diff <- exp(dfa$tte) - exp(dfa$tte2) id_diff <- which(abs(diff) > 0)  tolook <- seq(id_diff - 2, id_diff + 2)  dfcheck <- dfa[tolook, c(\"tte\", \"tte2\", \"event\", \"event2\", \"treatment\")] print(dfcheck, digits = 12) ##                tte           tte2 event event2    treatment ## 13  0.276251560170 0.276251560170     1      1 experimental ## 143 0.298789385712 0.298789385712     1      1      control ## 464 0.306132722582 0.306132604679     1      1      control ## 516 0.306132604679 0.306132604679     1      1 experimental ## 605 0.336489970678 0.336489970678     1      1 experimental # Check Cox with ties cox_breslow <- summary(coxph(Surv(tte, event) ~ treatment, data = dfa, ties = \"breslow\"))$conf.int cox_efron <- summary(coxph(Surv(tte, event) ~ treatment, data = dfa, ties = \"efron\"))$conf.int cat(\"Cox Breslow and Efron hr (tte, timefix=TRUE):\", c(cox_breslow[1], cox_efron[1]), \"\\n\") ## Cox Breslow and Efron hr (tte, timefix=TRUE): 0.9657106 0.9657106 # Here ties do not have impact because in separate arms cox_breslow <- summary(coxph(Surv(tte2, event2) ~ treatment, data = dfa, ties = \"breslow\", control = coxph.control(timefix = FALSE)))$conf.int cox_efron <- summary(coxph(Surv(tte2, event2) ~ treatment, data = dfa, ties = \"efron\", control = coxph.control(timefix = FALSE)))$conf.int cat(\"Cox Breslow and Efron hr (tte2, timefix=FALSE):\", c(cox_breslow[1], cox_efron[1]), \"\\n\") ## Cox Breslow and Efron hr (tte2, timefix=FALSE): 0.9657106 0.9657106 # Create tie within treatment arm by changing treatment dfa3 <- dfa dfa3[19, \"treat\"] <- 1.0  cox_breslow <- summary(coxph(Surv(tte, event) ~ treat, data = dfa3, ties = \"breslow\", control = coxph.control(timefix = TRUE)))$conf.int cox_efron <- summary(coxph(Surv(tte, event) ~ treat, data = dfa3, ties = \"efron\", control = coxph.control(timefix = TRUE)))$conf.int cat(\"Cox Breslow and Efron hr (tte, timefix=TRUE)=\", c(cox_breslow[1], cox_efron[1]), \"\\n\") ## Cox Breslow and Efron hr (tte, timefix=TRUE)= 0.9729723 0.9729778 cox_breslow <- summary(coxph(Surv(tte2, event2) ~ treat, data = dfa3, ties = \"breslow\", control = coxph.control(timefix = FALSE)))$conf.int cox_efron <- summary(coxph(Surv(tte2, event2) ~ treat, data = dfa3, ties = \"efron\", control = coxph.control(timefix = FALSE)))$conf.int cat(\"Cox Breslow and Efron hr (tte2, timefix=FALSE)=\", c(cox_breslow[1], cox_efron[1]), \"\\n\") ## Cox Breslow and Efron hr (tte2, timefix=FALSE)= 0.9729723 0.9729778"},{"path":"https://merck.github.io/simtrial/articles/maxcombo.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Computing p-values for Fleming-Harrington weighted logrank tests and the MaxCombo test","text":"vignette demonstrates use simple routine simulations testing using Fleming-Harrington weighted logrank tests MaxCombo test. addition, demonstrate perform tests dataset generated simulation routines within package. Note \\(p\\)-values computed one-sided small values indicating experimental treatment favored.","code":""},{"path":"https://merck.github.io/simtrial/articles/maxcombo.html","id":"defining-the-test","dir":"Articles","previous_headings":"","what":"Defining the test","title":"Computing p-values for Fleming-Harrington weighted logrank tests and the MaxCombo test","text":"MaxCombo test posed maximum multiple Fleming-Harrington weighted logrank tests (Harrington Fleming (1982), Fleming Harrington (2011)). Combination tests looking maximum selected tests class also proposed; see Lee (2007), Roychoudhury et al. (2021), Lin et al. (2020). Fleming-Harrington class indexed parameters \\(\\rho \\geq 0\\) \\(\\gamma \\geq 0\\). denote FH(\\(\\rho, \\gamma\\)). class includes logrank test FH(0, 0). tests interest include: FH(0, 1): test -weights early events FH(1, 0): test -weights late events FH(1, 1): test -weights events increasingly quantiles differ median","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/articles/maxcombo.html","id":"generating-test-statistics-with-sim_fixed_n","dir":"Articles","previous_headings":"Executing for a single dataset","what":"Generating test statistics with sim_fixed_n()","title":"Computing p-values for Fleming-Harrington weighted logrank tests and the MaxCombo test","text":"begin single trial simulation generated routine sim_fixed_n() using default arguments routine. sim_fixed_n() produces one record per test data cutoff method per simulation. choose 3 tests (logrank = FH(0, 0), FH(0, 1) FH(1, 1)). one test chosen correlation tests computed shown Karrison (2016), case columns V1, V2, V3. columns rho, gamma indicate \\(\\rho\\) \\(\\gamma\\) used compute test. z FH(\\(\\rho, \\gamma\\)) normal test statistic variance 1 negative value favoring experimental treatment. variable cut indicates data cut analysis, case maximum targeted minimum follow-last enrollment date targeted event count reached. Sim sequential index simulations performed.","code":"library(simtrial) library(knitr) library(dplyr) library(gt) set.seed(123)  x <- sim_fixed_n(   n_sim = 1,   timing_type = 5,   rho_gamma = data.frame(rho = c(0, 0, 1), gamma = c(0, 1, 1)) ) #> Backend uses sequential processing.  x |>   gt() |>   fmt_number(columns = c(\"ln_hr\", \"z\", \"duration\", \"v1\", \"v2\", \"v3\"), decimals = 2)"},{"path":"https://merck.github.io/simtrial/articles/maxcombo.html","id":"generating-data-with-sim_pw_surv","dir":"Articles","previous_headings":"Executing for a single dataset","what":"Generating data with sim_pw_surv()","title":"Computing p-values for Fleming-Harrington weighted logrank tests and the MaxCombo test","text":"begin another simulation generated sim_pw_surv(). , use defaults routine. generated, need cut data analysis. cut 75 events. Now can analyze data. begin s show can done single line. case, use 4 test combination suggested Lin et al. (2020), Roychoudhury et al. (2021). Suppose want \\(p\\)-value just based logrank FH(0, 1) FH(1, 0) suggested Lee (2007). remove rows columns associated FH(0, 0) FH(1, 1) apply pvalue_maxcombo().","code":"set.seed(123)  s <- sim_pw_surv(n = 100)  s |>   head() |>   gt() |>   fmt_number(columns = c(\"enroll_time\", \"fail_time\", \"dropout_time\", \"cte\"), decimals = 2) x <- s |> cut_data_by_event(75)  x |>   head() |>   gt() |>   fmt_number(columns = \"tte\", decimals = 2) z <- s |>   cut_data_by_event(75) |>   maxcombo(rho = c(0, 0, 1, 1), gamma = c(0, 1, 0, 1))  z #> $method #> [1] \"MaxCombo\" #>  #> $parameter #> [1] \"FH(0, 0) + FH(0, 1) + FH(1, 0) + FH(1, 1)\" #>  #> $z #> [1] -2.511925 -2.907093 -1.899871 -3.119549 #>  #> $p_value #> [1] 0.00204688 z <- s |>   cut_data_by_event(75) |>   maxcombo(rho = c(0, 1), gamma = c(1, 0))  z #> $method #> [1] \"MaxCombo\" #>  #> $parameter #> [1] \"FH(0, 1) + FH(1, 0)\" #>  #> $z #> [1] -2.907093 -1.899871 #>  #> $p_value #> [1] 0.003395849"},{"path":"https://merck.github.io/simtrial/articles/maxcombo.html","id":"using-survival-data-in-another-format","dir":"Articles","previous_headings":"Executing for a single dataset","what":"Using survival data in another format","title":"Computing p-values for Fleming-Harrington weighted logrank tests and the MaxCombo test","text":"trial generated sim_fixed_n(), process slightly involved. consider survival data simtrial format show transformation needed. case use small aml dataset survival package. rename variables create stratum variable follows: Now analyze data MaxCombo logrank FH(0, 1) compute \\(p\\)-value.","code":"library(survival) aml |>   head() |>   gt() x <- aml |> transmute(   tte = time,   event = status,   stratum = \"All\",   treatment = case_when(     x == \"Maintained\" ~ \"experimental\",     x == \"Nonmaintained\" ~ \"control\"   ) )  x |>   head() |>   gt() x |> maxcombo(rho = c(0, 0), gamma = c(0, 1)) #> $method #> [1] \"MaxCombo\" #>  #> $parameter #> [1] \"FH(0, 0) + FH(0, 1)\" #>  #> $z #> [1] -1.842929 -1.621762 #>  #> $p_value #> [1] 0.0491509"},{"path":"https://merck.github.io/simtrial/articles/maxcombo.html","id":"simulation","dir":"Articles","previous_headings":"","what":"Simulation","title":"Computing p-values for Fleming-Harrington weighted logrank tests and the MaxCombo test","text":"now consider example simulation pvalue_maxcombo() help file demonstrate simulate power MaxCombo test. However, increase number simulations 100 case; larger number used (e.g., 1000) better estimate design properties. test \\(\\alpha=0.001\\) level. note use group_map produces list \\(p\\)-values simulation. nice something worked like dplyr::summarize() avoid unlist() allow evaluating, say, multiple data cutoff methods. latter can done without re-run simulations follows, demonstrated smaller number simulations. Now compute \\(p\\)-value separately cut type, first targeted event count. Now use later targeted events minimum follow-cutoffs.","code":"set.seed(123)  # Only use cut events + min follow-up x <- sim_fixed_n(   n_sim = 100,   timing_type = 5,   rho_gamma = data.frame(rho = c(0, 0, 1), gamma = c(0, 1, 1)) )  # MaxCombo power estimate for cutoff at max of targeted events, minimum follow-up x |>   group_by(sim) |>   filter(row_number() == 1) |>   ungroup() |>   summarize(power = mean(p_value < .001)) #> # A tibble: 1 × 1 #>   power #>   <dbl> #> 1  0.79 # Only use cuts for events and events + min follow-up set.seed(123)  x <- sim_fixed_n(   n_sim = 100,   timing_type = c(2, 5),   rho_gamma = data.frame(rho = 0, gamma = c(0, 1)) ) # Subset to targeted events cutoff tests # This chunk will be updated after the development of sim_gs_n and sim_fixed_n x |>   filter(cut == \"Targeted events\") |>   group_by(sim) |>   filter(row_number() == 1) |>   ungroup() |>   summarize(power = mean(p_value < .025)) #> # A tibble: 1 × 1 #>   power #>   <dbl> #> 1  0.95 # Subset to targeted events cutoff tests x |>   filter(cut != \"Targeted events\") |>   group_by(sim) |>   filter(row_number() == 1) |>   ungroup() |>   summarize(power = mean(p_value < .025)) #> # A tibble: 1 × 1 #>   power #>   <dbl> #> 1  0.95"},{"path":[]},{"path":"https://merck.github.io/simtrial/articles/modest-wlrt.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using the Magirr-Burman weights for testing","text":"Magirr Burman (2019) implemented modestly weighted logrank test following claim: Tests new class can constructed high power delayed-onset treatment effect scenario, well almost efficient standard logrank test proportional hazards. implemented package modestWLRT. Since implementation relatively straightforward, added functionality simtrial package explain use mb_weight() function. Packages used follows:","code":"library(simtrial) library(dplyr) library(survival)"},{"path":"https://merck.github.io/simtrial/articles/modest-wlrt.html","id":"simulating-a-delayed-effect-example","dir":"Articles","previous_headings":"","what":"Simulating a delayed effect example","title":"Using the Magirr-Burman weights for testing","text":"First, specify study duration, sample size enrollment rates. enrollment rate assumed constant enrollment period targeted sample size reached. failure rates, consider delayed treatment effect example Magirr Burman (2019). control group exponential failure rate median 15 months. initial 6 months, underlying hazard ratio one followed hazard ratio 0.7 thereafter. differs Magirr Burman (2019) delayed effect assumptions assume hazard ratio 0.5 6 months. Now generate single dataset characteristics cut data analysis 36 months post start enrollment. plot Kaplan-Meier curves resulting dataset (red curve experimental treatment, black control):","code":"study_duration <- 36 sample_size <- 300 enroll_rate <- data.frame(duration = 12, rate = 200 / 12) fail_rate <- data.frame(   stratum = c(\"All\", \"All\"),   duration = c(6, 36),   fail_rate = c(log(2) / 15, log(2) / 15),   hr = c(1, .7),   dropout_rate = c(0, 0) ) set.seed(7789) xpar <- to_sim_pw_surv(fail_rate) MBdelay <- sim_pw_surv(   n = sample_size,   stratum = data.frame(stratum = \"All\", p = 1),   block = c(rep(\"control\", 2), rep(\"experimental\", 2)),   enroll_rate = enroll_rate,   fail_rate = xpar$fail_rate,   dropout_rate = xpar$dropout_rate ) |>   cut_data_by_date(study_duration) fit <- survfit(Surv(tte, event) ~ treatment, data = MBdelay) plot(fit, col = 1:2, mark = \"|\", xaxt = \"n\") axis(1, xaxp = c(0, 36, 6))"},{"path":"https://merck.github.io/simtrial/articles/modest-wlrt.html","id":"generalizing-the-magirr-burman-test","dir":"Articles","previous_headings":"","what":"Generalizing the Magirr-Burman test","title":"Using the Magirr-Burman weights for testing","text":"Next, consider Magirr (2021) extension modestly weighted logrank test (MWLRT) Magirr Burman (2019) weights follows: \\[w(t, \\tau, w_{\\max}) = \\min\\left(w_{\\max},\\left(\\frac{1}{S(\\min(t,\\tau))}\\right)\\right).\\] requires generating weights computing test. begin default w_max=Inf corresponds original Magirr Burman (2019) test set time maximum weight \\(\\tau\\) delay = 6. Now set maximum weight 2 Magirr (2021) set delay=Inf maximum weight begins observed median observed combined treatment Kaplan-Meier curve. Another way can done generalized Fleming-Harrington test \\[w(t; \\rho, \\gamma, w_{\\max})= \\min((1-F(t))^\\rho F(t)^\\gamma, w_{\\max})).\\] let \\(\\gamma=0, \\rho = -1/2.\\)","code":"ZMB <- MBdelay |>   wlr(weight = mb(delay = 6)) # Compute p-value of modestly weighted logrank of Magirr-Burman pnorm(ZMB$z, lower.tail = FALSE) #> [1] 0.1395378 ZMB <- MBdelay |>   wlr(weight = mb(delay = Inf, w_max = 2)) # Compute p-value of modestly weighted logrank of Magirr-Burman pnorm(ZMB$z, lower.tail = FALSE) #> [1] 0.1387672 w_max <- 2 Z_modified_FH <- MBdelay |>   counting_process(arm = \"experimental\") |>   mutate(w = pmin(w_max, 1 / s)) |>   summarize(     S = sum(o_minus_e * w),     V = sum(var_o_minus_e * w^2),     z = S / sqrt(V)   ) # Compute p-value of modestly weighted logrank of Magirr-Burman pnorm(Z_modified_FH$z) #> [1] 0.1387672"},{"path":"https://merck.github.io/simtrial/articles/modest-wlrt.html","id":"freidlin-and-korn-strong-null-hypothesis-example","dir":"Articles","previous_headings":"Generalizing the Magirr-Burman test","what":"Freidlin and Korn strong null hypothesis example","title":"Using the Magirr-Burman weights for testing","text":"next example, underlying survival uniformly worse experimental group compared control throughout planned follow-. presented Freidlin Korn (2019). case, hazard ratio 16 1/10 1 year (1.2 months), followed hazard ratio 0.76 thereafter. First, specify study duration, sample size enrollment rates. enrollment rate assumed constant enrollment period targeted sample size reached. failure rates, consider delayed treatment effect example Magirr Burman (2019). Now generate single dataset characteristics cut data analysis 5 years post start enrollment. plot Kaplan-Meier curves resulting dataset (red curve experimental treatment, black control):  perform logrank weighted logrank tests suggested limited downweighting follows, MaxCombo test component tests, p-value : Next, consider Magirr Burman (2019) modestly weighted logrank test -weighting specified first 6 months maximum weight 2. requires generating weights computing test. Finally, consider weighted logrank tests less -weighting. Results quite similar results greater -weighting. p-value Thus, less -weighting MaxCombo test appears less problematic. addressed greater length Mukhopadhyay et al. (2022).","code":"study_duration <- 5 sample_size <- 2000 enroll_duration <- .0001 enroll_rate <- data.frame(   duration = enroll_duration,   rate = sample_size / enroll_duration ) fail_rate <- data.frame(   stratum = \"All\",   fail_rate = 0.25,   dropout_rate = 0,   hr = c(4 / .25, .19 / .25),   duration = c(.1, 4.9) ) set.seed(7783) xpar <- to_sim_pw_surv(fail_rate) FHwn <- sim_pw_surv(   n = sample_size,   stratum = data.frame(stratum = \"All\", p = 1),   block = c(rep(\"control\", 2), rep(\"experimental\", 2)),   enroll_rate = enroll_rate,   fail_rate = xpar$fail_rate,   dropout_rate = xpar$dropout_rate ) |>   cut_data_by_date(study_duration) fit <- survfit(Surv(tte, event) ~ treatment, data = FHwn) plot(fit, col = 1:2, mark = \"|\", xaxt = \"n\") axis(1, xaxp = c(0, 36, 6)) xx <- FHwn |>   maxcombo(rho = c(0, 0, 1), gamma = c(0, 1, 1)) xx #> $method #> [1] \"MaxCombo\" #>  #> $parameter #> [1] \"FH(0, 0) + FH(0, 1) + FH(1, 1)\" #>  #> $z #> [1]  4.808526 -3.204735 -1.220445 #>  #> $p_value #> [1] 0.001256683 ZMB <- FHwn |>   wlr(weight = mb(delay = 6, w_max = 2))  # Compute p-value of modestly weighted logrank of Magirr-Burman pnorm(ZMB$z, lower.tail = FALSE) #> [1] 0.920727 xx <- FHwn |>   maxcombo(rho = c(0, 0, .5), gamma = c(0, .5, .5)) xx #> $method #> [1] \"MaxCombo\" #>  #> $parameter #> [1] \"FH(0, 0) + FH(0, 0.5) + FH(0.5, 0.5)\" #>  #> $z #> [1]  4.8085258 -0.6919228  0.9278452 #>  #> $p_value #> [1] 0.2915952"},{"path":[]},{"path":"https://merck.github.io/simtrial/articles/parallel.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Simulating time-to-event trials in parallel","text":"vignette demonstrates ability implement sim_fixed_n() using user-defined backends parallelize simulations. consider backends supported future framework. backends supported future package include: sequential - default non-parallel backend. multisession - uses multiple background R sessions single machine. multicore - uses multiple forked R processes single non-Windows machine outside RStudio. cluster - supports external R sessions across multiple machines. can also choose backend types supported additional future extension packages, HPC job scheduler backends future.batchtools. function sim_fixed_n() provides simulation workflow two-arm trial single endpoint. can vary parameters trial using different functions outlined documentation. function now provides users opportunity implement simulations using previously described parallel backends accelerate computation. function sim_gs_n() simulates group sequential designs fixed sample size also supports use user-defined backends parallelize simulations similar manner.","code":""},{"path":"https://merck.github.io/simtrial/articles/parallel.html","id":"background","dir":"Articles","previous_headings":"","what":"Background","title":"Simulating time-to-event trials in parallel","text":"Without specifying backend, sim_fixed_n() execute sequentially. sequential execution run n_sim iterations within process session R. order execute parallel, must define environment prior calling function. Setting seed prior calling function ensure results reproducible. Suppose want investigate duration trial two possible enrollments strategies. enrollments piecewise, varying durations rates.  see Enrollment 2 enrolls individuals quickly Enrollment 1 onset. Later, Enrollment 1 outpace Enrollment 2 eventually overtaken . , want consider duration study changes enrollments.","code":"library(simtrial) library(future) library(doFuture) set.seed(1)  n <- 5000 enroll_rate1 <- data.frame(rate = c(5, 20, 10), duration = c(100, 150, 150)) enroll_rate2 <- data.frame(rate = c(10, 15, 30), duration = c(150, 175, 75)) x1 <- rpwexp_enroll(n = n, enroll_rate = enroll_rate1) x2 <- rpwexp_enroll(n = n, enroll_rate = enroll_rate2)  plot(   x1, 1:n,   type = \"l\",   col = palette()[4],   xlim = c(0, max(x1, x2)),   main = \"Piecewise enrollments\",   xlab = \"Time\",   ylab = \"Enrollment\" ) lines(x2, 1:n, col = palette()[7]) legend(   250, 1500,   legend = c(\"Enrollment 1\", \"Enrollment 2\"),   col = c(palette()[4], palette()[7]),   lty = c(1, 1) )"},{"path":"https://merck.github.io/simtrial/articles/parallel.html","id":"the-sequential-run","dir":"Articles","previous_headings":"","what":"The sequential run","title":"Simulating time-to-event trials in parallel","text":"Naively, can execute simulations sequentially. set target total enrollment 3000 individuals trial ending observing 700 events. use timing_type = 2 return correct trial duration. Note: manually set number threads used {data.table} operations 1. purely sake comparing runtime parallel run performed later vignette. running simulations sequentially, want {data.table} take advantage parallel processing. message automatically appears console indicates backend used processing. calls proc.time() allow us evaluate computation time procedures. function provides three outputs, focus user elapsed time. User time represents CPU time spent evaluating function elapsed time represents “wall clock” time spent end user waiting results. can see CPU time 10.48 elapsed time 10.57 seconds. provide baseline computation time. may anticipated, see lower number events, enrollment 2 shorter average duration 99.8 enrollment 1, 131.2.","code":"data.table::setDTthreads(threads = 1) set.seed(1)  n_sim <- 200  start_sequential <- proc.time()  seq_result1 <- sim_fixed_n(   n_sim = n_sim,   sample_size = 3000,   target_event = 700,   enroll_rate = enroll_rate1,   timing_type = 2 # Time until targeted event count achieved ) #> Backend uses sequential processing.  seq_result2 <- sim_fixed_n(   n_sim = n_sim,   sample_size = 3000,   target_event = 700,   enroll_rate = enroll_rate2,   timing_type = 2 # Time until targeted event count achieved ) #> Backend uses sequential processing.  duration_sequential <- proc.time() - start_sequential print(duration_sequential) #>    user  system elapsed  #>  10.485   0.079  10.565"},{"path":"https://merck.github.io/simtrial/articles/parallel.html","id":"setting-up-a-parallel-backend","dir":"Articles","previous_headings":"","what":"Setting up a parallel backend","title":"Simulating time-to-event trials in parallel","text":"increased number simulations enrollment, can expect time run simulations increase. Furthermore, vary increase number parameter inputs consider, expect simulation process continue increase duration. help combat growing computational burden, can run simulations parallel using multisession backend available us plan(). can adjust default number cores function parallelly::availableCores(). multisession backend automatically use available cores default, use two. initialize backend, change plan.","code":"plan(multisession, workers = 2)"},{"path":"https://merck.github.io/simtrial/articles/parallel.html","id":"execution-in-parallel","dir":"Articles","previous_headings":"","what":"Execution in parallel","title":"Simulating time-to-event trials in parallel","text":"configured backend details, can execute code automatically distribute n_sim simulations across available cores. Note: worry setting data.table::setDTthreads(threads = 1) parallel processes spawned sim_fixed_n() {data.table} “automatically switches single threaded mode upon fork” (?data.table::setDTthreads). 1 can see CPU time 2.21 elapsed time 9.07 seconds. user time appears drastically reduced R keeps track time; time used parent process children processes reported user time. Therefore, compare elapsed time see real-world impact parallelization. change implementation back sequential backend, simply use . can also verify simulation results identical setting seed backend type affect results. , clear results sequential multisession backends match completely. Note: parallel implementation may always faster serial implementation. substantial overhead associated executing parallel, sequential evaluation may faster. low number simulations available cores, may preferable continue computation serial rather parallel. leave end user determine difference based resources available .","code":"set.seed(1)  start_parallel <- proc.time()  par_result1 <- sim_fixed_n(   n_sim = n_sim,   sample_size = 3000,   target_event = 700,   enroll_rate = enroll_rate1,   timing_type = 2 # Time until targeted event count achieved ) #> Using 2 cores with backend multisession  par_result2 <- sim_fixed_n(   n_sim = n_sim,   sample_size = 3000,   target_event = 700,   enroll_rate = enroll_rate2,   timing_type = 2 # Time until targeted event count achieved ) #> Using 2 cores with backend multisession  duration_parallel <- proc.time() - start_parallel print(duration_parallel) #>    user  system elapsed  #>   2.213   0.028   9.069 plan(sequential) all.equal(seq_result1, par_result1) #> [1] TRUE all.equal(seq_result2, par_result2) #> [1] TRUE"},{"path":"https://merck.github.io/simtrial/articles/parallel.html","id":"a-nested-parallel-example","dir":"Articles","previous_headings":"","what":"A nested parallel example","title":"Simulating time-to-event trials in parallel","text":"provide additional example using nested parallel structure users extensive resources, high-performance computing clusters, available . resources commonly available, execute code herein. Consider two accessible nodes, three cores (shown diagram ). Available resource schematic. Ideally, available resources used executing simulations. , need correctly define backend using plan() run code previously. different structures, topologies, backend can changed depth explanation given future topologies vignette. example follows closely example. snippet, consider two nodes named n1 n2 create function select number cores use named nodes. trivial , courteous user shared machines specify fewer available cores can using modification code. implement backend using list follows hierarchy available resources. function tweak() necessary override inherent protection nested parallelism, meant help avoid overloading one’s resources errantly starting many processes. need tweak backends, message echoed console nested backends reflects highest level nested hierarchy. backend place, can run identical code using available resources return results . , reset plan sequential avoid accidentally continuing execute later calls within resources.","code":"nodes <- c(\"n1\", \"n2\") custom_cores <- function() {   switch(Sys.info()[[\"nodename\"]],     \"n1\" = 3L, # Modify here for number of cores on node1     \"n2\" = 3L, # Modify here for number of cores on node2     ## Default:     availableCores()   ) } plan(list(   tweak(cluster, workers = nodes),   tweak(multisession, workers = custom_cores) )) set.seed(1)  enroll_rates <- list(enroll_rate1, enroll_rate2)  nested_result <- foreach::foreach(   i = 1:2,   .combine = \"list\",   .options.future = list(seed = TRUE) ) %dofuture% {   sim_fixed_n(     n_sim = n_sim,     sample_size = 3000,     target_event = 700,     enroll_rate = enroll_rates[[i]],     timing_type = 2 # Time until targeted event count achieved   ) } plan(sequential)"},{"path":"https://merck.github.io/simtrial/articles/rmst.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Restricted mean survival time (RMST)","text":"Restricted mean survival time (RMST) defined area survival curve specific time point. can interpreted average survival time defined time period ranging time 0 specific follow-time point, straightforward clinically meaningful way interpret contrast survival groups. RMST may provide valuable information comparing two survival curves proportional hazards assumption met, cases crossing delayed separation survival curves.","code":""},{"path":"https://merck.github.io/simtrial/articles/rmst.html","id":"rmst-vs--logrank","dir":"Articles","previous_headings":"","what":"RMST vs. logrank","title":"Restricted mean survival time (RMST)","text":"log-rank test calculates test statistics using survival rate time point, summarizes test equality survival curves whole entire follow-period. comparison RMST two survival curves provides estimate duration time gained lost associated exposure. Although RMST advantage hazard ratio, previous study showed difference RMST often operating characteristics similar log-rank test proportional hazards assumption (Royston Parmar 2013). However, case crossing survival curves, efficacy intervention may demonstrated showing difference RMST two curves, although log-rank test may fail detect difference occurrence non-proportional hazards.","code":""},{"path":"https://merck.github.io/simtrial/articles/rmst.html","id":"estimation-of-rmst-in-a-single-arm-at-a-single-time-point","dir":"Articles","previous_headings":"","what":"Estimation of RMST in a single arm at a single time point","title":"Restricted mean survival time (RMST)","text":"Assume event time \\(T\\), survival function \\(S(t) = Pr(T>t)\\). restricted mean survival time pre-specified cutoff time point \\(\\tau\\) \\[   \\text{RMST}(\\tau) = E[\\min (T, \\tau)] = \\int_{0}^{\\tau} S(u) d u. \\] Suppose \\(D\\) events, distinct observed event times \\(t_1 < t_2 < \\ldots <t_D\\). \\(= 1, \\ldots, D\\), let \\(Y_i\\) number risk just prior \\(t_i\\), let \\(d_i\\) number subjects fail \\(t_i\\). Kaplan-Meier (product-limit) estimate survival function \\(t_i\\) \\[   \\hat{S}(t_i)   =   \\prod_{j=1}^{}   \\left(     1-\\frac{d_{j}}{Y_{j}}   \\right) \\] Based definition formula , \\(\\text{RMST}(\\tau)\\) can estimated \\[   \\widehat{\\text{RMST}}(\\tau)   =   \\int_{0}^{\\tau} \\hat{S}(t) d t   =   \\sum_{=1}^{L_{\\tau}} \\hat{S}\\left(t_{-1}\\right)\\left(t_{}-t_{-1}\\right)   +   \\hat{S}\\left(t_{L_{\\tau}}\\right)\\left(\\tau-t_{L_{\\tau}}\\right), \\] \\(L_{\\tau}\\) number \\(t_i\\) values less \\(\\tau\\). standard error \\(\\widehat{\\text{RMST}}(\\tau)\\) can estimated \\[   \\hat{\\sigma}   =   \\widehat{\\text{Var}}(\\widehat{\\text{RMST}}(\\tau))   =   \\sqrt{\\sum_{=1}^{L_\\tau}   \\frac{d_{} A_{}^{2}}{Y_{}\\left(Y_{}-d_{}\\right)}} \\] \\[   A_{}   =   \\int_{t_i}^{\\tau} \\hat{S}(t) d t   =   \\sum_{j=}^{L_\\tau}   \\hat{S}(t_{j}) (t_{j+1}-t_{j})   +   \\hat{S}(t_{L_\\tau})(\\tau-t_{L_\\tau}) \\] \\(m=\\sum_{j=1}^{L_\\tau} d_{j}\\). \\((1-\\alpha)\\) confidence interval \\(\\text{RMST}\\) can calculated \\[   \\left[     \\widehat{\\operatorname{RMST}}(\\tau) - z_{\\alpha/2}\\hat{\\sigma},     \\;\\;     \\widehat{\\operatorname{RMST}}(\\tau) + z_{\\alpha/2}\\hat{\\sigma}   \\right] \\] \\(\\alpha\\) predefined significant level, \\(z_{\\alpha/2}\\) upper \\(1-\\alpha/2\\) critical value standard normal distribution.","code":"# Simulate NPH data from the piecewise model library(simtrial) # Table display library(gt) data(ex1_delayed_effect) data_single_arm <- ex1_delayed_effect[ex1_delayed_effect$trt == 1, ] simtrial:::rmst_single_arm(   time_var = data_single_arm$month,   event_var = data_single_arm$evntd,   tau = 10 ) |> gt()"},{"path":"https://merck.github.io/simtrial/articles/rmst.html","id":"estimation-of-rmst-differences-in-2-arms-at-a-single-time-point","dir":"Articles","previous_headings":"Estimation of RMST in a single arm at a single time point","what":"Estimation of RMST differences in 2 arms at a single time point","title":"Restricted mean survival time (RMST)","text":"Let \\(\\text{RMST}_{1}(\\tau)\\) \\(\\text{RMST}_{2}(\\tau)\\) RMST treatment group 1 2 predefined time \\(\\tau\\), RMST difference 2 treatment groups (\\(\\theta\\)) can defined \\[   \\theta = \\text{RMST}_1(\\tau) - \\text{RMST}_2(\\tau). \\] expected value \\(\\theta\\) \\(E(\\theta) = E[\\text{RMST}_{1}(\\tau)] - E[\\text{RMST}_{2}(\\tau)]\\). two treatment groups independent, variance \\(\\theta\\) \\[   \\text{Var}(\\theta) = \\sigma_{1}^{2} + \\sigma_{2}^{2} \\] Similarly, \\((1-\\alpha)\\) confidence interval RMST difference 2 groups can calculated : \\[   \\left[     \\hat{\\theta} - z_{\\alpha/2}\\sqrt{\\hat{\\sigma}_1^2 + \\hat{\\sigma}_2^2},     \\;\\;     \\hat{\\theta} + z_{\\alpha/2}\\sqrt{\\hat{\\sigma}_1^2 + \\hat{\\sigma}_2^2}   \\right]. \\] R package survRM2 (Uno et al. 2022) performs two-sample comparisons using RMST summary measure survival time distribution. Three kinds -group contrast metrics (.e., difference RMST, ratio RMST ratio restricted mean time lost (RMTL)) computed. performs ANCOVA-type covariate adjustment well unadjusted analyses measures. use R package validation simtrial::rmst().","code":"tau <- 10  data(ex1_delayed_effect)  ex1_delayed_effect |>   rmst(     var_label_tte = \"month\",     var_label_event = \"evntd\",     var_label_group = \"trt\",     tau = 10,     reference = \"0\"   ) #> $method #> [1] \"RMST\" #>  #> $parameter #> [1] 10 #>  #> $estimate #> [1] 0.8650493 #>  #> $se #> [1] 0.3900344 #>  #> $z #> [1] 2.21788 verify <- survRM2::rmst2(   time = ex1_delayed_effect$month,   status = ex1_delayed_effect$evntd,   arm = ex1_delayed_effect$trt,   tau = tau,   alpha = 0.05 )  verify$RMST.arm1$rmst[1] - verify$RMST.arm0$rmst[1] #>      Est.  #> 0.8650493"},{"path":[]},{"path":"https://merck.github.io/simtrial/articles/routines.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Basic tools for time-to-event trial simulation and testing","text":"vignette demonstrates lower-level routines simtrial package specifically related trial generation statistical testing. routines follows: randomize_by_fixed_block() - fixed block randomization rpwexp_enroll() - random inter-arrival times piecewise constant enrollment rates rpwexp() - piecewise exponential failure rate generation cut_data_by_date() - cut data analysis specified calendar time cut_data_by_event() - cut data analysis specified event count, including ties cutoff date get_cut_date_by_event() - find date event count reached counting_process() - pre-process survival data counting process format Application demonstrated using higher-level routines sim_pw_surv() sim_fixed_n() generate simulations weighted logrank analysis stratified design. intent write routines spirit tidyverse approach (alternately referred data wrangling, tidy data, R Data Science, split-apply-combine). objectives easily documentable validated package easy use efficient broadly-useful tool simulation time--event clinical trials. package extended many ways future, including: Weighted logrank weighted Kaplan-Meier analyses One-step, hazard ratio estimator (first-order approximation PH) Randomization schemes stratified, fixed-block Poisson mixture survival distribution generation","code":"library(simtrial) library(gt) library(dplyr)"},{"path":"https://merck.github.io/simtrial/articles/routines.html","id":"randomization","dir":"Articles","previous_headings":"","what":"Randomization","title":"Basic tools for time-to-event trial simulation and testing","text":"Fixed block randomization arbitrary block contents performed demonstrated . case block size 5 one string repeated twice block three strings appearing . normally, default blocks size four:","code":"randomize_by_fixed_block(n = 10, block = c(\"A\", \"Dog\", \"Cat\", \"Cat\")) #>  [1] \"A\"   \"Dog\" \"Cat\" \"Cat\" \"Dog\" \"Cat\" \"A\"   \"Cat\" \"Cat\" \"Dog\" randomize_by_fixed_block(n = 20) #>  [1] 0 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 0"},{"path":"https://merck.github.io/simtrial/articles/routines.html","id":"enrollment","dir":"Articles","previous_headings":"","what":"Enrollment","title":"Basic tools for time-to-event trial simulation and testing","text":"Piecewise constant enrollment can randomly generated follows. Note duration specifies interval durations constant rates; final rate extended long needed generate specified number observations.","code":"rpwexp_enroll(   n = 20,   enroll_rate = data.frame(     duration = c(1, 2),     rate = c(2, 5)   ) ) #>  [1] 0.4321713 1.1920483 1.3606775 1.4337998 1.9976912 2.2833587 2.3205687 #>  [8] 2.3603258 2.4128677 2.5312003 2.5393496 2.8971532 3.0539522 3.2447750 #> [15] 3.6015153 3.6141447 3.7810793 4.2056592 4.4276540 4.5577338"},{"path":"https://merck.github.io/simtrial/articles/routines.html","id":"time-to-event-and-time-to-dropout","dir":"Articles","previous_headings":"","what":"Time-to-event and time-to-dropout","title":"Basic tools for time-to-event trial simulation and testing","text":"Time--event time--dropout random number generation observations generated piecewise exponential failure times. large number observations, log-plot time--failure","code":"x <- rpwexp(   10000,   fail_rate = data.frame(     rate = c(1, 3, 10),     duration = c(.5, .5, 1)   ) ) plot(   sort(x),   (10000:1) / 10001,   log = \"y\",   main = \"PW Exponential simulated survival curve\",   xlab = \"Time\", ylab = \"P{Survival}\" )"},{"path":"https://merck.github.io/simtrial/articles/routines.html","id":"generating-a-trial","dir":"Articles","previous_headings":"","what":"Generating a trial","title":"Basic tools for time-to-event trial simulation and testing","text":"Ideally, might done routine generation randomization, time--event data done modular fashion plugged general trial generation routine. now, stratified randomization, piecewise constant enrollment, fixed block randomization piecewise exponential failure rates support flexible set trial generation options time--event endpoint trials. present, follow format carefully little checking input developed -date. methods used demonstrated , combined single routine generate trial. Note generated output dataset, cte calendar time event dropout, whichever comes first, fail indicator cte represents event time. First set input variables make later call sim_pw_surv() straightforward read.","code":"stratum <- data.frame(stratum = c(\"Negative\", \"Positive\"), p = c(.5, .5))  block <- c(rep(\"control\", 2), rep(\"experimental\", 2))  enroll_rate <- data.frame(rate = c(3, 6, 9), duration = c(3, 2, 1))  fail_rate <- data.frame(   stratum = c(rep(\"Negative\", 4), rep(\"Positive\", 4)),   period = rep(1:2, 4),   treatment = rep(c(rep(\"control\", 2), rep(\"experimental\", 2)), 2),   duration = rep(c(3, 1), 4),   rate = log(2) / c(4, 9, 4.5, 10, 4, 9, 8, 18) ) dropout_rate <- data.frame(   stratum = c(rep(\"Negative\", 4), rep(\"Positive\", 4)),   period = rep(1:2, 4),   treatment = rep(c(rep(\"control\", 2), rep(\"experimental\", 2)), 2),   duration = rep(c(3, 1), 4),   rate = rep(c(.001, .001), 4) ) x <- sim_pw_surv(   n = 400,   stratum = stratum,   block = block,   enroll_rate = enroll_rate,   fail_rate = fail_rate,   dropout_rate = dropout_rate )  head(x) |>   gt() |>   fmt_number(columns = c(\"enroll_time\", \"fail_time\", \"dropout_time\", \"cte\"), decimals = 2)"},{"path":"https://merck.github.io/simtrial/articles/routines.html","id":"cutting-data-for-analysis","dir":"Articles","previous_headings":"","what":"Cutting data for analysis","title":"Basic tools for time-to-event trial simulation and testing","text":"two ways cut data generated dataset x . first uses calendar cutoff date. output includes time randomization event dropout (tte), indicator represents event (event), stratum observation generated (stratum) treatment group assigned (treatment). Observations enrolled input cut_date deleted events censoring x cut_date censored specified cut_date. instance, wish cut entire dataset 50 events observed Positive stratum can use get_cut_date_by_event function follows: Perhaps common way cut data event count overall population, done using cut_data_by_event function. Note tied events date cte count reached, included. Also, count never reached, event times included cut - indication error.","code":"y <- cut_data_by_date(x, cut_date = 5)  head(y) |>   gt() |>   fmt_number(columns = \"tte\", decimals = 2) cut50Positive <- get_cut_date_by_event(filter(x, stratum == \"Positive\"), 50) y50Positive <- cut_data_by_date(x, cut50Positive)  with(y50Positive, table(stratum, event)) #>           event #> stratum     0  1 #>   Negative 41 53 #>   Positive 46 50 y150 <- cut_data_by_event(x, 150) table(y150$event, y150$treatment) #>     #>     control experimental #>   0      44           54 #>   1      80           70"},{"path":"https://merck.github.io/simtrial/articles/routines.html","id":"generating-a-counting-process-dataset","dir":"Articles","previous_headings":"","what":"Generating a counting process dataset","title":"Basic tools for time-to-event trial simulation and testing","text":"cut data analysis, can create dataset simple use weighted logrank tests. slightly complex version developed future enable Kaplan-Meier-based tests. take dataset y150 process format. counting process format discussed next section compute weighted logrank test.","code":"ten150 <- counting_process(y150, arm = \"experimental\")  head(ten150) |>   gt() |>   fmt_number(columns = c(\"tte\", \"o_minus_e\", \"var_o_minus_e\"), decimals = 2)"},{"path":"https://merck.github.io/simtrial/articles/routines.html","id":"logrank-and-weighted-logrank-testing","dir":"Articles","previous_headings":"","what":"Logrank and weighted logrank testing","title":"Basic tools for time-to-event trial simulation and testing","text":"Now stratified logrank stratified weighted logrank tests easily generated based counting process format. record counting process dataset represents tte one events occurs; results stratum-specific. Included observation number events overall (events) experimental treatment group (txevents), number risk overall (atrisk) experimental treatment group (txatrisk) just tte, combined treatment group Kaplan-Meier survival estimate (left-continuous) tte, observed events experimental group minus expected tte based assumption risk observations equally likely event time, variance quantity (Var). generate stratified logrank test corresponding one-sided p-value, simply following: Fleming-Harrington \\(\\rho=1\\), \\(\\gamma=2\\) nearly simple. compute z-statistic corresponding one-sided p-value. Fleming-Harrington tests, routine built tests : wanted take minimum MaxCombo test, first use fh_weight() compute correlation matrix z-statistics follows. Note ordering rho_gamma g argument list opposite . correlation matrix z-values now V1-V4. can compute p-value MaxCombo follows using mvtnorm::pmvnorm(). Note arguments GenzBretz() stringent defaults; also used stringent parameters example help file.","code":"z <- with(ten150, sum(o_minus_e) / sqrt(sum(var_o_minus_e))) c(z, pnorm(z)) #> [1] -2.505355629  0.006116416 xx <- mutate(ten150, w = s * (1 - s)^2) z <- with(xx, sum(o_minus_e * w) / sum(sqrt(var_o_minus_e * w^2))) c(z, pnorm(z)) #> [1] -0.1970797  0.4218826 fh00 <- y150 |> wlr(weight = fh(rho = 0, gamma = 0)) fh01 <- y150 |> wlr(weight = fh(rho = 0, gamma = 1)) fh10 <- y150 |> wlr(weight = fh(rho = 1, gamma = 0)) fh11 <- y150 |> wlr(weight = fh(rho = 1, gamma = 1))  temp_tbl <- fh00 |>   unlist() |>   as.data.frame() |>   cbind(fh01 |> unlist() |> as.data.frame()) |>   cbind(fh10 |> unlist() |> as.data.frame()) |>   cbind(fh11 |> unlist() |> as.data.frame())  colnames(temp_tbl) <- c(\"Test 1\", \"Test 2\", \"Test 3\", \"Test 4\") temp_tbl #>                       Test 1             Test 2             Test 3 #> method                   WLR                WLR                WLR #> parameter FH(rho=0, gamma=0) FH(rho=0, gamma=1) FH(rho=1, gamma=0) #> estimate   -14.9849475025986  -4.58833802802725  -10.3966094745713 #> se          5.98116583796613   2.21990881849575   4.28272384915455 #> z           2.50535562941256   2.06690382496719   2.42756942561769 #> info        37.0469798657718   5.42019004111222   18.2768366472186 #> info0                  37.25   5.44366046093289   18.6227889331453 #>                       Test 4 #> method                   WLR #> parameter FH(rho=1, gamma=1) #> estimate   -2.69994556253347 #> se          1.13659961009608 #> z           2.37545881465262 #> info        1.36992936361306 #> info0       1.37044207369963 y150 |>   maxcombo(rho = c(0, 0, 1, 1), gamma = c(0, 1, 0, 1)) #> $method #> [1] \"MaxCombo\" #>  #> $parameter #> [1] \"FH(0, 0) + FH(0, 1) + FH(1, 0) + FH(1, 1)\" #>  #> $z #> [1] -2.505356 -2.066904 -2.427569 -2.375459 #>  #> $p_value #> [1] 0.0125865"},{"path":"https://merck.github.io/simtrial/articles/routines.html","id":"simplification-for-2-arm-trials","dir":"Articles","previous_headings":"","what":"Simplification for 2-arm trials","title":"Basic tools for time-to-event trial simulation and testing","text":"sim_fixed_n() routine combines much go straight generating tests individual trials cutting data analyzing need done separately. argument structure meant simpler sim_pw_surv(). Now simulate trial 2 times cut data analysis based timing_type = 1:5 translates : planned study duration, targeted event count achieved, planned minimum follow-enrollment complete, maximum 1 2, maximum 2 3. look carefully, asking cutoff planned number events different data cutoff methods. explain, note generally want sample_size match enrollment specified enroll_rate: targeted enrollment takes, average, 30 months longer sum enrollment durations enroll_rate (14 months) input enrollment rates. achieve input sample_size 500, final enrollment rate assumed steady state extends simulation targeted enrollment achieved. planned duration trial taken 30 months specified total_duration. targeted minimum follow-thus, implicit last subject enrolled 16 months prior duration given cutoff “Minimum follow-” cutoff simulations . planned duration cutoff given total_duration argument results much earlier cutoff.","code":"stratum <- data.frame(stratum = \"All\", p = 1) enroll_rate <- data.frame(   duration = c(2, 2, 10),   rate = c(3, 6, 9) ) fail_rate <- data.frame(   stratum = \"All\",   duration = c(3, 100),   fail_rate = log(2) / c(9, 18),   hr = c(0.9, 0.6),   dropout_rate = rep(0.001, 2) ) block <- rep(c(\"experimental\", \"control\"), 2) rho_gamma <- data.frame(rho = 0, gamma = 0) sim_fixed_n(   n_sim = 2, # Number of simulations   sample_size = 500, # Trial sample size   target_event = 350, # Targeted events at analysis   stratum = stratum, # Study stratum   enroll_rate = enroll_rate, # Enrollment rates   fail_rate = fail_rate, # Failure rates   total_duration = 30, # Planned trial duration   block = block, # Block for treatment   timing_type = 1:5, # Use all possible data cutoff methods   rho_gamma = rho_gamma # FH test(s) to use; in this case, logrank ) |>   gt() |>   fmt_number(columns = c(\"ln_hr\", \"z\", \"duration\")) #> Backend uses sequential processing. enroll_rate |> summarize(   \"Targeted enrollment based on input enrollment rates\" = sum(duration * rate) ) #>   Targeted enrollment based on input enrollment rates #> 1                                                 108 total_duration <- 30 # From above total_duration - sum(enroll_rate$duration) #> [1] 16"},{"path":"https://merck.github.io/simtrial/articles/sim_fixed_design_custom.html","id":"step-1-simulate-time-to-event-data","dir":"Articles","previous_headings":"","what":"Step 1: Simulate time-to-event data","title":"Custom Fixed Design Simulations: A Tutorial on Writing Code from the Ground Up","text":"sim_pw_surv() function allows simulation clinical trial essentially arbitrary patterns enrollment, failure rates, censoring. implement sim_pw_surv(), need specify 5 design characteristics simulate time--event data: Sample Size (input n). Stratified Non-Stratified Designs (input stratum). Randomization Ratio (input block). sim_pw_surv() function uses fixed block randomization. Enrollment Rate (input enroll_rate). sim_pw_surv() function supports piecewise enrollment, allowing enrollment rate piecewise constant. Failure Rate (input fail_rate) time--event rate. sim_pw_surv() function uses piecewise exponential distribution failure rate, makes easy define distribution changing failure rates time. Specifically, \\(j\\)-th interval, rate denoted \\(\\lambda_j \\geq 0\\). require least one interval \\(\\lambda_j > 0\\). two methods defining failure rate: Specify failure rate treatment group, stratum, time period. example can found Scenario b). Create fail_rate using gsDesign2::define_fail_rate, convert required format using to_sim_pw_surv(). example provided Scenario ). Dropout Rate (input dropout_Rate). sim_pw_surv() function accepts piecewise constant dropout rates, may vary treatment group. configuration dropout specified treatment group, stratum, time period, setting dropout rate follows approach failure rate.","code":""},{"path":"https://merck.github.io/simtrial/articles/sim_fixed_design_custom.html","id":"scenario-a-the-simplest-scenario","dir":"Articles","previous_headings":"Step 1: Simulate time-to-event data","what":"Scenario a) The simplest scenario","title":"Custom Fixed Design Simulations: A Tutorial on Writing Code from the Ground Up","text":"begin simplest implementation sim_pw_surv(). following lines code generate 500 subjects using equal randomization unstratified design. output sim_pw_surv() subject-level observations, including stratum, enrollment time observation, treatment group observation randomized , failure time, dropout time, calendar time enrollment plot minimum failure time dropout time ( cte), failure dropout indicator (fail = 1 failure, fail = 0 dropout).","code":"n_sim <- 100 n <- 500 stratum <- data.frame(stratum = \"All\", p = 1) block <- rep(c(\"experimental\", \"control\"), 2)  enroll_rate <- define_enroll_rate(rate = 12, duration = n / 12)  fail_rate <- define_fail_rate(duration = c(6, Inf), fail_rate = log(2) / 10,                                hr = c(1, 0.7), dropout_rate = 0.0001)  uncut_data_a <- sim_pw_surv(n = n, stratum = stratum, block = block,                             enroll_rate = enroll_rate,                             fail_rate = to_sim_pw_surv(fail_rate)$fail_rate,                             dropout_rate = to_sim_pw_surv(fail_rate)$dropout_rate) uncut_data_a |> head() |> gt() |> tab_header(\"An Overview of Simulated TTE data\")"},{"path":"https://merck.github.io/simtrial/articles/sim_fixed_design_custom.html","id":"scenario-b-differential-dropout-rates","dir":"Articles","previous_headings":"Step 1: Simulate time-to-event data","what":"Scenario b) Differential dropout rates","title":"Custom Fixed Design Simulations: A Tutorial on Writing Code from the Ground Up","text":"dropout rate can differ groups. instance, open-label studies, control group may experience higher dropout rate. follow lines code assumes control group dropout rate 0.002 first 10 months, decreases 0.001 thereafter. contrast, experimental group constant dropout rate 0.001 throughout study.","code":"differential_dropout_rate <- data.frame(   stratum = rep(\"All\", 3),    period = c(1, 2, 1),    treatment = c(\"control\", \"control\", \"experimental\"),    duration = c(10, Inf, Inf),    rate = c(0.002, 0.001, 0.001))  uncut_data_b <- sim_pw_surv(n = n, stratum = stratum, block = block,                             enroll_rate = enroll_rate,                             fail_rate = to_sim_pw_surv(fail_rate)$fail_rate,                             dropout_rate = differential_dropout_rate)"},{"path":"https://merck.github.io/simtrial/articles/sim_fixed_design_custom.html","id":"scenario-c-stratified-designs","dir":"Articles","previous_headings":"Step 1: Simulate time-to-event data","what":"Scenario c) Stratified designs","title":"Custom Fixed Design Simulations: A Tutorial on Writing Code from the Ground Up","text":"following code assumes two strata (biomarker-positive biomarker-negative) equal prevalence 0.5 . control arm, median survival time 10 months biomarker-positive subjects 8 months biomarker-negative subjects. strata, hazard ratio 1 first 3 months, decreases 0.6 biomarker-positive subjects 0.8 biomarker-negative subjects. dropout rate contently 0.001 strata time.","code":"stratified_enroll_rate <- data.frame(   stratum = c(\"Biomarker positive\", \"Biomarker negative\"),   rate = c(12, 12),    duration = c(1, 1))  stratified_fail_rate <- data.frame(   stratum = c(rep(\"Biomarker positive\", 3), rep(\"Biomarker negative\", 3)),    period = c(1, 1, 2, 1, 1, 2),    treatment = rep(c(\"control\", \"experimental\", \"experimental\"), 2),   duration = c(Inf, 3, Inf, Inf, 3, Inf),    rate = c(# failure rate of biomarker positive subjects: control arm, exp arm period 1, exp arm period 2            log(2) / 10, log(2) /10, log(2) / 10 * 0.6,            # failure rate of biomarker negative subjects: control arm, exp arm period 1, exp arm period 2            log(2) / 8, log(2) /8, log(2) / 8 * 0.8)   )  stratified_dropout_rate <- data.frame(   stratum = rep(c(\"Biomarker positive\", \"Biomarker negative\"), each = 2),   period = c(1, 1, 1, 1),    treatment = c(\"control\", \"experimental\", \"control\", \"experimental\"),   duration = rep(Inf, 4),    rate = rep(0.001, 4)   )  uncut_data_c <- sim_pw_surv(n = n,                             stratum = data.frame(stratum = c(\"Biomarker positive\", \"Biomarker negative\"),                                                   p = c(0.5, 0.5)),                             block = block,                             enroll_rate = stratified_enroll_rate,                             fail_rate = stratified_fail_rate,                             dropout_rate = stratified_dropout_rate                             )"},{"path":"https://merck.github.io/simtrial/articles/sim_fixed_design_custom.html","id":"scenario-d-multi-arm-designs","dir":"Articles","previous_headings":"Step 1: Simulate time-to-event data","what":"Scenario d) Multi-arm designs","title":"Custom Fixed Design Simulations: A Tutorial on Writing Code from the Ground Up","text":"Suppose wish 3 arms: control, low-dose high-dose. following code assumes control arm median survival time 10 months, low-dose arm median survival time 12 months, high-dose arm median survival time 14 months. hazard ratio low-dose arm 0.8, hazard ratio high-dose arm 0.6. dropout rate 0.001 arms. Block size 7 3:2:2 randomization. begin setting enrollment, failure dropout rates. illustration purposes, focus scenario b) following discussion.","code":"enroll_rate <- define_enroll_rate(rate = 12, duration = n / 12)  three_arm_fail_rate <- data.frame(   stratum = \"All\",   period = c(1, 1, 2, 1, 2),    treatment = c(\"control\", \"low-dose\", \"low-dose\", \"high-dose\", \"high-dose\"),   duration = c(Inf, 3, Inf, 3, Inf),    rate = c(# failure rate of control arm: period 1, period 2            log(2) / 10,            # failure rate of low-dose arm: period 1, period 2            log(2) / c(10, 10 / .8),            # failure rate of high-dose arm: period 1, period 2            log(2) / c(10, 10 / .6)))  three_arm_dropout_rate <- data.frame(   stratum = \"All\",   period = c(1, 1, 1),    treatment = c(\"control\", \"low-dose\", \"high-dose\"),   duration = rep(Inf, 3),    rate = rep(0.001, 3))  uncut_data_d <- sim_pw_surv(n = n,                             stratum = data.frame(stratum = \"All\"),                             block = c(rep(\"control\", 3), rep(\"low-dose\", 2), rep(\"high-dose\", 2)),                             enroll_rate = enroll_rate,                             fail_rate = three_arm_fail_rate,                             dropout_rate = three_arm_dropout_rate) uncut_data <- uncut_data_b"},{"path":"https://merck.github.io/simtrial/articles/sim_fixed_design_custom.html","id":"step-2-cut-data","dir":"Articles","previous_headings":"","what":"Step 2: Cut data","title":"Custom Fixed Design Simulations: A Tutorial on Writing Code from the Ground Up","text":"get_analysis_date() derives analysis date interim/final analysis given multiple conditions, see help page get_analysis_date() pkgdown website. Users can cut analysis 24th month 300 events, whichever arrives later. equivalent timing_type = 4 sim_fixed_n(). Users can also cut maximum targeted 300 event minimum follow-12 months. equivalent timing_type = 5 sim_fixed_n(). Users can cut data 300 events, maximum time extension reach targeted events 24 months. enabled timing_type sim_fixed_n(). Users can cut data 12 months followup 80% patients enrolled overall population . enabled timing_type sim_fixed_n(). examples available reference page get_analysis_date() illustration purposes, focus scenario d) following discussion.","code":"cut_date_a <- get_analysis_date(data = uncut_data,                                 planned_calendar_time = 24,                                 target_event_overall = 300) cut_date_b <- get_analysis_date(data = uncut_data,                                 min_followup = 12,                                 target_event_overall = 300) cut_date_c <- get_analysis_date(data = uncut_data,                                 max_extension_for_target_event = 12,                                 target_event_overall = 300) cut_date_d <- get_analysis_date(data = uncut_data,                                 min_n_overall = 100 * 0.8,                                 min_followup = 12) cut_date <- cut_date_d cat(\"The cutoff date is \", round(cut_date, 2)) ## The cutoff date is  20.19 cut_data <- uncut_data |> cut_data_by_date(cut_date) cut_data |> head() |> gt() |> tab_header(paste0(\"An Overview of TTE data Cut at \", round(cut_date, 2), \"Months\"))"},{"path":"https://merck.github.io/simtrial/articles/sim_fixed_design_custom.html","id":"step-3-run-tests","dir":"Articles","previous_headings":"","what":"Step 3: Run tests","title":"Custom Fixed Design Simulations: A Tutorial on Writing Code from the Ground Up","text":"simtrial package provides many options testing methods, including (weighted) logrank tests, RMST test, milestone test, MaxComboi test, see [Section “Compute p-values/test statistics” pkgdown reference page] (https://merck.github.io/simtrial/reference/index.html#compute-p-values-test-statistics). following code lists possible tests available simtrial. Users can select one tests listed combine testing results make comparisons across tests. demonstration purposes, aggregate tests together. output tests mentioned lists including: testing method employed (WLR, RMST, milestone, MaxCombo), can accessed using sim_res_rmst$method. parameters associated testing method. instance, RMST test parameter 10, indicating RMST evaluated month 10. can find information using sim_res_rmst$parameter. point estimate standard error testing method used. example, point estimate RMST represents survival difference experimental group control group. estimate can retrieved sim_res_rmst$estimate sim_res_rmst$se. Z-score testing method, accessible via sim_res_rmst$z. Please note Z-score provided MaxCombo test; instead, p-value reported (sim_res_mc$p_value).","code":"# Logrank test sim_res_lr <- cut_data |> wlr(weight = fh(rho = 0, gamma = 0))  # weighted logrank test by Fleming-Harrington weights sim_res_fh <- cut_data |> wlr(weight = fh(rho = 0, gamma = 0.5))  # Modestly weighted logrank test sim_res_mb <- cut_data |> wlr(weight = mb(delay = Inf, w_max = 2))  # Weighted logrank test by Xu 2017's early zero weights sim_res_xu <- cut_data |> wlr(weight = early_zero(early_period = 3))  # RMST test sim_res_rmst <- cut_data |> rmst(tau = 10)  # Milestone test sim_res_ms <- cut_data |> milestone(ms_time = 10)  # Maxcombo tests comboing multiple weighted logrank test with Fleming-Harrington weights sim_res_mc <- cut_data |> maxcombo(rho = c(0, 0), gamma = c(0, 0.5)) sim_res <- tribble(   ~Method, ~Parameter, ~Z, ~Estimate, ~SE, ~`P value`,   sim_res_lr$method, sim_res_lr$parameter, sim_res_lr$z, sim_res_lr$estimate, sim_res_lr$se, pnorm(-sim_res_lr$z),   sim_res_fh$method, sim_res_fh$parameter, sim_res_fh$z, sim_res_fh$estimate, sim_res_fh$se, pnorm(-sim_res_fh$z),   sim_res_mb$method, sim_res_mb$parameter, sim_res_mb$z, sim_res_mb$estimate, sim_res_mb$se, pnorm(-sim_res_mb$z),   sim_res_xu$method, sim_res_xu$parameter, sim_res_xu$z, sim_res_xu$estimate, sim_res_xu$se, pnorm(-sim_res_xu$z),   sim_res_rmst$method, sim_res_rmst$parameter|> as.character(), sim_res_rmst$z, sim_res_rmst$estimate, sim_res_rmst$se, pnorm(-sim_res_rmst$z),   sim_res_ms$method, sim_res_ms$parameter |> as.character(), sim_res_ms$z, sim_res_ms$estimate, sim_res_ms$se, pnorm(-sim_res_ms$z),   sim_res_mc$method, sim_res_mc$parameter, NA, NA, NA, sim_res_mc$p_value   )   sim_res |> gt() |> tab_header(\"One Simulation Results\")"},{"path":"https://merck.github.io/simtrial/articles/sim_fixed_design_custom.html","id":"step-4-perform-the-above-single-simulation-repeatedly","dir":"Articles","previous_headings":"","what":"Step 4: Perform the above single simulation repeatedly","title":"Custom Fixed Design Simulations: A Tutorial on Writing Code from the Ground Up","text":"now merge Steps 1 3 single function named one_sim(), facilitates single simulation run. construction one_sim() involves copying lines code Steps 1 3. , execute one_sim() multiple times using parallel computation. following lines code uses 2 workers run 100 simulations. output parallel computation resembles output sim_fix_n() described vignette Simulate Fixed Designs Ease via sim_fixed_n. row output corresponds simulation results testing method per repeation.","code":"one_sim <- function(sim_id = 1,                      # arguments from Step 1: design characteristic                     n, stratum, enroll_rate, fail_rate, dropout_rate, block,                      # arguments from Step 2； cutting method                     min_n_overall, min_followup,                     # arguments from Step 3； testing method                     fh, mb, xu, rmst, ms, mc                     ) {     # Step 1: simulate a time-to-event data     uncut_data <- sim_pw_surv(       n = n,       stratum = stratum,       block = block,       enroll_rate = enroll_rate,       fail_rate = fail_rate,       dropout_rate = dropout_rate)           ## Step 2: Cut data     cut_date <- get_analysis_date(min_n_overall = min_n_overall, min_followup = min_followup, data = uncut_data)     cut_data <- uncut_data |> cut_data_by_date(cut_date)          # Step 3: Run tests     sim_res_lr <- cut_data |> wlr(weight = fh(rho = 0, gamma = 0))     sim_res_fh <- cut_data |> wlr(weight = fh(rho = fh$rho, gamma = fh$gamma))     sim_res_mb <- cut_data |> wlr(weight = mb(delay = mb$delay, w_max = mb$w_max))     sim_res_xu <- cut_data |> wlr(weight = early_zero(early_period = xu$early_period))     sim_res_rmst <- cut_data |> rmst(tau = rmst$tau)     sim_res_ms <- cut_data |> milestone(ms_time = ms$ms_time)     sim_res_mc <- cut_data |> maxcombo(rho = mc$rho, gamma = mc$gamma)          sim_res <- tribble(       ~`Sim ID`, ~Method, ~Parameter, ~Z, ~Estimate, ~SE, ~`P value`,       sim_id, sim_res_lr$method, sim_res_lr$parameter, sim_res_lr$z, sim_res_lr$estimate, sim_res_lr$se, pnorm(-sim_res_lr$z),       sim_id, sim_res_fh$method, sim_res_fh$parameter, sim_res_fh$z, sim_res_fh$estimate, sim_res_fh$se, pnorm(-sim_res_fh$z),       sim_id, sim_res_mb$method, sim_res_mb$parameter, sim_res_mb$z, sim_res_mb$estimate, sim_res_mb$se, pnorm(-sim_res_mb$z),       sim_id, sim_res_xu$method, sim_res_xu$parameter, sim_res_xu$z, sim_res_xu$estimate, sim_res_xu$se, pnorm(-sim_res_xu$z),       sim_id, sim_res_rmst$method, sim_res_rmst$parameter|> as.character(), sim_res_rmst$z, sim_res_rmst$estimate, sim_res_rmst$se, pnorm(-sim_res_rmst$z),       sim_id, sim_res_ms$method, sim_res_ms$parameter |> as.character(), sim_res_ms$z, sim_res_ms$estimate, sim_res_ms$se, pnorm(-sim_res_ms$z),       sim_id, sim_res_mc$method, sim_res_mc$parameter, NA, NA, NA, sim_res_mc$p_value   )             return(sim_res) } set.seed(2025)  plan(\"multisession\", workers = 2) ans <- foreach(   sim_id = seq_len(n_sim),   .errorhandling = \"stop\",   .options.future = list(seed = TRUE)   ) %dofuture% {     ans_new <- one_sim(       sim_id = sim_id,        # arguments from Step 1: design characteristic       n = n,        stratum = stratum,        enroll_rate = enroll_rate,        fail_rate = to_sim_pw_surv(fail_rate)$fail_rate,        dropout_rate = differential_dropout_rate,        block = block,        # arguments from Step 2； cutting method       min_n_overall = 500 * 0.8,       min_followup = 12,       # arguments from Step 3； testing method       fh = list(rho = 0, gamma = 0.5),        mb = list(delay = Inf, w_max = 2),        xu = list(early_period = 3),        rmst = list(tau = 10),        ms = list(ms_time = 10),        mc = list(rho = c(0, 0), gamma = c(0, 0.5))       )                                    ans_new   }  ans <- data.table::rbindlist(ans)  plan(\"sequential\") ans |> head() |> gt() |> tab_header(\"Overview Each Simulation results\")"},{"path":"https://merck.github.io/simtrial/articles/sim_fixed_design_custom.html","id":"step-5-summarize-simulations","dir":"Articles","previous_headings":"","what":"Step 5: Summarize simulations","title":"Custom Fixed Design Simulations: A Tutorial on Writing Code from the Ground Up","text":"Using 100 parallel simulations provided , users can summarize simulated power compare across different testing methods data manipulation using dplyr. Please note power calculation MaxCombo test differs tests, report Z-score.","code":"ans_non_mc <- ans |>   filter(Method != \"MaxCombo\") |>   group_by(Method, Parameter) %>%    summarise(Power = mean(Z > -qnorm(0.025))) |>   ungroup()  ans_mc <- ans |>   filter(Method == \"MaxCombo\") |>   summarize(Power = mean(`P value` < 0.025), Method = \"MaxCombo\", Parameter = \"FH(0, 0) + FH(0, 0.5)\")   ans_non_mc |>   union(ans_mc) |>   gt() |>   tab_header(\"Summary from 100 simulations\")"},{"path":[]},{"path":"https://merck.github.io/simtrial/articles/sim_fixed_design_simple.html","id":"step-1-define-design-parameters","dir":"Articles","previous_headings":"","what":"Step 1: Define design parameters","title":"Simulate Fixed Designs with Ease via sim_fixed_n","text":"run simulations fixed design, several design characteristics may used. Depending data cutoff analysis option, different inputs may required. following lines code specify unstratified 2-arm trial equal randomization. simulation repeated 2 times. Enrollment targeted last 12 months constant enrollment rate. median control arm 10 months, delayed effect first 3 months followed hazard ratio 0.7 thereafter. exponential dropout rate 0.001 time. specify sample size targeted event count based fixed_design_ahr() function options. following design computes sample size targeted event counts 85% power. approach, users can obtain sample size targeted events output x, specifically using sample_size <- x$analysis$n target_event <- x$analysis$event. Now set derived targeted sample size, enrollment rate, event count .","code":"n_sim <- 100 total_duration <- 36 stratum <- data.frame(stratum = \"All\", p = 1) block <- rep(c(\"experimental\", \"control\"), 2)  enroll_rate <- data.frame(stratum = \"All\", rate = 12, duration = 500 / 12) fail_rate <- data.frame(stratum = \"All\",                         duration = c(3, Inf), fail_rate = log(2) / 10,                          hr = c(1, 0.6), dropout_rate = 0.001) x <- fixed_design_ahr(enroll_rate = enroll_rate, fail_rate = fail_rate,                        alpha = 0.025, power = 0.85, ratio = 1,                        study_duration = total_duration) |> to_integer() x |> summary() |> gt() |>    tab_header(title = \"Sample Size and Targeted Events Based on AHR Method\",               subtitle = \"Fixed Design with 85% Power, One-sided 2.5% Type I error\") |>   fmt_number(columns = c(4, 5, 7), decimals = 2) sample_size <- x$analysis$n target_event <- x$analysis$event enroll_rate <- x$enroll_rate"},{"path":"https://merck.github.io/simtrial/articles/sim_fixed_design_simple.html","id":"step-2-run-sim_fixed_n","dir":"Articles","previous_headings":"","what":"Step 2: Run sim_fixed_n()","title":"Simulate Fixed Designs with Ease via sim_fixed_n","text":"Now set design characteristics Step 1, can proceed run sim_fix_n() simulations. function automatically utilizes parallel computing backend, helps reduce running time. timing_type specifies one following cutoffs setting time analysis: timing_type = 1: planned study duration. timing_type = 2: time target event count observed. timing_type = 3: planned minimum follow-period enrollment completion. timing_type = 4: maximum planned study duration time observe targeted event count (.e., using timing_type = 1 timing_type = 2 together). timing_type = 5: maximum time observe targeted event count minimum follow-following enrollment completion (.e., using timing_type = 2 timing_type = 3 together). rho_gamma argument data frame containing variables rho gamma, greater equal zero, specify one Fleming-Harrington weighted log-rank test per row. instance, setting rho = 0 gamma = 0 yields standard unweighted log-rank test, rho = 0 gamma = 0.5 provides weighted Fleming-Harrington (0, 0.5) log-rank test. interested tests Fleming-Harrington weighted log-rank test, please refer vignette “Articles”/“Simulate fixed/group sequential designs”/“Custom Fixed Design Simulations: Tutorial Writing Code Ground ”. output sim_fixed_n data frame one row per simulated dataset per cutoff specified timing_type, per test statistic specified rho_gamma. just run 2 simulated trials see different cutoffs vary 2 trial instances.","code":"sim_res <- sim_fixed_n(   n_sim = 2, # only use 2 simulations for initial run   sample_size = sample_size,    block = block,    stratum = stratum,   target_event = target_event,    total_duration = total_duration,   enroll_rate = enroll_rate,    fail_rate = fail_rate,   timing_type = 1:5,    rho_gamma = data.frame(rho = 0, gamma = 0)) sim_res |>   gt() |>   tab_header(\"Tests for Each Simulation Result\", subtitle = \"Logrank Test for Different Analysis Cutoffs\") |>   fmt_number(columns = c(4, 5, 7), decimals = 2)"},{"path":"https://merck.github.io/simtrial/articles/sim_fixed_design_simple.html","id":"step-3-summarize-simulations","dir":"Articles","previous_headings":"","what":"Step 3: Summarize simulations","title":"Simulate Fixed Designs with Ease via sim_fixed_n","text":"Now run 100 simulated trials summarize results data cutoff analysis. 100 simulations provided, users can summarize simulated power compare targeted 85% power. cutoff methods approximate targeted power well similar average duration mean number events. can also things like summarize distribution event counts planned study duration. can see event count varies fair amount.  also evaluate distribution trial duration analysis performed targeted events achieved.","code":"sim_res <- sim_fixed_n(   n_sim = n_sim,   sample_size = sample_size,    block = block, stratum = stratum,   target_event = target_event,    total_duration = total_duration,   enroll_rate = enroll_rate,    fail_rate = fail_rate,   timing_type = 1:5,    rho_gamma = data.frame(rho = 0, gamma = 0)) sim_res |>   group_by(cut) |>   summarize(`Simulated Power` = mean(z > qnorm(1 - 0.025)),              `Mean events` = mean(event),             `Mean duration` = mean(duration)) |>   mutate(`Sample size` = sample_size,          `Targeted events` = target_event) |>   gt() |>   tab_header(title = \"Summary of 100 simulations by 5 different analysis cutoff methods\",              subtitle = \"Tested by logrank\") |>   fmt_number(columns = c(2:4), decimals = 2) hist(sim_res$event[sim_res$cut == \"Planned duration\"],       breaks = 10,      main = \"Distribution of Event Counts at Planned Study Duration\",      xlab = \"Event Count at Targeted Trial Duration\") plot(density(sim_res$duration[sim_res$cut == \"Targeted events\"]),       main = \"Trial Duration Smoothed Density\",      xlab = \"Trial duration when Targeted Event Count is Observed\")"},{"path":"https://merck.github.io/simtrial/articles/sim_gs_design_simple.html","id":"step-1-define-design-paramaters","dir":"Articles","previous_headings":"","what":"Step 1: Define design paramaters","title":"Simulate Group Sequential Designs with Ease via sim_gs_n","text":"run simulations group sequential design, several design characteristics required. following code creates design unstratified 2-arm trial equal randomization. Enrollment targeted last 12 months constant enrollment rate. control arm specified exponential median 10 months. experimental arm distribution piecewise exponential distribution delay 3 months benefit relative control (HR = 1) followed hazard ratio 0.6 thereafter. Additionally, exponential dropout rate 0.001 per month (unit time). set parameters similar vignette Simulate Fixed Designs Ease via sim_fixed_n. total sample size derived 90% power. Now get updated planned enrollment rate design achieve targeted sample size. additional parameters required group sequential design simulation demonstrated . One testing method. focus logrank . Users can change tests interest; comments demonstrate logrank modestly weighted logrank test (Magirr Burman (2019)) Fleming-Harrington (Harrington Fleming (1982)) tests; set group sequential designs alternate tests beyond scope article. testing methods available reference page simtrial. final step specify data cut analysis group sequential design. create_cut() function includes 5 options analysis cutoff: planned calendar time, targeted events, maximum time extension reach targeted events, planned minimum time previous analysis, minimal follow-time specified enrollment fraction. details examples available help page. straightforward method cutting analyses based events. instance, following code specifies 2 interim analyses 1 final analysis cut 106, 227, 287 events occur. event-driven approach, need update efficacy boundary. Users can set complex cutting. example, first interim analysis occurs targeted IA 1 analyusis time least IA 1 targeted events observed, later. However, target number events reached, wait maximum 16 months start enrollment. second interim analysis targeted take place targeted time targeted events IA 2, whichever later. Additionally, interim analysis scheduled least 10 months first interim analysis, later 28 months start enrollment. final analysis set targeted final analysis time targeted events final analysis, whichever later. must least 6 months IA 2. Please keep mind cut event-driven, boundary updates necessary; covered . can find information boundary updates boundary update vignette. vignette, use event-driven cut illustrative purposes.","code":"stratum <- data.frame(stratum = \"All\", p = 1) block <- rep(c(\"experimental\", \"control\"), 2) # enrollment rate will be updated later,  # multiplied by a constant to get targeted power enroll_rate <- data.frame(stratum = \"All\", rate = 1, duration = 12) fail_rate <- data.frame(stratum = \"All\",                         duration = c(3, Inf), fail_rate = log(2) / 10,                          hr = c(1, 0.6), dropout_rate = 0.001) # Derive design using the average hazard ratio method x <- gs_design_ahr(enroll_rate = enroll_rate, fail_rate = fail_rate,                    analysis_time = c(12, 24, 36), alpha = 0.025, beta = 0.1,                    # spending function for upper bound                    upper = gs_spending_bound,                     upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025),                    # Fixed lower bound                    lower = gs_b,                    lpar = rep(-Inf, 3)) |> to_integer()  sample_size <- x$analysis$n |> max() event <- x$analysis$event eff_bound <- x$bound$z[x$bound$bound == \"upper\"] cat(paste(\"The total sample size is \", sample_size, \"\\n\", sep = '')) ## The total sample size is 362 cat(\"The number of events at IA1, IA2 and FA are:\", event, \"\\n\") ## The number of events at IA1, IA2 and FA are: 106 227 287 cat(\"The efficacy bounds at IA1, IA2 and FA are:\", round(eff_bound, 3), \"\\n\") ## The efficacy bounds at IA1, IA2 and FA are: 3.508 2.269 2.023 cat(\"Targeted analysis times:\", round(x$analysis$time, 1), \"\\n\") ## Targeted analysis times: 12 24 35.9 enroll_rate <- x$enroll_rate enroll_rate ##   stratum     rate duration ## 1     All 30.16667       12 # Example for logrank weight <- fh(rho = 0, gamma = 0) test <- wlr # Example for Modestly Weighted Logrank Test (Magirr-Burman) # weight <- mb(delay = Inf, w_max = 2) # Example for Fleming-Harrington(0, 0.5) # weight <- fh(rho = 0, gamma = 0.5) ia1_cut <- create_cut(target_event_overall = event[1]) ia2_cut <- create_cut(target_event_overall = event[2]) fa_cut <- create_cut(target_event_overall = event[3])  cut <- list(ia1 = ia1_cut, ia2 = ia2_cut, fa = fa_cut) ia1_cut <- create_cut(   planned_calendar_time = round(x$analysis$time[1]),    target_event_overall = x$analysis$event[1],   max_extension_for_target_event = 16)  ia2_cut <- create_cut(   planned_calendar_time = round(x$analysis$time[2]),   target_event_overall = x$analysis$event[2],   min_time_after_previous_analysis = 10,    max_extension_for_target_event = 28)  fa_cut <- create_cut(   planned_calendar_time = round(x$analysis$time[3]),   min_time_after_previous_analysis = 6,   target_event_overall = x$analysis$event[3])  cut <- list(ia1 = ia1_cut, ia2 = ia2_cut, fa = fa_cut)"},{"path":"https://merck.github.io/simtrial/articles/sim_gs_design_simple.html","id":"step-2-run-sim_gs_n","dir":"Articles","previous_headings":"","what":"Step 2: Run sim_gs_n()","title":"Simulate Group Sequential Designs with Ease via sim_gs_n","text":"Now set design characteristics Step 1, can proceed run sim_gs_n() specified number simulations. function automatically utilizes parallel computing backend, helps reduce running time. output sim_gs_n data frame one row per simulation per analysis. show results first 2 simulated trials . estimate column sum(0 - E) logrank test; se column standard error estimated null hypothesis. z column test statistic logrank test (estimate / se). info info0 columns information current analysis alternate null hypotheses, respectively.","code":"n_sim <- 100 # Number of simulated trials sim_res <- sim_gs_n(   n_sim = n_sim,   sample_size = sample_size, stratum = stratum, block = block,   enroll_rate = enroll_rate, fail_rate = fail_rate,   test = test, weight = weight, cut = cut) sim_res |> head(n = 6) |> gt() |> tab_header(\"Overview Each Simulation results\") |>   fmt_number(columns = c(5, 8:12), decimals = 2)"},{"path":"https://merck.github.io/simtrial/articles/sim_gs_design_simple.html","id":"step-3-summarize-simulations","dir":"Articles","previous_headings":"","what":"Step 3: Summarize simulations","title":"Simulate Group Sequential Designs with Ease via sim_gs_n","text":"100 simulations provided, users can summarize simulated power compare target power 90% follows:","code":"sim_res |>   left_join(data.frame(analysis = 1:3, eff_bound = eff_bound)) |>   group_by(analysis) |>   summarize(`Mean time` = mean(cut_date), `sd(time)` = sd(cut_date), `Simulated power` = mean(z >= eff_bound)) |>   ungroup() |>   mutate(`Asymptotic power` = x$bound$probability[x$bound$bound == \"upper\"]) |>   gt() |>   tab_header(\"Summary of 100 simulations\") |>    fmt_number(columns = 2, decimals = 1) |>   fmt_number(columns = 3:5, decimals = 2)"},{"path":[]},{"path":"https://merck.github.io/simtrial/articles/workflow.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"TTE simulation data manipulations","text":"attempt provide big picture view involved clinical trial simulation individual time--event data generated patient. Primary interest group sequential trials, usually single endpoint. However extensions made.","code":""},{"path":"https://merck.github.io/simtrial/articles/workflow.html","id":"results-data-table","dir":"Articles","previous_headings":"","what":"Results data table","title":"TTE simulation data manipulations","text":"time simulation planning analysis plan trial needed. group sequential design, data table store results generated. Generally, dimensions variables planned storage planned front. simple example, group sequential design 3 analyses planned, 15 data items analysis 10,000 simulations planned, data table 30,000 rows 15 columns used store summary results. trial simulation proceeds, row updated results analysis.","code":""},{"path":"https://merck.github.io/simtrial/articles/workflow.html","id":"simulated-trial-dataset-generation","dir":"Articles","previous_headings":"","what":"Simulated trial dataset generation","title":"TTE simulation data manipulations","text":"simulated trial, initial table generated information patient level. trials generated sequentially, space needed data table re-used, never requiring allocation space. row contains data single patient. example, simulate trial 500 patients 10 data items per patients. data items columns, patients rows.","code":""},{"path":"https://merck.github.io/simtrial/articles/workflow.html","id":"dataset-manipulations-for-analysis","dir":"Articles","previous_headings":"","what":"Dataset manipulations for analysis","title":"TTE simulation data manipulations","text":"Simulated trial data need manipulated individual analysis (interim final) clinical trial. following operations needed: Ordering data Selecting subset analysis Calculating individual patient results subset time analysis. Number subjects treatment group Number events treatment group Kaplan-Meier estimation survival curves Observed minus expected computations well weighting logrank, weighted logrank calculations. Using survival package compute hazard ratio estimates.","code":""},{"path":"https://merck.github.io/simtrial/articles/workflow.html","id":"flow-for-simulating-group-sequential-one-scenario-algorithm","dir":"Articles","previous_headings":"","what":"Flow for simulating group sequential: one scenario algorithm","title":"TTE simulation data manipulations","text":"Group sequential design simulation flow: Generate trial. Analyze repeatedly. Summarize across simulated trials.","code":""},{"path":"https://merck.github.io/simtrial/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Keaven Anderson. Author. Yujie Zhao. Author, maintainer. John Blischak. Author. Nan Xiao. Contributor. Yilong Zhang. Author. Jianxiao Yang. Contributor. Lili Ling. Contributor. Xintong Li. Contributor. Ruixue Wang. Contributor. Yi Cui. Contributor. Ping Yang. Contributor. Yalin Zhu. Contributor. Heng Zhou. Contributor. Amin Shirazi. Contributor. Cole Manschot. Contributor. Larry Leon. Contributor. Merck & Co., Inc., Rahway, NJ, USA affiliates. Copyright holder.","code":""},{"path":"https://merck.github.io/simtrial/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Anderson K, Zhao Y, Blischak J, Zhang Y (2025). simtrial: Clinical Trial Simulation. R package version 1.0.0, https://merck.github.io/simtrial/.","code":"@Manual{,   title = {simtrial: Clinical Trial Simulation},   author = {Keaven Anderson and Yujie Zhao and John Blischak and Yilong Zhang},   year = {2025},   note = {R package version 1.0.0},   url = {https://merck.github.io/simtrial/}, }"},{"path":"https://merck.github.io/simtrial/index.html","id":"simtrial-","dir":"","previous_headings":"","what":"Clinical Trial Simulation","title":"Clinical Trial Simulation","text":"simtrial fast extensible clinical trial simulation framework time--event endpoints.","code":""},{"path":"https://merck.github.io/simtrial/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Clinical Trial Simulation","text":"easiest way get simtrial install CRAN: Alternatively, use new feature get bug fix, can install development version simtrial GitHub:","code":"install.packages(\"simtrial\") # install.packages(\"remotes\") remotes::install_github(\"Merck/simtrial\")"},{"path":"https://merck.github.io/simtrial/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Clinical Trial Simulation","text":"simtrial intended general purpose tool simulating fixed, group sequential adaptive clinical trials. allows stratified populations flexible parameters generating enrollment, event times, dropout times. takes care bookkeeping enable easily going data generation creating analysis datasets evaluation standard innovative designs testing procedures. single endpoint, easily generate trials multiple arms (e.g., single multiple experimental arms versus common control) multiple study populations (e.g., overall population biomarker positive). tools built package logrank weighted logrank tests, arbitrary testing estimation procedures easily applied. addition weighted logrank tests, support combinations weighted logrank tests (e.g., MaxCombo test). package used piecewise constant enrollment, failure dropout rates simple model able approximate arbitrary distributions easily. model also enables simulating non-proportional hazards assumptions transparent users explain non-statistical collaborators. simtrial designed core philosophy basing computations efficient table transformations package easy qualify use regulated environments. utilizes blazingly fast data.table tabular data processing, enhanced C++ implementations ensure optimal performance. However, require user data.table C++ user. Initial areas focus : Generating time--event data stratified trials using piecewise constant enrollment piecewise exponential failure rates. proportional non-proportional hazards supported. proportional hazards, assumptions along lines used Lachin Foulkes implemented gsDesign deriving group sequential designs. Setting data cutoffs (interim final) analyses. Support weighted logrank tests arbitrary weighting schemes, specifically supporting Fleming-Harrington set tests, including logrank test.","code":""},{"path":"https://merck.github.io/simtrial/index.html","id":"future-developments","dir":"","previous_headings":"","what":"Future developments","title":"Clinical Trial Simulation","text":"Expectations future development include: Provide test suite document package fit use regulatory environment. examples.","code":""},{"path":"https://merck.github.io/simtrial/reference/as_gt.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert summary table to a gt object — as_gt","title":"Convert summary table to a gt object — as_gt","text":"Convert summary table gt object","code":""},{"path":"https://merck.github.io/simtrial/reference/as_gt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert summary table to a gt object — as_gt","text":"","code":"as_gt(x, ...)  # S3 method for class 'simtrial_gs_wlr' as_gt(   x,   title = \"Summary of simulation results by WLR tests\",   subtitle = NULL,   ... )"},{"path":"https://merck.github.io/simtrial/reference/as_gt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert summary table to a gt object — as_gt","text":"x object returned summary(). ... Additional parameters (used). title Title gt table. subtitle Subtitle gt table.","code":""},{"path":"https://merck.github.io/simtrial/reference/as_gt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert summary table to a gt object — as_gt","text":"gt table. gt table summarizing simulation results.","code":""},{"path":"https://merck.github.io/simtrial/reference/as_gt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert summary table to a gt object — as_gt","text":"","code":"# Parameters for enrollment enroll_rampup_duration <- 4 # Duration for enrollment ramp up enroll_duration <- 16 # Total enrollment duration enroll_rate <- gsDesign2::define_enroll_rate(   duration = c(     enroll_rampup_duration, enroll_duration - enroll_rampup_duration),  rate = c(10, 30))  # Parameters for treatment effect delay_effect_duration <- 3 # Delay treatment effect in months median_ctrl <- 9 # Survival median of the control arm median_exp <- c(9, 14) # Survival median of the experimental arm dropout_rate <- 0.001 fail_rate <- gsDesign2::define_fail_rate(   duration = c(delay_effect_duration, 100),   fail_rate = log(2) / median_ctrl,   hr = median_ctrl / median_exp,   dropout_rate = dropout_rate)  # Other related parameters alpha <- 0.025 # Type I error beta <- 0.1 # Type II error ratio <- 1 # Randomization ratio (experimental:control)  # Build a one-sided group sequential design design <- gsDesign2::gs_design_ahr(   enroll_rate = enroll_rate, fail_rate = fail_rate,   ratio = ratio, alpha = alpha, beta = beta,   analysis_time = c(12, 24, 36),   upper = gsDesign2::gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = alpha),   lower = gsDesign2::gs_b,   lpar = rep(-Inf, 3))  # Define cuttings of 2 IAs and 1 FA ia1_cut <- create_cut(target_event_overall = ceiling(design$analysis$event[1])) ia2_cut <- create_cut(target_event_overall = ceiling(design$analysis$event[2])) fa_cut <- create_cut(target_event_overall = ceiling(design$analysis$event[3]))  # Run simulations simulation <- sim_gs_n(   n_sim = 3,   sample_size = ceiling(design$analysis$n[3]),   enroll_rate = design$enroll_rate,   fail_rate = design$fail_rate,   test = wlr,   cut = list(ia1 = ia1_cut, ia2 = ia2_cut, fa = fa_cut),   weight = fh(rho = 0, gamma = 0.5)) #> Backend uses sequential processing.  # Summarize simulations simulation |>  summary(bound = gsDesign::gsDesign(k = 3, test.type = 1, sfu = gsDesign::sfLDOF)$upper$bound) |>  simtrial::as_gt()     Summary of simulation results by WLR tests     Weighted by FH(rho=0, gamma=0.5)     analysis       Time       N       Event       Crossing probability     1 12.14286 356 97 NA2 24.71662 505 305 0.66666673 36.84514 505 405 1.0000000 # Summarize simulations and compare with the planned design simulation |>   summary(design = design) |>   simtrial::as_gt()     Summary of simulation results by WLR tests     Weighted by FH(rho=0, gamma=0.5)     Analysis                Time                       N                       Events                       Probability of crossing efficacy bounds under H1            Asymptotic       Simulated       Asymptotic       Simulated       Asymptotic       Simulated       Asymptotic       Simulated     1 12 12.14286 353.0464 356 96.77449 97 0.0001486592 NA2 24 24.71662 504.3520 505 304.00970 305 0.5723210881 13 36 36.84514 504.3520 505 404.14162 405 0.8999997572 NA"},{"path":"https://merck.github.io/simtrial/reference/check_args.html","id":null,"dir":"Reference","previous_headings":"","what":"Check argument types, length, or dimension — check_args","title":"Check argument types, length, or dimension — check_args","text":"Check argument types, length, dimension","code":""},{"path":"https://merck.github.io/simtrial/reference/check_args.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check argument types, length, or dimension — check_args","text":"","code":"check_args(arg, type, length = NULL, dim = NULL)"},{"path":"https://merck.github.io/simtrial/reference/check_args.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check argument types, length, or dimension — check_args","text":"arg argument checked. type character vector candidate argument type. length numeric value argument length NULL. dim numeric vector argument dimension NULL.","code":""},{"path":"https://merck.github.io/simtrial/reference/check_args.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check argument types, length, or dimension — check_args","text":"Check failure detailed error message.","code":""},{"path":"https://merck.github.io/simtrial/reference/check_args.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check argument types, length, or dimension — check_args","text":"type, length dim NULL, corresponding check executed.","code":""},{"path":"https://merck.github.io/simtrial/reference/check_args.html","id":"specification","dir":"Reference","previous_headings":"","what":"Specification","title":"Check argument types, length, or dimension — check_args","text":"contents section shown PDF user manual .","code":""},{"path":"https://merck.github.io/simtrial/reference/check_args.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check argument types, length, or dimension — check_args","text":"","code":"if (FALSE) { # \\dontrun{ tbl <- as.data.frame(matrix(1:9, nrow = 3)) simtrial:::check_args(arg = tbl, type = c(\"data.frame\"))  vec <- c(\"a\", \"b\", \"c\") simtrial:::check_args(arg = vec, type = c(\"character\"), length = 3) } # }"},{"path":"https://merck.github.io/simtrial/reference/counting_process.html","id":null,"dir":"Reference","previous_headings":"","what":"Process survival data into counting process format — counting_process","title":"Process survival data into counting process format — counting_process","text":"Produces data frame sorted stratum time. Included times one event occurs. output dataset contains stratum, TTE (time--event), risk count, count events specified TTE sorted stratum TTE.","code":""},{"path":"https://merck.github.io/simtrial/reference/counting_process.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process survival data into counting process format — counting_process","text":"","code":"counting_process(x, arm)"},{"path":"https://merck.github.io/simtrial/reference/counting_process.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process survival data into counting process format — counting_process","text":"x data frame missing values contain variables: stratum: Stratum. treatment: Treatment group. tte: Observed time. event: Binary event indicator, 1 represents event, 0 represents censoring. arm Value input treatment column indicates treatment group value.","code":""},{"path":"https://merck.github.io/simtrial/reference/counting_process.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process survival data into counting process format — counting_process","text":"data frame grouped stratum sorted within stratum tte. includes rows least one event population, least one subject risk treatment group control group. variables represent following within stratum time one events observed: event_total: Total number events event_trt: Total number events treatment group n_risk_total: Number subjects risk n_risk_trt: Number subjects risk treatment group s: Left-continuous Kaplan-Meier survival estimate o_minus_e: treatment group, observed number events minus expected number events. expected number events estimated assuming treatment effect hypergeometric distribution parameters total number events, total number events treatment group number events time. (assumption log-rank test null hypothesis) var_o_minus_e: Variance o_minus_e assumption.","code":""},{"path":"https://merck.github.io/simtrial/reference/counting_process.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Process survival data into counting process format — counting_process","text":"function considered two group situation. tie handled Breslow's Method. output produced counting_process() produces counting process dataset grouped stratum sorted within stratum increasing times events occur. object assigned class \"counting_process\". also attribute \"ratio\", ratio events treatment arm compared control arm input time--event data. input data generated sim_pw_surv(), ratio attribute simply obtained attribute name input object. Otherwise, returned ratio empirical ratio treatment control events.","code":""},{"path":"https://merck.github.io/simtrial/reference/counting_process.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process survival data into counting process format — counting_process","text":"","code":"# Example 1 x <- data.frame(   stratum = c(rep(1, 10), rep(2, 6)),   treatment = rep(c(1, 1, 0, 0), 4),   tte = 1:16,   event = rep(c(0, 1), 8) ) counting_process(x, arm = 1) #>   stratum event_total event_trt tte n_risk_total n_risk_trt         s #> 1       1           1         1   2            9          5 1.0000000 #> 2       1           1         0   4            7          4 0.8888889 #> 3       1           1         1   6            5          3 0.7619048 #> 4       1           1         0   8            3          2 0.6095238 #> 5       2           1         0  12            5          2 1.0000000 #> 6       2           1         1  14            3          1 0.8000000 #>    o_minus_e var_o_minus_e #> 1  0.4444444     0.2469136 #> 2 -0.5714286     0.2448980 #> 3  0.4000000     0.2400000 #> 4 -0.6666667     0.2222222 #> 5 -0.4000000     0.2400000 #> 6  0.6666667     0.2222222  # Example 2 x <- sim_pw_surv(n = 400) y <- cut_data_by_event(x, 150) |> counting_process(arm = \"experimental\") # Weighted logrank test (Z-value and 1-sided p-value) z <- sum(y$o_minus_e) / sqrt(sum(y$var_o_minus_e)) c(z, pnorm(z)) #> [1] -3.5701616116  0.0001783805"},{"path":"https://merck.github.io/simtrial/reference/create_cut.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a cutting function — create_cut","title":"Create a cutting function — create_cut","text":"Create cutting function use sim_gs_n()","code":""},{"path":"https://merck.github.io/simtrial/reference/create_cut.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a cutting function — create_cut","text":"","code":"create_cut(...)"},{"path":"https://merck.github.io/simtrial/reference/create_cut.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a cutting function — create_cut","text":"... Arguments passed get_analysis_date()","code":""},{"path":"https://merck.github.io/simtrial/reference/create_cut.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a cutting function — create_cut","text":"function accepts data frame simulated trial data returns cut date","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/reference/create_cut.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a cutting function — create_cut","text":"","code":"# Simulate trial data trial_data <- sim_pw_surv()  # Create a cutting function that applies the following 2 conditions: # - At least 45 months have passed since the start of the study # - At least 300 events have occurred cutting <- create_cut(   planned_calendar_time = 45,   target_event_overall = 350 )  # Cut the trial data cutting(trial_data) #> [1] 77.87317"},{"path":"https://merck.github.io/simtrial/reference/create_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a cutting test function — create_test","title":"Create a cutting test function — create_test","text":"Create cutting test function use sim_gs_n()","code":""},{"path":"https://merck.github.io/simtrial/reference/create_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a cutting test function — create_test","text":"","code":"create_test(test, ...)"},{"path":"https://merck.github.io/simtrial/reference/create_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a cutting test function — create_test","text":"test test function wlr(), maxcombo(), rmst() ... Arguments passed cutting test function","code":""},{"path":"https://merck.github.io/simtrial/reference/create_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a cutting test function — create_test","text":"function accepts data frame simulated trial data returns test result","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/reference/create_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a cutting test function — create_test","text":"","code":"# Simulate trial data trial_data <- sim_pw_surv()  # Cut after 150 events trial_data_cut <- cut_data_by_event(trial_data, 150)  # Create a cutting test function that can be used by sim_gs_n() regular_logrank_test <- create_test(wlr, weight = fh(rho = 0, gamma = 0))  # Test the cutting regular_logrank_test(trial_data_cut) #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"FH(rho=0, gamma=0)\" #>  #> $estimate #> [1] -16.60282 #>  #> $se #> [1] 4.370912 #>  #> $z #> [1] 3.798481 #>  #> $info #> [1] 23.1828 #>  #> $info0 #> [1] 23.25 #>   # The results are the same as directly calling the function stopifnot(all.equal(   regular_logrank_test(trial_data_cut),   wlr(trial_data_cut, weight = fh(rho = 0, gamma = 0)) ))"},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Cut a dataset for analysis at a specified date — cut_data_by_date","title":"Cut a dataset for analysis at a specified date — cut_data_by_date","text":"Cut dataset analysis specified date","code":""},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cut a dataset for analysis at a specified date — cut_data_by_date","text":"","code":"cut_data_by_date(x, cut_date)"},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cut a dataset for analysis at a specified date — cut_data_by_date","text":"x time--event dataset, example, generated sim_pw_surv(). cut_date Date relative start randomization (cte input dataset) dataset cut analysis.","code":""},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cut a dataset for analysis at a specified date — cut_data_by_date","text":"data frame ready survival analysis, including columns time event (tte), event, stratum, treatment. class data frame tte_data, attribute ratio generated sim_pw_surv() also attached.","code":""},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cut a dataset for analysis at a specified date — cut_data_by_date","text":"","code":"# Use default enrollment and event rates and # cut at calendar time 5 after start of randomization sim_pw_surv(n = 20) |> cut_data_by_date(5) #>          tte event stratum    treatment #> 1  4.8763169     0     All experimental #> 2  4.8703586     0     All experimental #> 3  2.2070735     1     All      control #> 4  0.1173257     1     All      control #> 5  4.6605109     0     All experimental #> 6  4.5461906     0     All      control #> 7  4.5116372     0     All      control #> 8  4.0148199     0     All experimental #> 9  3.8905856     0     All experimental #> 10 3.7668601     0     All      control #> 11 3.6986976     0     All experimental #> 12 3.6716565     0     All      control #> 13 3.5130873     0     All experimental #> 14 3.2754677     0     All      control #> 15 1.1770995     1     All      control #> 16 3.2343190     0     All experimental #> 17 3.1307312     0     All experimental #> 18 2.9814824     0     All experimental #> 19 2.9608820     0     All      control #> 20 0.3731280     1     All      control"},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_event.html","id":null,"dir":"Reference","previous_headings":"","what":"Cut a dataset for analysis at a specified event count — cut_data_by_event","title":"Cut a dataset for analysis at a specified event count — cut_data_by_event","text":"Takes time--event data set cuts data event count reached.","code":""},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_event.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cut a dataset for analysis at a specified event count — cut_data_by_event","text":"","code":"cut_data_by_event(x, event)"},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_event.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cut a dataset for analysis at a specified event count — cut_data_by_event","text":"x time--event dataset, example, generated sim_pw_surv(). event Event count data cutoff made.","code":""},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_event.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cut a dataset for analysis at a specified event count — cut_data_by_event","text":"data frame ready survival analysis, including columns time event (tte), event, stratum, treatment. class data frame tte_data, attribute ratio generated sim_pw_surv() also attached.","code":""},{"path":"https://merck.github.io/simtrial/reference/cut_data_by_event.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cut a dataset for analysis at a specified event count — cut_data_by_event","text":"","code":"# Use default enrollment and event rates at cut at 100 events x <- sim_pw_surv(n = 200) |> cut_data_by_event(100) table(x$event, x$treatment) #>     #>     control experimental #>   0      44           48 #>   1      52           48"},{"path":"https://merck.github.io/simtrial/reference/early_zero.html","id":null,"dir":"Reference","previous_headings":"","what":"Zero early weighting function — early_zero","title":"Zero early weighting function — early_zero","text":"Zero early weighting function","code":""},{"path":"https://merck.github.io/simtrial/reference/early_zero.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Zero early weighting function — early_zero","text":"","code":"early_zero(early_period, fail_rate = NULL)"},{"path":"https://merck.github.io/simtrial/reference/early_zero.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Zero early weighting function — early_zero","text":"early_period initial delay period weights increase; , weights constant final weight delay period. fail_rate Failure rate","code":""},{"path":"https://merck.github.io/simtrial/reference/early_zero.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Zero early weighting function — early_zero","text":"list parameters zero early weighting function","code":""},{"path":"https://merck.github.io/simtrial/reference/early_zero.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Zero early weighting function — early_zero","text":"Xu, Z., Zhen, B., Park, Y., & Zhu, B. (2017). \"Designing therapeutic cancer vaccine trials delayed treatment effect.\"","code":""},{"path":"https://merck.github.io/simtrial/reference/early_zero.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Zero early weighting function — early_zero","text":"","code":"library(gsDesign2) #>  #> Attaching package: ‘gsDesign2’ #> The following object is masked from ‘package:simtrial’: #>  #>     as_gt  # Example 1: Unstratified ---- sim_pw_surv(n = 200) |>   cut_data_by_event(125) |>   wlr(weight = early_zero(early_period = 2)) #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"Xu 2017 with first 2 months of 0 weights\" #>  #> $estimate #> [1] -19.03831 #>  #> $se #> [1] 4.794997 #>  #> $z #> [1] 3.970454 #>  #> $info #> [1] 22.73958 #>  #> $info0 #> [1] 24 #>   # Example 2: Stratified ---- n <- 500 # Two strata stratum <- c(\"Biomarker-positive\", \"Biomarker-negative\") prevalence_ratio <- c(0.6, 0.4)  # Enrollment rate enroll_rate <- define_enroll_rate(   stratum = rep(stratum, each = 2),   duration = c(2, 10, 2, 10),   rate = c(c(1, 4) * prevalence_ratio[1], c(1, 4) * prevalence_ratio[2]) ) enroll_rate$rate <- enroll_rate$rate * n / sum(enroll_rate$duration * enroll_rate$rate)  # Failure rate med_pos <- 10 # Median of the biomarker positive population med_neg <- 8 # Median of the biomarker negative population hr_pos <- c(1, 0.7) # Hazard ratio of the biomarker positive population hr_neg <- c(1, 0.8) # Hazard ratio of the biomarker negative population fail_rate <- define_fail_rate(   stratum = rep(stratum, each = 2),   duration = c(3, 1000, 4, 1000),   fail_rate = c(log(2) / c(med_pos, med_pos, med_neg, med_neg)),   hr = c(hr_pos, hr_neg),   dropout_rate = 0.01 )  # Simulate data temp <- to_sim_pw_surv(fail_rate) # Convert the failure rate set.seed(2023)  sim_pw_surv(   n = n, # Sample size   # Stratified design with prevalence ratio of 6:4   stratum = data.frame(stratum = stratum, p = prevalence_ratio),   # Randomization ratio   block = c(\"control\", \"control\", \"experimental\", \"experimental\"),   enroll_rate = enroll_rate, # Enrollment rate   fail_rate = temp$fail_rate, # Failure rate   dropout_rate = temp$dropout_rate # Dropout rate ) |>   cut_data_by_event(125) |>   wlr(weight = early_zero(early_period = 2, fail_rate = fail_rate)) #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"Xu 2017 with first 2 months of 0 weights\" #>  #> $estimate #> [1] 1.207753 #>  #> $se #> [1] 1.133941 #>  #> $z #> [1] -1.065093 #>  #> $info #> [1] 1.285211 #>  #> $info0 #> [1] 1.298506 #>"},{"path":"https://merck.github.io/simtrial/reference/ex1_delayed_effect.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-to-event data example 1 for non-proportional hazards working group — ex1_delayed_effect","title":"Time-to-event data example 1 for non-proportional hazards working group — ex1_delayed_effect","text":"Survival objects reverse-engineered datasets published Kaplan-Meier curves. Individual trials de-identified since data approximations actual data. Data intended evaluate methods designs trials non-proportional hazards may anticipated outcome data.","code":""},{"path":"https://merck.github.io/simtrial/reference/ex1_delayed_effect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-to-event data example 1 for non-proportional hazards working group — ex1_delayed_effect","text":"","code":"data(ex1_delayed_effect)"},{"path":"https://merck.github.io/simtrial/reference/ex1_delayed_effect.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Time-to-event data example 1 for non-proportional hazards working group — ex1_delayed_effect","text":"Data frame 4 variables: id: Sequential numbering unique identifiers. month: Time--event. event: 1 event, 0 censored. trt: 1 experimental, 0 control.","code":""},{"path":"https://merck.github.io/simtrial/reference/ex1_delayed_effect.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Time-to-event data example 1 for non-proportional hazards working group — ex1_delayed_effect","text":"Lin, Ray S., Ji Lin, Satrajit Roychoudhury, Keaven M. Anderson, Tianle Hu, Bo Huang, Larry F Leon, Jason J.Z. Liao, Rong Liu, Xiaodong Luo, Pralay Mukhopadhyay, Rui Qin, Kay Tatsuoka, Xuejing Wang, Yang Wang, Jian Zhu, Tai-Tsang Chen, Renee Iacona & Cross-Pharma Non-proportional Hazards Working Group. 2020. Alternative analysis methods time event endpoints nonproportional hazards: comparative analysis. Statistics Biopharmaceutical Research 12(2): 187–198.","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/reference/ex1_delayed_effect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-to-event data example 1 for non-proportional hazards working group — ex1_delayed_effect","text":"","code":"library(survival) #>  #> Attaching package: ‘survival’ #> The following object is masked from ‘package:future’: #>  #>     cluster  data(ex1_delayed_effect) km1 <- with(ex1_delayed_effect, survfit(Surv(month, evntd) ~ trt)) km1 #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>         n events median 0.95LCL 0.95UCL #> trt=0 121     86   5.04    4.18    6.21 #> trt=1 240    132   7.66    6.54    9.48 plot(km1)  with(subset(ex1_delayed_effect, trt == 1), survfit(Surv(month, evntd) ~ trt)) #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>        n events median 0.95LCL 0.95UCL #> [1,] 240    132   7.66    6.54    9.48 with(subset(ex1_delayed_effect, trt == 0), survfit(Surv(month, evntd) ~ trt)) #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>        n events median 0.95LCL 0.95UCL #> [1,] 121     86   5.04    4.18    6.21"},{"path":"https://merck.github.io/simtrial/reference/ex2_delayed_effect.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-to-event data example 2 for non-proportional hazards working group — ex2_delayed_effect","title":"Time-to-event data example 2 for non-proportional hazards working group — ex2_delayed_effect","text":"Survival objects reverse-engineered datasets published Kaplan-Meier curves. Individual trials de-identified since data approximations actual data. Data intended evaluate methods designs trials non-proportional hazards may anticipated outcome data.","code":""},{"path":"https://merck.github.io/simtrial/reference/ex2_delayed_effect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-to-event data example 2 for non-proportional hazards working group — ex2_delayed_effect","text":"","code":"data(ex2_delayed_effect)"},{"path":"https://merck.github.io/simtrial/reference/ex2_delayed_effect.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Time-to-event data example 2 for non-proportional hazards working group — ex2_delayed_effect","text":"Data frame 4 variables: id: Sequential numbering unique identifiers. month: Time--event. event: 1 event, 0 censored. trt: 1 experimental, 0 control.","code":""},{"path":"https://merck.github.io/simtrial/reference/ex2_delayed_effect.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Time-to-event data example 2 for non-proportional hazards working group — ex2_delayed_effect","text":"Lin, Ray S., Ji Lin, Satrajit Roychoudhury, Keaven M. Anderson, Tianle Hu, Bo Huang, Larry F Leon, Jason J.Z. Liao, Rong Liu, Xiaodong Luo, Pralay Mukhopadhyay, Rui Qin, Kay Tatsuoka, Xuejing Wang, Yang Wang, Jian Zhu, Tai-Tsang Chen, Renee Iacona & Cross-Pharma Non-proportional Hazards Working Group. 2020. Alternative analysis methods time event endpoints nonproportional hazards: comparative analysis. Statistics Biopharmaceutical Research 12(2): 187–198.","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/reference/ex2_delayed_effect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-to-event data example 2 for non-proportional hazards working group — ex2_delayed_effect","text":"","code":"library(survival)  data(ex2_delayed_effect) km1 <- with(ex2_delayed_effect, survfit(Surv(month, evntd) ~ trt)) km1 #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>         n events median 0.95LCL 0.95UCL #> trt=0 137    123   2.84    2.18    3.50 #> trt=1 135    105   3.45    2.13    5.07 plot(km1)  with(subset(ex2_delayed_effect, trt == 1), survfit(Surv(month, evntd) ~ trt)) #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>        n events median 0.95LCL 0.95UCL #> [1,] 135    105   3.45    2.13    5.07 with(subset(ex2_delayed_effect, trt == 0), survfit(Surv(month, evntd) ~ trt)) #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>        n events median 0.95LCL 0.95UCL #> [1,] 137    123   2.84    2.18     3.5"},{"path":"https://merck.github.io/simtrial/reference/ex3_cure_with_ph.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-to-event data example 3 for non-proportional hazards working group — ex3_cure_with_ph","title":"Time-to-event data example 3 for non-proportional hazards working group — ex3_cure_with_ph","text":"Survival objects reverse-engineered datasets published Kaplan-Meier curves. Individual trials de-identified since data approximations actual data. Data intended evaluate methods designs trials non-proportional hazards may anticipated outcome data.","code":""},{"path":"https://merck.github.io/simtrial/reference/ex3_cure_with_ph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-to-event data example 3 for non-proportional hazards working group — ex3_cure_with_ph","text":"","code":"data(ex3_cure_with_ph)"},{"path":"https://merck.github.io/simtrial/reference/ex3_cure_with_ph.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Time-to-event data example 3 for non-proportional hazards working group — ex3_cure_with_ph","text":"Data frame 4 variables: id: Sequential numbering unique identifiers. month: Time--event. event: 1 event, 0 censored. trt: 1 experimental, 0 control.","code":""},{"path":"https://merck.github.io/simtrial/reference/ex3_cure_with_ph.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Time-to-event data example 3 for non-proportional hazards working group — ex3_cure_with_ph","text":"Lin, Ray S., Ji Lin, Satrajit Roychoudhury, Keaven M. Anderson, Tianle Hu, Bo Huang, Larry F Leon, Jason J.Z. Liao, Rong Liu, Xiaodong Luo, Pralay Mukhopadhyay, Rui Qin, Kay Tatsuoka, Xuejing Wang, Yang Wang, Jian Zhu, Tai-Tsang Chen, Renee Iacona & Cross-Pharma Non-proportional Hazards Working Group. 2020. Alternative analysis methods time event endpoints nonproportional hazards: comparative analysis. Statistics Biopharmaceutical Research 12(2): 187–198.","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/reference/ex3_cure_with_ph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-to-event data example 3 for non-proportional hazards working group — ex3_cure_with_ph","text":"","code":"library(survival)  data(ex3_cure_with_ph) km1 <- with(ex3_cure_with_ph, survfit(Surv(month, evntd) ~ trt)) km1 #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>         n events median 0.95LCL 0.95UCL #> trt=0 137    101   1.05   0.523    1.74 #> trt=1 143     86   1.74   1.158    3.13 plot(km1)"},{"path":"https://merck.github.io/simtrial/reference/ex4_belly.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-to-event data example 4 for non-proportional hazards working group — ex4_belly","title":"Time-to-event data example 4 for non-proportional hazards working group — ex4_belly","text":"Survival objects reverse-engineered datasets published Kaplan-Meier curves. Individual trials de-identified since data approximations actual data. Data intended evaluate methods designs trials non-proportional hazards may anticipated outcome data.","code":""},{"path":"https://merck.github.io/simtrial/reference/ex4_belly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-to-event data example 4 for non-proportional hazards working group — ex4_belly","text":"","code":"data(ex4_belly)"},{"path":"https://merck.github.io/simtrial/reference/ex4_belly.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Time-to-event data example 4 for non-proportional hazards working group — ex4_belly","text":"Data frame 4 variables: id: Sequential numbering unique identifiers. month: Time--event. event: 1 event, 0 censored. trt: 1 experimental, 0 control.","code":""},{"path":"https://merck.github.io/simtrial/reference/ex4_belly.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Time-to-event data example 4 for non-proportional hazards working group — ex4_belly","text":"Lin, Ray S., Ji Lin, Satrajit Roychoudhury, Keaven M. Anderson, Tianle Hu, Bo Huang, Larry F Leon, Jason J.Z. Liao, Rong Liu, Xiaodong Luo, Pralay Mukhopadhyay, Rui Qin, Kay Tatsuoka, Xuejing Wang, Yang Wang, Jian Zhu, Tai-Tsang Chen, Renee Iacona & Cross-Pharma Non-proportional Hazards Working Group. 2020. Alternative analysis methods time event endpoints nonproportional hazards: comparative analysis. Statistics Biopharmaceutical Research 12(2): 187–198.","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/reference/ex4_belly.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-to-event data example 4 for non-proportional hazards working group — ex4_belly","text":"","code":"library(survival)  data(ex4_belly) km1 <- with(ex4_belly, survfit(Surv(month, evntd) ~ trt)) km1 #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>         n events median 0.95LCL 0.95UCL #> trt=0 387    339   5.40    4.61    5.55 #> trt=1 387    327   6.42    5.81    6.91 plot(km1)"},{"path":"https://merck.github.io/simtrial/reference/ex5_widening.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-to-event data example 5 for non-proportional hazards working group — ex5_widening","title":"Time-to-event data example 5 for non-proportional hazards working group — ex5_widening","text":"Survival objects reverse-engineered datasets published Kaplan-Meier curves. Individual trials de-identified since data approximations actual data. Data intended evaluate methods designs trials non-proportional hazards may anticipated outcome data.","code":""},{"path":"https://merck.github.io/simtrial/reference/ex5_widening.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-to-event data example 5 for non-proportional hazards working group — ex5_widening","text":"","code":"data(ex5_widening)"},{"path":"https://merck.github.io/simtrial/reference/ex5_widening.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Time-to-event data example 5 for non-proportional hazards working group — ex5_widening","text":"Data frame 4 variables: id: Sequential numbering unique identifiers. month: Time--event. event: 1 event, 0 censored. trt: 1 experimental, 0 control.","code":""},{"path":"https://merck.github.io/simtrial/reference/ex5_widening.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Time-to-event data example 5 for non-proportional hazards working group — ex5_widening","text":"Lin, Ray S., Ji Lin, Satrajit Roychoudhury, Keaven M. Anderson, Tianle Hu, Bo Huang, Larry F Leon, Jason J.Z. Liao, Rong Liu, Xiaodong Luo, Pralay Mukhopadhyay, Rui Qin, Kay Tatsuoka, Xuejing Wang, Yang Wang, Jian Zhu, Tai-Tsang Chen, Renee Iacona & Cross-Pharma Non-proportional Hazards Working Group. 2020. Alternative analysis methods time event endpoints nonproportional hazards: comparative analysis. Statistics Biopharmaceutical Research 12(2): 187–198.","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/reference/ex5_widening.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-to-event data example 5 for non-proportional hazards working group — ex5_widening","text":"","code":"library(survival)  data(ex5_widening) km1 <- with(ex5_widening, survfit(Surv(month, evntd) ~ trt)) km1 #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>        n events median 0.95LCL 0.95UCL #> trt=0 79     65   8.16    6.65    10.3 #> trt=1 86     48  19.97   17.07    26.6 plot(km1)"},{"path":"https://merck.github.io/simtrial/reference/ex6_crossing.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-to-event data example 6 for non-proportional hazards working group — ex6_crossing","title":"Time-to-event data example 6 for non-proportional hazards working group — ex6_crossing","text":"Survival objects reverse-engineered datasets published Kaplan-Meier curves. Individual trials de-identified since data approximations actual data. Data intended evaluate methods designs trials non-proportional hazards may anticipated outcome data.","code":""},{"path":"https://merck.github.io/simtrial/reference/ex6_crossing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-to-event data example 6 for non-proportional hazards working group — ex6_crossing","text":"","code":"data(ex6_crossing)"},{"path":"https://merck.github.io/simtrial/reference/ex6_crossing.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Time-to-event data example 6 for non-proportional hazards working group — ex6_crossing","text":"Data frame 4 variables: id: Sequential numbering unique identifiers. month: Time--event. event: 1 event, 0 censored. trt: 1 experimental, 0 control.","code":""},{"path":"https://merck.github.io/simtrial/reference/ex6_crossing.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Time-to-event data example 6 for non-proportional hazards working group — ex6_crossing","text":"Lin, Ray S., Ji Lin, Satrajit Roychoudhury, Keaven M. Anderson, Tianle Hu, Bo Huang, Larry F Leon, Jason J.Z. Liao, Rong Liu, Xiaodong Luo, Pralay Mukhopadhyay, Rui Qin, Kay Tatsuoka, Xuejing Wang, Yang Wang, Jian Zhu, Tai-Tsang Chen, Renee Iacona & Cross-Pharma Non-proportional Hazards Working Group. 2020. Alternative analysis methods time event endpoints nonproportional hazards: comparative analysis. Statistics Biopharmaceutical Research 12(2): 187–198.","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/reference/ex6_crossing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-to-event data example 6 for non-proportional hazards working group — ex6_crossing","text":"","code":"library(survival)  data(ex6_crossing) km1 <- with(ex6_crossing, survfit(Surv(month, evntd) ~ trt)) km1 #> Call: survfit(formula = Surv(month, evntd) ~ trt) #>  #>         n events median 0.95LCL 0.95UCL #> trt=0 145    111  10.66    8.83    12.5 #> trt=1 145    113   9.92    7.38    14.3 plot(km1)"},{"path":"https://merck.github.io/simtrial/reference/fh.html","id":null,"dir":"Reference","previous_headings":"","what":"Fleming-Harrington weighting function — fh","title":"Fleming-Harrington weighting function — fh","text":"Fleming-Harrington weighting function","code":""},{"path":"https://merck.github.io/simtrial/reference/fh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fleming-Harrington weighting function — fh","text":"","code":"fh(rho = 0, gamma = 0)"},{"path":"https://merck.github.io/simtrial/reference/fh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fleming-Harrington weighting function — fh","text":"rho Non-negative number. rho = 0, gamma = 0 equivalent regular logrank test. gamma Non-negative number. rho = 0, gamma = 0 equivalent regular logrank test.","code":""},{"path":"https://merck.github.io/simtrial/reference/fh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fleming-Harrington weighting function — fh","text":"list parameters Fleming-Harrington weighting function","code":""},{"path":"https://merck.github.io/simtrial/reference/fh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fleming-Harrington weighting function — fh","text":"","code":"sim_pw_surv(n = 200) |>   cut_data_by_event(100) |>   wlr(weight = fh(rho = 0, gamma = 1)) #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"FH(rho=0, gamma=1)\" #>  #> $estimate #> [1] -2.354546 #>  #> $se #> [1] 1.596507 #>  #> $z #> [1] 1.474812 #>  #> $info #> [1] 2.598126 #>  #> $info0 #> [1] 2.625333 #>"},{"path":"https://merck.github.io/simtrial/reference/fit_pwexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Piecewise exponential survival estimation — fit_pwexp","title":"Piecewise exponential survival estimation — fit_pwexp","text":"Computes survival function, density function, -2 * log-likelihood based input dataset intervals piecewise constant failure rates. Initial version assumes observations right censored events .","code":""},{"path":"https://merck.github.io/simtrial/reference/fit_pwexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Piecewise exponential survival estimation — fit_pwexp","text":"","code":"fit_pwexp(   srv = Surv(time = ex1_delayed_effect$month, event = ex1_delayed_effect$evntd),   intervals = array(3, 3) )"},{"path":"https://merck.github.io/simtrial/reference/fit_pwexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Piecewise exponential survival estimation — fit_pwexp","text":"srv Input survival object (see survival::Surv()); note 0 = censored, 1 = event survival::Surv(). intervals Vector containing positive values indicating interval lengths exponential rates assumed. Note final infinite interval added events occur final interval specified.","code":""},{"path":"https://merck.github.io/simtrial/reference/fit_pwexp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Piecewise exponential survival estimation — fit_pwexp","text":"matrix rows containing interval length, estimated rate, -2 * log-likelihood interval.","code":""},{"path":"https://merck.github.io/simtrial/reference/fit_pwexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Piecewise exponential survival estimation — fit_pwexp","text":"","code":"# Use default arguments for delayed effect example dataset (ex1_delayed_effect) library(survival)  # Example 1 rateall <- fit_pwexp() rateall #>   intervals     ttot event       rate     m2ll #> 1         3 937.1785    97 0.10350216 634.0236 #> 2         3 605.3572    71 0.11728612 446.3257 #> 3         3 346.8482    30 0.08649317 206.8614 #> 4       Inf 254.1148    20 0.07870458 141.6822  # Example 2 # Estimate by treatment effect rate1 <- with(subset(ex1_delayed_effect, trt == 1), fit_pwexp(Surv(month, evntd))) rate0 <- with(subset(ex1_delayed_effect, trt == 0), fit_pwexp(Surv(month, evntd)))  rate1 #>   intervals     ttot event       rate      m2ll #> 1         3 620.4375    64 0.10315302 418.75734 #> 2         3 415.8482    36 0.08657005 248.16970 #> 3         3 256.2053    19 0.07415927 136.85853 #> 4       Inf 205.4186    13 0.06328542  97.76261 rate0 #>   intervals      ttot event      rate      m2ll #> 1         3 316.74106    33 0.1041861 215.26408 #> 2         3 189.50899    35 0.1846878 188.23619 #> 3         3  90.64288    11 0.1213554  68.39871 #> 4       Inf  48.69624     7 0.1437483  41.15568 rate1$rate / rate0$rate #> [1] 0.9900847 0.4687372 0.6110917 0.4402517  # Chi-square test for (any) treatment effect (8 - 4 parameters = 4 df) pchisq(sum(rateall$m2ll) - sum(rate1$m2ll + rate0$m2ll),   df = 4,   lower.tail = FALSE ) #> [1] 0.006424744  # Compare with logrank survdiff(formula = Surv(month, evntd) ~ trt, data = ex1_delayed_effect) #> Call: #> survdiff(formula = Surv(month, evntd) ~ trt, data = ex1_delayed_effect) #>  #>         N Observed Expected (O-E)^2/E (O-E)^2/V #> trt=0 121       86     67.7      4.97      7.35 #> trt=1 240      132    150.3      2.24      7.35 #>  #>  Chisq= 7.3  on 1 degrees of freedom, p= 0.007   # Example 3 # Simple model with 3 rates same for each for 3 months, # different for each treatment after months rate1a <- with(subset(ex1_delayed_effect, trt == 1), fit_pwexp(Surv(month, evntd), 3)) rate0a <- with(subset(ex1_delayed_effect, trt == 0), fit_pwexp(Surv(month, evntd), 3)) rate1a$rate / rate0a$rate #> [1] 0.9900847 0.4808339  m2ll0 <- rateall$m2ll[1] + rate1a$m2ll[2] + rate0a$m2ll[2] m2ll1 <- sum(rate0$m2ll) + sum(rate1$m2ll)  # As a measure of strength, chi-square examines improvement in likelihood pchisq(m2ll0 - m2ll1, df = 5, lower.tail = FALSE) #> [1] 0.741822"},{"path":"https://merck.github.io/simtrial/reference/get_analysis_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Derive analysis date for interim/final analysis given multiple conditions — get_analysis_date","title":"Derive analysis date for interim/final analysis given multiple conditions — get_analysis_date","text":"Derive analysis date interim/final analysis given multiple conditions","code":""},{"path":"https://merck.github.io/simtrial/reference/get_analysis_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Derive analysis date for interim/final analysis given multiple conditions — get_analysis_date","text":"","code":"get_analysis_date(   data,   planned_calendar_time = NA,   target_event_overall = NA,   target_event_per_stratum = NA,   max_extension_for_target_event = NA,   previous_analysis_date = 0,   min_time_after_previous_analysis = NA,   min_n_overall = NA,   min_n_per_stratum = NA,   min_followup = NA )"},{"path":"https://merck.github.io/simtrial/reference/get_analysis_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Derive analysis date for interim/final analysis given multiple conditions — get_analysis_date","text":"data simulated data generated sim_pw_surv(). planned_calendar_time numerical value specifying planned calendar time analysis. target_event_overall numerical value specifying targeted events overall population. target_event_per_stratum numerical vector specifying targeted events per stratum. max_extension_for_target_event numerical value specifying maximum time extension reach targeted events. previous_analysis_date numerical value specifying previous analysis date. min_time_after_previous_analysis numerical value specifying planned minimum time previous analysis. min_n_overall numerical value specifying minimal overall sample size enrolled kick analysis. min_n_per_stratum numerical value specifying minimal sample size enrolled per stratum kick analysis. min_followup numerical value specifying minimal follow-time specified enrollment fraction min_n_overall min_n_per_stratum.","code":""},{"path":"https://merck.github.io/simtrial/reference/get_analysis_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Derive analysis date for interim/final analysis given multiple conditions — get_analysis_date","text":"numerical value analysis date.","code":""},{"path":"https://merck.github.io/simtrial/reference/get_analysis_date.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Derive analysis date for interim/final analysis given multiple conditions — get_analysis_date","text":"obtain analysis date, consider following multiple conditions: Condition 1 planned calendar time analysis. Condition 2 targeted events, encompassing overall population stratum-specific events. Condition 3 maximum time extension required achieve targeted events. Condition 4 planned minimum time interval previous analysis. Condition 5 minimum follow-time needed reach certain number patients enrollments. Users flexibility employ 5 conditions simultaneously selectively choose specific conditions determine analysis date. unused conditions default NA affect output. Regardless number conditions used, analysis date determined min(max(date1, date2, date4, date5, na.rm = TRUE), date3, na.rm = TRUE), date1, date2, date3, date4, date5 represent analysis dates determined solely Condition 1, Condition 2, Condition 3, Condition 4 Condition 5, respectively.","code":""},{"path":"https://merck.github.io/simtrial/reference/get_analysis_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Derive analysis date for interim/final analysis given multiple conditions — get_analysis_date","text":"","code":"library(gsDesign2)  alpha <- 0.025 ratio <- 3 n <- 500 info_frac <- c(0.7, 1) prevalence_ratio <- c(0.4, 0.6) study_duration <- 48  # Two strata stratum <- c(\"Biomarker-positive\", \"Biomarker-negative\")  prevalence_ratio <- c(0.6, 0.4) # enrollment rate enroll_rate <- define_enroll_rate(   stratum = rep(stratum, each = 2),   duration = c(2, 10, 2, 10),   rate = c(c(1, 4) * prevalence_ratio[1], c(1, 4) * prevalence_ratio[2]) ) enroll_rate$rate <- enroll_rate$rate * n / sum(enroll_rate$duration * enroll_rate$rate)  # Failure rate med_pos <- 10 # Median of the biomarker positive population med_neg <- 8 # Median of the biomarker negative population hr_pos <- c(1, 0.7) # Hazard ratio of the biomarker positive population hr_neg <- c(1, 0.8) # Hazard ratio of the biomarker negative population fail_rate <- define_fail_rate(   stratum = rep(stratum, each = 2),   duration = 1000,   fail_rate = c(log(2) / c(med_pos, med_pos, med_neg, med_neg)),   hr = c(hr_pos, hr_neg),   dropout_rate = 0.01 )  # Simulate data temp <- to_sim_pw_surv(fail_rate) # Convert the failure rate set.seed(2023) simulated_data <- sim_pw_surv(   n = n, # Sample size   # Stratified design with prevalence ratio of 6:4   stratum = data.frame(stratum = stratum, p = prevalence_ratio),   # Randomization ratio   block = c(\"control\", \"control\", \"experimental\", \"experimental\"),   enroll_rate = enroll_rate, # Enrollment rate   fail_rate = temp$fail_rate, # Failure rate   dropout_rate = temp$dropout_rate # Dropout rate )  # Example 1: Cut for analysis at the 24th month. # Here, we only utilize the `planned_calendar_time = 24` argument, # while leaving the remaining unused arguments as their default value of `NA`. get_analysis_date(   simulated_data,   planned_calendar_time = 24 ) #> [1] 24  # Example 2: Cut for analysis when there are 300 events in the overall population. # Here, we only utilize the `target_event_overall = 300` argument, # while leaving the remaining unused arguments as their default value of `NA`. get_analysis_date(   simulated_data,   target_event_overall = 300 ) #> [1] 25.61506  # Example 3: Cut for analysis at the 24th month and there are 300 events # in the overall population, whichever arrives later. # Here, we only utilize the `planned_calendar_time = 24` and # `target_event_overall = 300` argument, # while leaving the remaining unused arguments as their default value of `NA`. get_analysis_date(   simulated_data,   planned_calendar_time = 24,   target_event_overall = 300 ) #> [1] 25.61506  # Example 4a: Cut for analysis when there are at least 100 events # in the biomarker-positive population, and at least 200 events # in the biomarker-negative population, whichever arrives later. # Here, we only utilize the `target_event_per_stratum = c(100, 200)`, # which refers to 100 events in the biomarker-positive population, # and 200 events in the biomarker-negative population. # The remaining unused arguments as their default value of `NA`, # so the analysis date is only decided by the number of events # in each stratum. get_analysis_date(   simulated_data,   target_event_per_stratum = c(100, 200) ) #> [1] 30.78865 # Example 4b: Cut for analysis when there are at least 100 events # in the biomarker-positive population, but we don't have a requirement # for the biomarker-negative population. Additionally, we want to cut # the analysis when there are at least 150 events in total. # Here, we only utilize the `target_event_overall = 150` and # `target_event_per_stratum = c(100, NA)`, which refers to 100 events # in the biomarker-positive population, and there is event requirement # for the biomarker-negative population. # The remaining unused arguments as their default value of `NA`, # so the analysis date is only decided by the number of events # in the biomarker-positive population, and the total number of events, # which arrives later. get_analysis_date(   simulated_data,   target_event_overall = 150,   target_event_per_stratum = c(100, NA) ) #> [1] 18.30272 # Example 4c: Cut for analysis when there are at least 100 events # in the biomarker-positive population, but we don't have a requirement # for the biomarker-negative population. Additionally, we want to cut # the analysis when there are at least 150 events in total and after 24 months. # Here, we only utilize the `planned_calendar_time = 24`, # `target_event_overall = 150` and # `target_event_per_stratum = c(100, NA)`, which refers to 100 events # in the biomarker-positive population, and there is event requirement # for the biomarker-negative population. # The remaining unused arguments as their default value of `NA`, # so the analysis date is only decided by the number of events # in the biomarker-positive population, the total number of events, and # planned calendar time, which arrives later. get_analysis_date(   simulated_data,   planned_calendar_time = 24,   target_event_overall = 150,   target_event_per_stratum = c(100, NA) ) #> [1] 24  # Example 5: Cut for analysis when there are at least 100 events # in the biomarker positive population, and at least 200 events # in the biomarker negative population, whichever arrives later. # But will stop at the 30th month if events are fewer than 100/200. # Here, we only utilize the `max_extension_for_target_event = 30`, # and `target_event_per_stratum =  c(100, 200)`, which refers to # 100/200 events in the biomarker-positive/negative population. # The remaining unused arguments as their default value of `NA`, # so the analysis date is only decided by the number of events # in the 2 strata, and the max extension to arrive at the targeted # events, which arrives later. get_analysis_date(   simulated_data,   target_event_per_stratum = c(100, 200),   max_extension_for_target_event = 30 ) #> [1] 30  # Example 6a: Cut for analysis after 12 months followup when 80% # of the patients are enrolled in the overall population. # The remaining unused arguments as their default value of `NA`, # so the analysis date is only decided by # 12 months + time when 80% patients enrolled. get_analysis_date(   simulated_data,   min_n_overall = n * 0.8,   min_followup = 12 ) #> [1] 28.82521 # Example 6b: Cut for analysis after 12 months followup when 80% # of the patients are enrolled in the overall population. Besides, # the analysis happens when there are at least 150 events in total. # The remaining unused arguments as their default value of `NA`, # so the analysis date is only decided by the total number of events, # and 12 months + time when 80% patients enrolled, which arrives later. get_analysis_date(   simulated_data,   target_event_overall = 150,   min_n_overall = n * 0.8,   min_followup = 12 ) #> [1] 28.82521  # Example 7a: Cut for analysis when 12 months after at least 200/160 patients # are enrolled in the biomarker positive/negative population. # The remaining unused arguments as their default value of `NA`, # so the analysis date is only decided by 12 months + time when there are # 200/160 patients enrolled in the biomarker-positive/negative stratum. get_analysis_date(   simulated_data,   min_n_per_stratum = c(200, 160),   min_followup = 12 ) #> [1] 27.33728 # Example 7b: Cut for analysis when 12 months after at least 200 patients # are enrolled in the biomarker positive population, but we don't have a # specific requirement for the biomarker negative population. # The remaining unused arguments as their default value of `NA`, # so the analysis date is only decided by 12 months + time when there are # 200 patients enrolled in the biomarker-positive stratum. get_analysis_date(   simulated_data,   min_n_per_stratum = c(200, NA),   min_followup = 12 ) #> [1] 27.33728 # Example 7c: Cut for analysis when 12 months after at least 200 patients # are enrolled in the biomarker-positive population, but we don't have a # specific requirement for the biomarker-negative population. We also want # there are at least 80% of the patients enrolled in the overall population. # The remaining unused arguments as their default value of `NA`, # so the analysis date is only decided by 12 months + max(time when there are # 200 patients enrolled in the biomarker-positive stratum, time when there are # 80% patients enrolled). get_analysis_date(   simulated_data,   min_n_overall = n * 0.8,   min_n_per_stratum = c(200, NA),   min_followup = 12 ) #> [1] 28.82521"},{"path":"https://merck.github.io/simtrial/reference/get_cut_date_by_event.html","id":null,"dir":"Reference","previous_headings":"","what":"Get date at which an event count is reached — get_cut_date_by_event","title":"Get date at which an event count is reached — get_cut_date_by_event","text":"Get date event count reached","code":""},{"path":"https://merck.github.io/simtrial/reference/get_cut_date_by_event.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get date at which an event count is reached — get_cut_date_by_event","text":"","code":"get_cut_date_by_event(x, event)"},{"path":"https://merck.github.io/simtrial/reference/get_cut_date_by_event.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get date at which an event count is reached — get_cut_date_by_event","text":"x time--event dataset, example, generated sim_pw_surv(). event Event count dataset cut analysis.","code":""},{"path":"https://merck.github.io/simtrial/reference/get_cut_date_by_event.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get date at which an event count is reached — get_cut_date_by_event","text":"numeric value cte input dataset targeted event count reached, final event count never reached, final cte event occurs.","code":""},{"path":"https://merck.github.io/simtrial/reference/get_cut_date_by_event.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get date at which an event count is reached — get_cut_date_by_event","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union  # Use default enrollment and calendar cut date # for 50 events in the \"Positive\" stratum x <- sim_pw_surv(   n = 200,   stratum = data.frame(     stratum = c(\"Positive\", \"Negative\"),     p = c(.5, .5)   ),   fail_rate = data.frame(     stratum = rep(c(\"Positive\", \"Negative\"), 2),     period = rep(1, 4),     treatment = c(rep(\"control\", 2), rep(\"experimental\", 2)),     duration = rep(1, 4),     rate = log(2) / c(6, 9, 9, 12)   ),   dropout_rate = data.frame(     stratum = rep(c(\"Positive\", \"Negative\"), 2),     period = rep(1, 4),     treatment = c(rep(\"control\", 2), rep(\"experimental\", 2)),     duration = rep(1, 4),     rate = rep(.001, 4)   ) )  d <- get_cut_date_by_event(x |> filter(stratum == \"Positive\"), event = 50)  y <- cut_data_by_date(x, cut_date = d) table(y$stratum, y$event) #>            #>             0  1 #>   Negative 50 44 #>   Positive 34 50"},{"path":"https://merck.github.io/simtrial/reference/maxcombo.html","id":null,"dir":"Reference","previous_headings":"","what":"MaxCombo test — maxcombo","title":"MaxCombo test — maxcombo","text":"WARNING: experimental function work--progress. function arguments change add additional features.","code":""},{"path":"https://merck.github.io/simtrial/reference/maxcombo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MaxCombo test — maxcombo","text":"","code":"maxcombo(   data = cut_data_by_event(sim_pw_surv(n = 200), 150),   rho = c(0, 0, 1),   gamma = c(0, 1, 1),   return_variance = FALSE,   return_corr = FALSE )"},{"path":"https://merck.github.io/simtrial/reference/maxcombo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MaxCombo test — maxcombo","text":"data TTE dataset. rho Numeric vector. Must greater equal zero. Must length gamma. gamma Numeric vector. Must greater equal zero. Must length rho. return_variance logical flag , TRUE, adds columns estimated variance weighted sum observed minus expected; see details; Default: FALSE. return_corr logical flag , TRUE, adds columns estimated correlation weighted sum observed minus expected; see details; Default: FALSE.","code":""},{"path":"https://merck.github.io/simtrial/reference/maxcombo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MaxCombo test — maxcombo","text":"list containing test method (method), parameters test method (parameter), point estimate treatment effect (estimate), standardized error treatment effect (se), Z-score test MaxCombo (z), p-values (p_value) correlation matrix tests MaxCombo (begin v)","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/reference/maxcombo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MaxCombo test — maxcombo","text":"","code":"sim_pw_surv(n = 200) |>   cut_data_by_event(150) |>   maxcombo(rho = c(0, 0), gamma = c(0, 1), return_corr = TRUE) #> $method #> [1] \"MaxCombo\" #>  #> $parameter #> [1] \"FH(0, 0) + FH(0, 1)\" #>  #> $z #> [1] -1.429270 -1.925974 #>  #> $corr #>          v1        v2 #> 1 1.0000000 0.8572258 #> 2 0.8572258 1.0000000 #>  #> $p_value #> [1] 0.03992553 #>"},{"path":"https://merck.github.io/simtrial/reference/mb.html","id":null,"dir":"Reference","previous_headings":"","what":"Magirr and Burman weighting function — mb","title":"Magirr and Burman weighting function — mb","text":"Magirr Burman weighting function","code":""},{"path":"https://merck.github.io/simtrial/reference/mb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Magirr and Burman weighting function — mb","text":"","code":"mb(delay = 4, w_max = Inf)"},{"path":"https://merck.github.io/simtrial/reference/mb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Magirr and Burman weighting function — mb","text":"delay initial delay period weights increase; , weights constant final weight delay period. w_max Maximum weight returned. Set delay = Inf, w_max = 2 consistent recommendation Magirr (2021).","code":""},{"path":"https://merck.github.io/simtrial/reference/mb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Magirr and Burman weighting function — mb","text":"list parameters Magirr Burman weighting function","code":""},{"path":"https://merck.github.io/simtrial/reference/mb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Magirr and Burman weighting function — mb","text":"Magirr Burman (2019) proposed weighted logrank test better power logrank test treatment effect delayed, still maintain good power proportional hazards assumption. Magirr (2021), (equivalent ) maximum weight proposed opposed fixed time duration weights increase. weights early interval specified user inverse combined treatment group empirical survival distribution; see details. initial period, weights constant maximum previous weights. Another advantage test strong null hypothesis underlying survival control group greater equal underlying survival experimental group, Type error controlled specified level. define \\(t^*\\) input variable delay. specifies initial period weights increase. also set maximum weight \\(w_{\\max}\\). define specific weights, let \\(S(t)\\) denote Kaplan-Meier survival estimate time \\(t\\) combined data (control plus experimental treatment groups). weight time \\(t\\) defined $$w(t)=\\min(w_{\\max}, S(\\min(t, t^*))^{-1}).$$","code":""},{"path":"https://merck.github.io/simtrial/reference/mb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Magirr and Burman weighting function — mb","text":"Magirr, Dominic, Carl‐Fredrik Burman. 2019. \"Modestly weighted logrank tests.\" Statistics Medicine 38 (20): 3782–3790. Magirr, Dominic. 2021. \"Non‐proportional hazards immuno‐oncology: old perspective needed?\" Pharmaceutical Statistics 20 (3): 512–527.","code":""},{"path":"https://merck.github.io/simtrial/reference/mb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Magirr and Burman weighting function — mb","text":"","code":"sim_pw_surv(n = 200) |>   cut_data_by_event(100) |>   wlr(weight = mb(delay = 8, w_max = Inf)) #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"MB(delay = 8, max_weight = Inf)\" #>  #> $estimate #> [1] -12.94058 #>  #> $se #> [1] 6.689765 #>  #> $z #> [1] 1.934385 #>  #> $info #> [1] 44.70922 #>  #> $info0 #> [1] 45.36046 #>"},{"path":"https://merck.github.io/simtrial/reference/mb_delayed_effect.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated survival dataset with delayed treatment effect — mb_delayed_effect","title":"Simulated survival dataset with delayed treatment effect — mb_delayed_effect","text":"Magirr Burman (2019) considered several scenarios modestly weighted logrank test. One delayed treatment effect hazard ratio 1 6 months followed hazard ratio 1/2 thereafter. scenario enrolled 200 patients uniformly 12 months cut data analysis 36 months enrollment opened. dataset generated sim_pw_surv() function scenario.","code":""},{"path":"https://merck.github.io/simtrial/reference/mb_delayed_effect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated survival dataset with delayed treatment effect — mb_delayed_effect","text":"","code":"mb_delayed_effect"},{"path":"https://merck.github.io/simtrial/reference/mb_delayed_effect.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated survival dataset with delayed treatment effect — mb_delayed_effect","text":"data frame 200 rows 4 columns: tte: Time event.","code":""},{"path":"https://merck.github.io/simtrial/reference/mb_delayed_effect.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulated survival dataset with delayed treatment effect — mb_delayed_effect","text":"Magirr, Dominic, Carl‐Fredrik Burman. 2019. \"Modestly weighted logrank tests.\" Statistics Medicine 38 (20): 3782–3790.","code":""},{"path":"https://merck.github.io/simtrial/reference/mb_delayed_effect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated survival dataset with delayed treatment effect — mb_delayed_effect","text":"","code":"library(survival)  fit <- survfit(Surv(tte, event) ~ treatment, data = mb_delayed_effect)  # Plot survival plot(fit, lty = 1:2) legend(\"topright\", legend = c(\"control\", \"experimental\"), lty = 1:2)   # Set up time, event, number of event dataset for testing # with arbitrary weights ten <- mb_delayed_effect |> counting_process(arm = \"experimental\") head(ten) #>   stratum event_total event_trt        tte n_risk_total n_risk_trt     s #> 1     All           1         1 0.07659251          200        100 1.000 #> 2     All           1         0 0.49067015          199         99 0.995 #> 3     All           1         1 0.65465035          198         99 0.990 #> 4     All           1         0 0.65906384          197         98 0.985 #> 5     All           1         1 0.81945349          196         98 0.980 #> 6     All           1         0 0.82788909          195         97 0.975 #>    o_minus_e var_o_minus_e #> 1  0.5000000     0.2500000 #> 2 -0.4974874     0.2499937 #> 3  0.5000000     0.2500000 #> 4 -0.4974619     0.2499936 #> 5  0.5000000     0.2500000 #> 6 -0.4974359     0.2499934  # MaxCombo with logrank, FH(0,1), FH(1,1) mb_delayed_effect |>   maxcombo(rho = c(0, 0, 1), gamma = c(0, 1, 1), return_corr = TRUE) #> $method #> [1] \"MaxCombo\" #>  #> $parameter #> [1] \"FH(0, 0) + FH(0, 1) + FH(1, 1)\" #>  #> $z #> [1] -2.473248 -2.424018 -2.482653 #>  #> $corr #>          v1        v2        v3 #> 1 1.0000000 0.8606625 0.9312916 #> 2 0.8606625 1.0000000 0.9579831 #> 3 0.9312916 0.9579831 1.0000000 #>  #> $p_value #> [1] 0.01104817 #>   # Generate another dataset ds <- sim_pw_surv(   n = 200,   enroll_rate = data.frame(rate = 200 / 12, duration = 12),   fail_rate = data.frame(     stratum = c(\"All\", \"All\", \"All\"),     period = c(1, 1, 2),     treatment = c(\"control\", \"experimental\", \"experimental\"),     duration = c(42, 6, 36),     rate = c(log(2) / 15, log(2) / 15, log(2) / 15 * 0.6)   ),   dropout_rate = data.frame(     stratum = c(\"All\", \"All\"),     period = c(1, 1),     treatment = c(\"control\", \"experimental\"),     duration = c(42, 42),     rate = c(0, 0)   ) ) # Cut data at 24 months after final enrollment mb_delayed_effect_2 <- ds |> cut_data_by_date(max(ds$enroll_time) + 24)"},{"path":"https://merck.github.io/simtrial/reference/milestone.html","id":null,"dir":"Reference","previous_headings":"","what":"Milestone test for two survival curves — milestone","title":"Milestone test for two survival curves — milestone","text":"Milestone test two survival curves","code":""},{"path":"https://merck.github.io/simtrial/reference/milestone.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Milestone test for two survival curves — milestone","text":"","code":"milestone(data, ms_time, test_type = c(\"log-log\", \"naive\"))"},{"path":"https://merck.github.io/simtrial/reference/milestone.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Milestone test for two survival curves — milestone","text":"data Data frame containing least 3 columns: tte - Time event. event - Event indicator. treatment - Grouping variable. ms_time Milestone analysis time. test_type Method build test statistics. 2 options: \"naive\": naive approach dividing KM survival difference standard derivations, see equation (1) Klein, J. P., Logan, B., Harhoff, M., & Andersen, P. K. (2007). \"log-log\": log-log transformation survival, see equation (3) Klein, J. P., Logan, B., Harhoff, M., & Andersen, P. K. (2007).","code":""},{"path":"https://merck.github.io/simtrial/reference/milestone.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Milestone test for two survival curves — milestone","text":"list frame containing: method - method, always \"milestone\". parameter - Milestone time point. estimate - Survival difference experimental control arm. se - Standard error control experimental arm. z - Test statistics.","code":""},{"path":"https://merck.github.io/simtrial/reference/milestone.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Milestone test for two survival curves — milestone","text":"Klein, J. P., Logan, B., Harhoff, M., & Andersen, P. K. (2007). \"Analyzing survival curves fixed point time.\" Statistics Medicine, 26(24), 4505–4519.","code":""},{"path":"https://merck.github.io/simtrial/reference/milestone.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Milestone test for two survival curves — milestone","text":"","code":"cut_data <- sim_pw_surv(n = 200) |>   cut_data_by_event(150)  cut_data |>   milestone(10, test_type = \"log-log\") #> $method #> [1] \"milestone\" #>  #> $parameter #> [1] 10 #>  #> $estimate #> [1] 0.3090112 #>  #> $se #> [1] 0.2084854 #>  #> $z #> [1] 1.482171 #>   cut_data |>   milestone(10, test_type = \"naive\") #> $method #> [1] \"milestone\" #>  #> $parameter #> [1] 10 #>  #> $estimate #> [1] 0.105612 #>  #> $se #> [1] 0.07066159 #>  #> $z #> [1] 1.494617 #>"},{"path":"https://merck.github.io/simtrial/reference/multitest.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform multiple tests on trial data cutting — multitest","title":"Perform multiple tests on trial data cutting — multitest","text":"WARNING: experimental function work--progress. function arguments /returned output format may change add additional features.","code":""},{"path":"https://merck.github.io/simtrial/reference/multitest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform multiple tests on trial data cutting — multitest","text":"","code":"multitest(data, ...)"},{"path":"https://merck.github.io/simtrial/reference/multitest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform multiple tests on trial data cutting — multitest","text":"data Trial data cut cut_data_by_event() cut_data_by_date() ... One test functions. Use create_test() change default arguments test function.","code":""},{"path":"https://merck.github.io/simtrial/reference/multitest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform multiple tests on trial data cutting — multitest","text":"list test results, one per test. test functions named call multitest(), returned list uses names.","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/reference/multitest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform multiple tests on trial data cutting — multitest","text":"","code":"trial_data <- sim_pw_surv(n = 200) trial_data_cut <- cut_data_by_event(trial_data, 150)  # create cutting test functions wlr_partial <- create_test(wlr, weight = fh(rho = 0, gamma = 0)) rmst_partial <- create_test(rmst, tau = 20) maxcombo_partial <- create_test(maxcombo, rho = c(0, 0), gamma = c(0, 0.5))  multitest(   data = trial_data_cut,   wlr = wlr_partial,   rmst = rmst_partial,   maxcombo = maxcombo_partial ) #> $wlr #> $wlr$method #> [1] \"WLR\" #>  #> $wlr$parameter #> [1] \"FH(rho=0, gamma=0)\" #>  #> $wlr$estimate #> [1] -21.51717 #>  #> $wlr$se #> [1] 5.971903 #>  #> $wlr$z #> [1] 3.603067 #>  #> $wlr$info #> [1] 36.96 #>  #> $wlr$info0 #> [1] 37.5 #>  #>  #> $rmst #> $rmst$method #> [1] \"RMST\" #>  #> $rmst$parameter #> [1] 20 #>  #> $rmst$estimate #> [1] 3.504274 #>  #> $rmst$se #> [1] 1.064673 #>  #> $rmst$z #> [1] 3.291409 #>  #>  #> $maxcombo #> $maxcombo$method #> [1] \"MaxCombo\" #>  #> $maxcombo$parameter #> [1] \"FH(0, 0) + FH(0, 0.5)\" #>  #> $maxcombo$z #> [1] -3.603067 -3.567134 #>  #> $maxcombo$p_value #> [1] 0.0002371133 #>  #>"},{"path":"https://merck.github.io/simtrial/reference/randomize_by_fixed_block.html","id":null,"dir":"Reference","previous_headings":"","what":"Permuted fixed block randomization — randomize_by_fixed_block","title":"Permuted fixed block randomization — randomize_by_fixed_block","text":"Fixed block randomization. block input repeat treatment code number times included within block. final block partial block n exact multiple block length.","code":""},{"path":"https://merck.github.io/simtrial/reference/randomize_by_fixed_block.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Permuted fixed block randomization — randomize_by_fixed_block","text":"","code":"randomize_by_fixed_block(n = 10, block = c(0, 0, 1, 1))"},{"path":"https://merck.github.io/simtrial/reference/randomize_by_fixed_block.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Permuted fixed block randomization — randomize_by_fixed_block","text":"n Sample size randomized. block Vector treatments included block.","code":""},{"path":"https://merck.github.io/simtrial/reference/randomize_by_fixed_block.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Permuted fixed block randomization — randomize_by_fixed_block","text":"treatment group sequence (vector) length n treatments block permuted within block block size equal length block.","code":""},{"path":"https://merck.github.io/simtrial/reference/randomize_by_fixed_block.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Permuted fixed block randomization — randomize_by_fixed_block","text":"","code":"library(dplyr)  # Example 1 # 2:1 randomization with block size 3, treatments \"A\" and \"B\" data.frame(x = 1:10) |> mutate(Treatment = randomize_by_fixed_block(block = c(\"A\", \"B\", \"B\"))) #>     x Treatment #> 1   1         B #> 2   2         B #> 3   3         A #> 4   4         A #> 5   5         B #> 6   6         B #> 7   7         B #> 8   8         A #> 9   9         B #> 10 10         A  # Example 2 # Stratified randomization data.frame(stratum = c(rep(\"A\", 10), rep(\"B\", 10))) |>   group_by(stratum) |>   mutate(Treatment = randomize_by_fixed_block()) #> # A tibble: 20 × 2 #> # Groups:   stratum [2] #>    stratum Treatment #>    <chr>       <dbl> #>  1 A               1 #>  2 A               1 #>  3 A               0 #>  4 A               0 #>  5 A               1 #>  6 A               0 #>  7 A               0 #>  8 A               1 #>  9 A               1 #> 10 A               0 #> 11 B               1 #> 12 B               0 #> 13 B               1 #> 14 B               0 #> 15 B               0 #> 16 B               1 #> 17 B               0 #> 18 B               1 #> 19 B               1 #> 20 B               0"},{"path":"https://merck.github.io/simtrial/reference/rmst.html","id":null,"dir":"Reference","previous_headings":"","what":"RMST difference of 2 arms — rmst","title":"RMST difference of 2 arms — rmst","text":"RMST difference 2 arms","code":""},{"path":"https://merck.github.io/simtrial/reference/rmst.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"RMST difference of 2 arms — rmst","text":"","code":"rmst(   data,   tau = 10,   var_label_tte = \"tte\",   var_label_event = \"event\",   var_label_group = \"treatment\",   formula = NULL,   reference = \"control\",   alpha = 0.05 )"},{"path":"https://merck.github.io/simtrial/reference/rmst.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"RMST difference of 2 arms — rmst","text":"data time--event dataset column tte indicating survival time column event indicating whether event censor. tau RMST analysis time. var_label_tte Column name TTE variable. var_label_event Column name event variable. var_label_group Column name grouping variable. formula (default: NULL) formula indicates TTE, event, group variables using syntax Surv(tte, event) ~ group) (see Details information). alternative specifying variables strings. formula provided, values passed var_label_tte, var_label_event, var_label_group ignored. reference group label indicating reference group. alpha Type error.","code":""},{"path":"https://merck.github.io/simtrial/reference/rmst.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"RMST difference of 2 arms — rmst","text":"z statistics.","code":""},{"path":"https://merck.github.io/simtrial/reference/rmst.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"RMST difference of 2 arms — rmst","text":"argument formula provided convenience easily specify TTE, event, grouping variables using syntax Surv(tte, event) ~ group). Surv() {survival} package (survival::Surv()). can also explicitly name arguments passed Surv(), example following equivalent Surv(event = event, time = tte) ~ group). Note however function Surv() never actually executed. Similarly, functions applied formula also ignored, thus apply transformation functions log() since effect.","code":""},{"path":"https://merck.github.io/simtrial/reference/rmst.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"RMST difference of 2 arms — rmst","text":"","code":"data(ex1_delayed_effect) rmst(   data = ex1_delayed_effect,   var_label_tte = \"month\",   var_label_event = \"evntd\",   var_label_group = \"trt\",   tau = 10,   reference = \"0\" ) #> $method #> [1] \"RMST\" #>  #> $parameter #> [1] 10 #>  #> $estimate #> [1] 0.8650493 #>  #> $se #> [1] 0.3900344 #>  #> $z #> [1] 2.21788 #>   # Formula interface rmst(   data = ex1_delayed_effect,   formula = Surv(month, evntd) ~ trt,   tau = 10,   reference = \"0\" ) #> $method #> [1] \"RMST\" #>  #> $parameter #> [1] 10 #>  #> $estimate #> [1] 0.8650493 #>  #> $se #> [1] 0.3900344 #>  #> $z #> [1] 2.21788 #>"},{"path":"https://merck.github.io/simtrial/reference/rmst_single_arm.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate RMST for a single cut-off time point — rmst_single_arm","title":"Calculate RMST for a single cut-off time point — rmst_single_arm","text":"Calculate RMST single cut-time point","code":""},{"path":"https://merck.github.io/simtrial/reference/rmst_single_arm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate RMST for a single cut-off time point — rmst_single_arm","text":"","code":"rmst_single_arm(   time_var,   event_var,   tau,   group_label = \"Single Group\",   alpha = 0.05 )"},{"path":"https://merck.github.io/simtrial/reference/rmst_single_arm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate RMST for a single cut-off time point — rmst_single_arm","text":"time_var numeric vector follow time. event_var numeric integer vector status indicator; 0=alive 1=event. tau value pre-defined cut-time point. group_label character customized treatment group name. alpha numeric value significant level RMST confidence interval. Default 0.05.","code":""},{"path":"https://merck.github.io/simtrial/reference/rmst_single_arm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate RMST for a single cut-off time point — rmst_single_arm","text":"data frame Cutoff time: tau; Group label: group_label; Estimated RMST; Variance, standard error, CIs estimated RMST; Number events.","code":""},{"path":"https://merck.github.io/simtrial/reference/rmst_single_arm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate RMST for a single cut-off time point — rmst_single_arm","text":"","code":"data(ex1_delayed_effect) data_single_arm <- ex1_delayed_effect[ex1_delayed_effect$trt == 1, ] simtrial:::rmst_single_arm(   time_var = data_single_arm$month,   event_var = data_single_arm$evntd,   tau = 10,   group_label = \"Treatment 1\",   alpha = 0.05 ) #>   cutoff_time       group     rmst   variance       std      lcl      ucl event #> 1          10 Treatment 1 6.495175 0.05711322 0.2389837 6.026776 6.963575   127"},{"path":"https://merck.github.io/simtrial/reference/rmst_two_arm.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate RMST difference — rmst_two_arm","title":"Calculate RMST difference — rmst_two_arm","text":"Calculate RMST difference","code":""},{"path":"https://merck.github.io/simtrial/reference/rmst_two_arm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate RMST difference — rmst_two_arm","text":"","code":"rmst_two_arm(   time_var,   event_var,   group_var,   trunc_time,   reference = sort(unique(group_var))[1],   alpha = 0.05 )"},{"path":"https://merck.github.io/simtrial/reference/rmst_two_arm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate RMST difference — rmst_two_arm","text":"time_var numeric vector follow time. event_var numeric integer vector status indicator; 0=alive 1=event. group_var vector treatment groups. trunc_time numeric vector pre-defined cut-time point(s). reference Group name reference group RMST comparison. Default first group name alphabetical order. alpha numeric value significant level RMST confidence interval. Default 0.05.","code":""},{"path":"https://merck.github.io/simtrial/reference/rmst_two_arm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate RMST difference — rmst_two_arm","text":"list 2 data frames RMST calculations: rmst_per_arm: calculation results per group. rmst_diff: calculation results RMST differences.","code":""},{"path":"https://merck.github.io/simtrial/reference/rmst_two_arm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate RMST difference — rmst_two_arm","text":"","code":"data(ex1_delayed_effect) with(   ex1_delayed_effect,   simtrial:::rmst_two_arm(     time_var = month,     event_var = evntd,     group_var = trt,     trunc_time = 6,     reference = \"0\",     alpha = 0.05   ) ) #> $rmst_per_arm #>   cutoff_time group     rmst   variance       std      lcl      ucl event #> 1           6     0 4.340067 0.02902105 0.1703557 4.006176 4.673958    68 #> 2           6     1 4.552177 0.01607455 0.1267854 4.303682 4.800672   100 #>  #> $rmst_diff #>   cutoff_time group rmst_diff  variance       std        lcl       ucl #> 1           6 1 - 0 0.2121097 0.0450956 0.2123572 -0.2041029 0.6283222 #>"},{"path":"https://merck.github.io/simtrial/reference/rpwexp.html","id":null,"dir":"Reference","previous_headings":"","what":"The piecewise exponential distribution — rpwexp","title":"The piecewise exponential distribution — rpwexp","text":"piecewise exponential distribution allows simple method specify distribution hazard rate changes time. likely useful conditions failure rates change, also simulations may delayed treatment effect treatment effect otherwise changing (example, decreasing) time. rpwexp() support simulation Lachin Foulkes (1986) sample size method (fixed trial duration) well Kim Tsiatis (1990) method (fixed enrollment rates either fixed enrollment duration fixed minimum follow-); see gsDesign::nSurv().","code":""},{"path":"https://merck.github.io/simtrial/reference/rpwexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The piecewise exponential distribution — rpwexp","text":"","code":"rpwexp(n = 100, fail_rate = data.frame(duration = c(1, 1), rate = c(10, 20)))"},{"path":"https://merck.github.io/simtrial/reference/rpwexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The piecewise exponential distribution — rpwexp","text":"n Number observations generated. fail_rate data frame containing duration rate variables. rate specifies failure rates corresponding interval duration specified duration. final interval extended infinite ensure observations generated.","code":""},{"path":"https://merck.github.io/simtrial/reference/rpwexp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The piecewise exponential distribution — rpwexp","text":"generated random numbers.","code":""},{"path":"https://merck.github.io/simtrial/reference/rpwexp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The piecewise exponential distribution — rpwexp","text":"Using cumulative = TRUE option, enrollment times piecewise constant time can generated.","code":""},{"path":"https://merck.github.io/simtrial/reference/rpwexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The piecewise exponential distribution — rpwexp","text":"","code":"# Example 1 # Exponential failure times x <- rpwexp(   n = 10000,   fail_rate = data.frame(rate = 5, duration = 1) ) plot(sort(x), (10000:1) / 10001,   log = \"y\", main = \"Exponential simulated survival curve\",   xlab = \"Time\", ylab = \"P{Survival}\" )   # Example 2  # Get 10k piecewise exponential failure times. # Failure rates are 1 for time 0 to 0.5, 3 for time 0.5 to 1, and 10 for > 1. # Intervals specifies duration of each failure rate interval # with the final interval running to infinity. x <- rpwexp(   n = 1e4,   fail_rate = data.frame(rate = c(1, 3, 10), duration = c(.5, .5, 1)) ) plot(sort(x), (1e4:1) / 10001,   log = \"y\", main = \"PW Exponential simulated survival curve\",   xlab = \"Time\", ylab = \"P{Survival}\" )"},{"path":"https://merck.github.io/simtrial/reference/rpwexp_enroll.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate piecewise exponential enrollment — rpwexp_enroll","title":"Generate piecewise exponential enrollment — rpwexp_enroll","text":"piecewise exponential enrollment rate generation enrollment rate distribution can easily approximated. rpwexp_enroll() support simulation Lachin Foulkes (1986) sample size method (fixed trial duration) well Kim Tsiatis(1990) method (fixed enrollment rates either fixed enrollment duration fixed minimum follow-); see gsDesign::nSurv().","code":""},{"path":"https://merck.github.io/simtrial/reference/rpwexp_enroll.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate piecewise exponential enrollment — rpwexp_enroll","text":"","code":"rpwexp_enroll(   n = NULL,   enroll_rate = data.frame(duration = c(1, 2), rate = c(2, 5)) )"},{"path":"https://merck.github.io/simtrial/reference/rpwexp_enroll.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate piecewise exponential enrollment — rpwexp_enroll","text":"n Number observations. Default NULL yields random enrollment size. enroll_rate data frame containing period duration (duration) enrollment rate (rate). specified enrollment periods. necessary, last period extended ensure enrollment specified n.","code":""},{"path":"https://merck.github.io/simtrial/reference/rpwexp_enroll.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate piecewise exponential enrollment — rpwexp_enroll","text":"vector random enrollment times.","code":""},{"path":"https://merck.github.io/simtrial/reference/rpwexp_enroll.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate piecewise exponential enrollment — rpwexp_enroll","text":"","code":"# Example 1 # Piecewise uniform (piecewise exponential inter-arrival times) for 10k patients enrollment # Enrollment rates of 5 for time 0-100, 15 for 100-300, and 30 thereafter x <- rpwexp_enroll(   n = 1e5,   enroll_rate = data.frame(     rate = c(5, 15, 30),     duration = c(100, 200, 100)   ) ) plot(x, 1:1e5,   main = \"Piecewise uniform enrollment simulation\",   xlab = \"Time\",   ylab = \"Enrollment\" )   # Example 2 # Exponential enrollment x <- rpwexp_enroll(   n = 1e5,   enroll_rate = data.frame(rate = .03, duration = 1) ) plot(x, 1:1e5,   main = \"Simulated exponential inter-arrival times\",   xlab = \"Time\",   ylab = \"Enrollment\" )"},{"path":"https://merck.github.io/simtrial/reference/sim_fixed_n.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulation of fixed sample size design for time-to-event endpoint — sim_fixed_n","title":"Simulation of fixed sample size design for time-to-event endpoint — sim_fixed_n","text":"sim_fixed_n() provides simulations single endpoint two-arm trial enrollment, hazard ratio, failure dropout rates change time.","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_fixed_n.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulation of fixed sample size design for time-to-event endpoint — sim_fixed_n","text":"","code":"sim_fixed_n(   n_sim = 1000,   sample_size = 500,   target_event = 350,   stratum = data.frame(stratum = \"All\", p = 1),   enroll_rate = data.frame(duration = c(2, 2, 10), rate = c(3, 6, 9)),   fail_rate = data.frame(stratum = \"All\", duration = c(3, 100), fail_rate = log(2)/c(9,     18), hr = c(0.9, 0.6), dropout_rate = rep(0.001, 2)),   total_duration = 30,   block = rep(c(\"experimental\", \"control\"), 2),   timing_type = 1:5,   rho_gamma = data.frame(rho = 0, gamma = 0) )"},{"path":"https://merck.github.io/simtrial/reference/sim_fixed_n.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulation of fixed sample size design for time-to-event endpoint — sim_fixed_n","text":"n_sim Number simulations perform. sample_size Total sample size per simulation. target_event Targeted event count analysis. stratum data frame stratum specified stratum, probability (incidence) stratum p. enroll_rate Piecewise constant enrollment rates time period. Note overall population enrollment rates stratum argument controls random distribution stratum. fail_rate Piecewise constant control group failure rates, hazard ratio experimental vs. control, dropout rates stratum time period. total_duration Total follow-start enrollment data cutoff. block sim_pw_surv(). Vector treatments included block. timing_type numeric vector determining data cutoffs used; see details. Default include available cutoff methods. rho_gamma data frame variables rho gamma, greater equal zero, specify one Fleming-Harrington weighted logrank test per row.","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_fixed_n.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulation of fixed sample size design for time-to-event endpoint — sim_fixed_n","text":"data frame including columns: event: Event count. ln_hr: Log-hazard ratio. z: Normal test statistic; < 0 favors experimental. cut: Text describing cutoff used. duration: Duration trial cutoff analysis. sim: Sequential simulation ID. One row per simulated dataset per cutoff specified timing_type, per test statistic specified. multiple Fleming-Harrington tests specified rho_gamma, columns rho gamma also included.","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_fixed_n.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulation of fixed sample size design for time-to-event endpoint — sim_fixed_n","text":"timing_type 5 elements indicating different options data cutoff: 1: Uses planned study duration. 2: time targeted event count achieved. 3: planned minimum follow-enrollment complete. 4: maximum planned study duration targeted event count cuts (1 2). 5: maximum targeted event count minimum follow-cuts (2 3).","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_fixed_n.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulation of fixed sample size design for time-to-event endpoint — sim_fixed_n","text":"","code":"library(dplyr) library(future)  # Example 1: logrank test ---- x <- sim_fixed_n(n_sim = 10, timing_type = 1, rho_gamma = data.frame(rho = 0, gamma = 0)) #> Backend uses sequential processing. # Get power approximation mean(x$z <= qnorm(.025)) #> [1] 0  # Example 2: WLR with FH(0,1) ---- sim_fixed_n(n_sim = 1, timing_type = 1, rho_gamma = data.frame(rho = 0, gamma = 1)) #> Backend uses sequential processing. #>   method          parameter    estimate       se          z event      ln_hr #> 1    WLR FH(rho=0, gamma=1) -0.03587586 1.351219 0.02655074   103 -0.1042096 #>                cut duration sim #> 1 Planned duration       30   1 # Get power approximation mean(x$z <= qnorm(.025)) #> [1] 0  # \\donttest{ # Example 3: MaxCombo, i.e., WLR-FH(0,0)+ WLR-FH(0,1) # Power by test # Only use cuts for events, events + min follow-up x <- sim_fixed_n(   n_sim = 10,   timing_type = 2,   rho_gamma = data.frame(rho = 0, gamma = c(0, 1)) ) #> Backend uses sequential processing.  # Get power approximation x |>   group_by(sim) |>   filter(row_number() == 1) |>   ungroup() |>   summarize(power = mean(p_value < .025)) #> # A tibble: 1 × 1 #>   power #>   <dbl> #> 1     1  # Example 4 # Use two cores set.seed(2023) plan(\"multisession\", workers = 2) sim_fixed_n(n_sim = 10) #> Using 2 cores with backend multisession #>    method          parameter   estimate       se         z event      ln_hr #> 1     WLR FH(rho=0, gamma=0)  -9.044800 5.213492 1.7348832   109 -0.3342849 #> 2     WLR FH(rho=0, gamma=0) -41.170785 9.229540 4.4607622   350 -0.4793575 #> 3     WLR FH(rho=0, gamma=0) -41.444949 9.546994 4.3411518   376 -0.4498374 #> 4     WLR FH(rho=0, gamma=0) -41.170785 9.229540 4.4607622   350 -0.4793575 #> 5     WLR FH(rho=0, gamma=0) -41.444949 9.546994 4.3411518   376 -0.4498374 #> 6     WLR FH(rho=0, gamma=0)  -5.248725 5.068148 1.0356297   103 -0.2047494 #> 7     WLR FH(rho=0, gamma=0) -33.266167 9.245312 3.5981660   350 -0.3873648 #> 8     WLR FH(rho=0, gamma=0) -35.663072 9.468334 3.7665623   367 -0.3953215 #> 9     WLR FH(rho=0, gamma=0) -33.266167 9.245312 3.5981660   350 -0.3873648 #> 10    WLR FH(rho=0, gamma=0) -35.663072 9.468334 3.7665623   367 -0.3953215 #> 11    WLR FH(rho=0, gamma=0) -18.821290 4.838510 3.8898935    95 -0.8181040 #> 12    WLR FH(rho=0, gamma=0) -55.442685 9.055033 6.1228581   350 -0.6662357 #> 13    WLR FH(rho=0, gamma=0) -55.753830 9.043216 6.1652657   349 -0.6719858 #> 14    WLR FH(rho=0, gamma=0) -55.442685 9.055033 6.1228581   350 -0.6662357 #> 15    WLR FH(rho=0, gamma=0) -55.442685 9.055033 6.1228581   350 -0.6662357 #> 16    WLR FH(rho=0, gamma=0)  -3.064636 5.228765 0.5861109   110 -0.1120785 #> 17    WLR FH(rho=0, gamma=0) -33.961737 9.264232 3.6658988   350 -0.3939024 #> 18    WLR FH(rho=0, gamma=0) -34.607774 9.536543 3.6289642   372 -0.3781111 #> 19    WLR FH(rho=0, gamma=0) -33.961737 9.264232 3.6658988   350 -0.3939024 #> 20    WLR FH(rho=0, gamma=0) -34.607774 9.536543 3.6289642   372 -0.3781111 #> 21    WLR FH(rho=0, gamma=0) -13.960942 4.823458 2.8943845    94 -0.6069906 #> 22    WLR FH(rho=0, gamma=0) -37.851426 9.213540 4.1082391   350 -0.4410650 #> 23    WLR FH(rho=0, gamma=0) -36.640901 9.184545 3.9894083   348 -0.4296748 #> 24    WLR FH(rho=0, gamma=0) -37.851426 9.213540 4.1082391   350 -0.4410650 #> 25    WLR FH(rho=0, gamma=0) -37.851426 9.213540 4.1082391   350 -0.4410650 #> 26    WLR FH(rho=0, gamma=0) -14.173675 5.030231 2.8176983   103 -0.5638412 #> 27    WLR FH(rho=0, gamma=0) -35.792430 9.171024 3.9027737   350 -0.4227156 #> 28    WLR FH(rho=0, gamma=0) -36.093884 9.190638 3.9272445   351 -0.4245379 #> 29    WLR FH(rho=0, gamma=0) -35.792430 9.171024 3.9027737   350 -0.4227156 #> 30    WLR FH(rho=0, gamma=0) -36.093884 9.190638 3.9272445   351 -0.4245379 #> 31    WLR FH(rho=0, gamma=0)  -4.479885 5.189040 0.8633360   108 -0.1666295 #> 32    WLR FH(rho=0, gamma=0) -29.984429 9.309267 3.2209226   350 -0.3453421 #> 33    WLR FH(rho=0, gamma=0) -27.732193 9.152805 3.0299119   338 -0.3305844 #> 34    WLR FH(rho=0, gamma=0) -29.984429 9.309267 3.2209226   350 -0.3453421 #> 35    WLR FH(rho=0, gamma=0) -29.984429 9.309267 3.2209226   350 -0.3453421 #> 36    WLR FH(rho=0, gamma=0)  -8.620094 5.553024 1.5523243   124 -0.2803523 #> 37    WLR FH(rho=0, gamma=0) -30.211007 9.300647 3.2482694   350 -0.3478454 #> 38    WLR FH(rho=0, gamma=0) -33.581256 9.516244 3.5288351   367 -0.3690357 #> 39    WLR FH(rho=0, gamma=0) -30.211007 9.300647 3.2482694   350 -0.3478454 #> 40    WLR FH(rho=0, gamma=0) -33.581256 9.516244 3.5288351   367 -0.3690357 #> 41    WLR FH(rho=0, gamma=0)  -3.955284 5.093447 0.7765436   104 -0.1525416 #> 42    WLR FH(rho=0, gamma=0) -26.670986 9.302656 2.8670291   350 -0.3069406 #> 43    WLR FH(rho=0, gamma=0) -26.342504 9.314768 2.8280363   351 -0.3023229 #> 44    WLR FH(rho=0, gamma=0) -26.670986 9.302656 2.8670291   350 -0.3069406 #> 45    WLR FH(rho=0, gamma=0) -26.342504 9.314768 2.8280363   351 -0.3023229 #> 46    WLR FH(rho=0, gamma=0)  -9.242625 5.104900 1.8105400   106 -0.3551148 #> 47    WLR FH(rho=0, gamma=0) -35.255531 9.270632 3.8029263   350 -0.4077490 #> 48    WLR FH(rho=0, gamma=0) -36.706949 9.386743 3.9105095   360 -0.4138911 #> 49    WLR FH(rho=0, gamma=0) -35.255531 9.270632 3.8029263   350 -0.4077490 #> 50    WLR FH(rho=0, gamma=0) -36.706949 9.386743 3.9105095   360 -0.4138911 #>                                 cut duration sim #> 1                  Planned duration 30.00000   1 #> 2                   Targeted events 65.23187   1 #> 3                 Minimum follow-up 73.17268   1 #> 4  Max(planned duration, event cut) 65.23187   1 #> 5     Max(min follow-up, event cut) 73.17268   1 #> 6                  Planned duration 30.00000   2 #> 7                   Targeted events 67.64612   2 #> 8                 Minimum follow-up 72.56793   2 #> 9  Max(planned duration, event cut) 67.64612   2 #> 10    Max(min follow-up, event cut) 72.56793   2 #> 11                 Planned duration 30.00000   3 #> 12                  Targeted events 74.95821   3 #> 13                Minimum follow-up 74.72225   3 #> 14 Max(planned duration, event cut) 74.95821   3 #> 15    Max(min follow-up, event cut) 74.95821   3 #> 16                 Planned duration 30.00000   4 #> 17                  Targeted events 69.16631   4 #> 18                Minimum follow-up 73.68989   4 #> 19 Max(planned duration, event cut) 69.16631   4 #> 20    Max(min follow-up, event cut) 73.68989   4 #> 21                 Planned duration 30.00000   5 #> 22                  Targeted events 77.05035   5 #> 23                Minimum follow-up 76.68470   5 #> 24 Max(planned duration, event cut) 77.05035   5 #> 25    Max(min follow-up, event cut) 77.05035   5 #> 26                 Planned duration 30.00000   6 #> 27                  Targeted events 71.51268   6 #> 28                Minimum follow-up 72.34254   6 #> 29 Max(planned duration, event cut) 71.51268   6 #> 30    Max(min follow-up, event cut) 72.34254   6 #> 31                 Planned duration 30.00000   7 #> 32                  Targeted events 75.61250   7 #> 33                Minimum follow-up 72.99192   7 #> 34 Max(planned duration, event cut) 75.61250   7 #> 35    Max(min follow-up, event cut) 75.61250   7 #> 36                 Planned duration 30.00000   8 #> 37                  Targeted events 66.62160   8 #> 38                Minimum follow-up 70.19488   8 #> 39 Max(planned duration, event cut) 66.62160   8 #> 40    Max(min follow-up, event cut) 70.19488   8 #> 41                 Planned duration 30.00000   9 #> 42                  Targeted events 70.92746   9 #> 43                Minimum follow-up 71.28078   9 #> 44 Max(planned duration, event cut) 70.92746   9 #> 45    Max(min follow-up, event cut) 71.28078   9 #> 46                 Planned duration 30.00000  10 #> 47                  Targeted events 75.17856  10 #> 48                Minimum follow-up 76.94235  10 #> 49 Max(planned duration, event cut) 75.17856  10 #> 50    Max(min follow-up, event cut) 76.94235  10 plan(\"sequential\") # }"},{"path":"https://merck.github.io/simtrial/reference/sim_gs_n.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate group sequential designs with fixed sample size — sim_gs_n","title":"Simulate group sequential designs with fixed sample size — sim_gs_n","text":"function uses option \"stop\" error-handling behavior foreach loop. cause entire function stop errors encountered return first error encountered instead returning errors individual simulation.","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_gs_n.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate group sequential designs with fixed sample size — sim_gs_n","text":"","code":"sim_gs_n(   n_sim = 1000,   sample_size = 500,   stratum = data.frame(stratum = \"All\", p = 1),   enroll_rate = data.frame(duration = c(2, 2, 10), rate = c(3, 6, 9)),   fail_rate = data.frame(stratum = \"All\", duration = c(3, 100), fail_rate = log(2)/c(9,     18), hr = c(0.9, 0.6), dropout_rate = rep(0.001, 2)),   block = rep(c(\"experimental\", \"control\"), 2),   test = wlr,   cut = NULL,   original_design = NULL,   ia_alpha_spending = c(\"min_planned_actual\", \"actual\"),   fa_alpha_spending = c(\"full_alpha\", \"info_frac\"),   ... )"},{"path":"https://merck.github.io/simtrial/reference/sim_gs_n.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate group sequential designs with fixed sample size — sim_gs_n","text":"n_sim Number simulations perform. sample_size Total sample size per simulation. stratum data frame stratum specified stratum, probability (incidence) stratum p. enroll_rate Piecewise constant enrollment rates time period. Note overall population enrollment rates stratum argument controls random distribution stratum. fail_rate Piecewise constant control group failure rates, hazard ratio experimental vs. control, dropout rates stratum time period. block sim_pw_surv(). Vector treatments included block. test One test functions wlr(), rmst(), milestone() (maxcombo() can applied ). single test function provided, applied cut. Alternatively list functions created create_test(). list form experimental currently limited. accepts one test per cutting (future multiple tests may accepted), tests must consistently return exact results (may flexible future). Importantly, note simulated data set always passed first positional argument test function provided. cut list cutting functions created create_cut(), see examples. original_design design object gsDesign2 package, required users want calculate updated bounds. default NULL leaving updated bounds uncalculated. ia_alpha_spending Spend alpha interim analysis based \"min_planned_actual\": minimal planned actual alpha spending. \"actual\": actual alpha spending. fa_alpha_spending targeted final event count achieved (-running final analysis), specify final spending. Generally, specified analysis plan. \"info_frac\" = spend final alpha according final information fraction \"full_alpha\" = spend full alpha final analysis. ... Arguments passed test function(s) provided argument test.","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_gs_n.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate group sequential designs with fixed sample size — sim_gs_n","text":"data frame summarizing simulation ID, analysis date, z statistics p-values.","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_gs_n.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate group sequential designs with fixed sample size — sim_gs_n","text":"WARNING: experimental function work--progress. function arguments change add additional features.","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_gs_n.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate group sequential designs with fixed sample size — sim_gs_n","text":"","code":"library(gsDesign2)  # Parameters for enrollment enroll_rampup_duration <- 4 # Duration for enrollment ramp up enroll_duration <- 16 # Total enrollment duration enroll_rate <- define_enroll_rate(   duration = c(     enroll_rampup_duration,     enroll_duration - enroll_rampup_duration   ),   rate = c(10, 30) )  # Parameters for treatment effect delay_effect_duration <- 3 # Delay treatment effect in months median_ctrl <- 9 # Survival median of the control arm median_exp <- c(9, 14) # Survival median of the experimental arm dropout_rate <- 0.001 fail_rate <- define_fail_rate(   duration = c(delay_effect_duration, 100),   fail_rate = log(2) / median_ctrl,   hr = median_ctrl / median_exp,   dropout_rate = dropout_rate )  # Other related parameters alpha <- 0.025 # Type I error beta <- 0.1 # Type II error ratio <- 1 # Randomization ratio (experimental:control)  # Define cuttings of 2 IAs and 1 FA # IA1 # The 1st interim analysis will occur at the later of the following 3 conditions: # - At least 20 months have passed since the start of the study. # - At least 100 events have occurred. # - At least 20 months have elapsed after enrolling 200/400 subjects, with a #   minimum of 20 months follow-up. # However, if events accumulation is slow, we will wait for a maximum of 24 months. ia1_cut <- create_cut(   planned_calendar_time = 20,   target_event_overall = 100,   max_extension_for_target_event = 24,   min_n_overall = 200,   min_followup = 20 )  # IA2 # The 2nd interim analysis will occur at the later of the following 3 conditions: # - At least 32 months have passed since the start of the study. # - At least 200 events have occurred. # - At least 10 months after IA1. # However, if events accumulation is slow, we will wait for a maximum of 34 months. ia2_cut <- create_cut(   planned_calendar_time = 32,   target_event_overall = 200,   max_extension_for_target_event = 34,   min_time_after_previous_analysis = 10 )  # FA # The final analysis will occur at the later of the following 2 conditions: # - At least 45 months have passed since the start of the study. # - At least 350 events have occurred. fa_cut <- create_cut(   planned_calendar_time = 45,   target_event_overall = 350 )  # Example 1: regular logrank test at all 3 analyses sim_gs_n(   n_sim = 3,   sample_size = 400,   enroll_rate = enroll_rate,   fail_rate = fail_rate,   test = wlr,   cut = list(ia1 = ia1_cut, ia2 = ia2_cut, fa = fa_cut),   weight = fh(rho = 0, gamma = 0) ) #> Backend uses sequential processing. #>   sim_id method          parameter analysis cut_date   n event  estimate #> 1      1    WLR FH(rho=0, gamma=0)        1 24.00000 400   245 -26.39845 #> 2      1    WLR FH(rho=0, gamma=0)        2 32.00000 400   301 -34.97803 #> 3      1    WLR FH(rho=0, gamma=0)        3 48.63895 400   350 -41.42441 #> 4      2    WLR FH(rho=0, gamma=0)        1 24.00000 400   235 -20.37909 #> 5      2    WLR FH(rho=0, gamma=0)        2 32.00000 400   306 -30.55728 #> 6      2    WLR FH(rho=0, gamma=0)        3 45.00000 400   354 -32.66420 #> 7      3    WLR FH(rho=0, gamma=0)        1 24.00000 400   251 -16.50549 #> 8      3    WLR FH(rho=0, gamma=0)        2 32.00000 400   311 -22.97248 #> 9      3    WLR FH(rho=0, gamma=0)        3 45.00000 400   351 -32.13795 #>         se        z     info info0 #> 1 7.770184 3.397404 60.13878 61.25 #> 2 8.564565 4.084041 74.23256 75.25 #> 3 9.126837 4.538748 87.01714 87.50 #> 4 7.649520 2.664100 57.85532 58.75 #> 5 8.662696 3.527456 75.76471 76.50 #> 6 9.231999 3.538151 88.31921 88.50 #> 7 7.907949 2.087202 62.22311 62.75 #> 8 8.766078 2.620611 77.32476 77.75 #> 9 9.215294 3.487458 87.37322 87.75  # \\donttest{ # Example 2: weighted logrank test by FH(0, 0.5) at all 3 analyses sim_gs_n(   n_sim = 3,   sample_size = 400,   enroll_rate = enroll_rate,   fail_rate = fail_rate,   test = wlr,   cut = list(ia1 = ia1_cut, ia2 = ia2_cut, fa = fa_cut),   weight = fh(rho = 0, gamma = 0.5) ) #> Backend uses sequential processing. #>   sim_id method            parameter analysis cut_date   n event   estimate #> 1      1    WLR FH(rho=0, gamma=0.5)        1 24.00000 400   238 -11.519460 #> 2      1    WLR FH(rho=0, gamma=0.5)        2 32.00000 400   302 -21.050307 #> 3      1    WLR FH(rho=0, gamma=0.5)        3 47.15475 400   350 -25.657580 #> 4      2    WLR FH(rho=0, gamma=0.5)        1 24.00000 400   237 -17.779288 #> 5      2    WLR FH(rho=0, gamma=0.5)        2 32.00000 400   303 -17.104511 #> 6      2    WLR FH(rho=0, gamma=0.5)        3 45.20750 400   350 -21.259844 #> 7      3    WLR FH(rho=0, gamma=0.5)        1 24.00000 400   243  -7.641473 #> 8      3    WLR FH(rho=0, gamma=0.5)        2 32.00000 400   313 -16.222460 #> 9      3    WLR FH(rho=0, gamma=0.5)        3 45.00000 400   357 -13.462925 #>         se        z     info    info0 #> 1 4.212840 2.734369 17.66159 18.06453 #> 2 5.287754 3.980954 28.10427 28.80492 #> 3 6.011098 4.268368 38.33550 38.53873 #> 4 4.159616 4.274261 17.21443 17.86992 #> 5 5.253254 3.255984 28.85187 28.85822 #> 6 6.029132 3.526187 38.42666 38.42690 #> 7 4.315878 1.770549 18.64245 18.87826 #> 8 5.485709 2.957222 30.52415 30.87758 #> 9 6.241763 2.156911 39.98650 39.99242  # Example 3: weighted logrank test by MB(3) at all 3 analyses sim_gs_n(   n_sim = 3,   sample_size = 400,   enroll_rate = enroll_rate,   fail_rate = fail_rate,   test = wlr,   cut = list(ia1 = ia1_cut, ia2 = ia2_cut, fa = fa_cut),   weight = mb(delay = 3) ) #> Backend uses sequential processing. #>   sim_id method                       parameter analysis cut_date   n event #> 1      1    WLR MB(delay = 3, max_weight = Inf)        1 24.00000 400   237 #> 2      1    WLR MB(delay = 3, max_weight = Inf)        2 32.00000 400   292 #> 3      1    WLR MB(delay = 3, max_weight = Inf)        3 47.13787 400   350 #> 4      2    WLR MB(delay = 3, max_weight = Inf)        1 24.00000 400   228 #> 5      2    WLR MB(delay = 3, max_weight = Inf)        2 32.00000 400   302 #> 6      2    WLR MB(delay = 3, max_weight = Inf)        3 45.00000 400   356 #> 7      3    WLR MB(delay = 3, max_weight = Inf)        1 24.00000 400   232 #> 8      3    WLR MB(delay = 3, max_weight = Inf)        2 32.00000 400   296 #> 9      3    WLR MB(delay = 3, max_weight = Inf)        3 45.00000 400   355 #>    estimate        se        z      info     info0 #> 1 -23.99092  9.119518 2.630723  81.75319  83.61133 #> 2 -27.23502 10.132880 2.687786 103.25527 104.18572 #> 3 -28.70345 11.105597 2.584593 125.58628 125.88236 #> 4 -15.71567  9.376773 1.676022  87.95612  88.29343 #> 5 -30.27144 10.886050 2.780755 118.83819 119.70573 #> 6 -37.58441 11.785381 3.189071 143.09412 143.37252 #> 7 -40.22868  9.270549 4.339406  84.05534  87.29638 #> 8 -47.10964 10.480221 4.495100 111.98258 113.59487 #> 9 -59.88361 11.354711 5.273900 137.01487 137.83879  # Example 4: weighted logrank test by early zero (6) at all 3 analyses sim_gs_n(   n_sim = 3,   sample_size = 400,   enroll_rate = enroll_rate,   fail_rate = fail_rate,   test = wlr,   cut = list(ia1 = ia1_cut, ia2 = ia2_cut, fa = fa_cut),   weight = early_zero(6) ) #> Backend uses sequential processing. #>   sim_id method                                parameter analysis cut_date   n #> 1      1    WLR Xu 2017 with first 6 months of 0 weights        1 24.00000 400 #> 2      1    WLR Xu 2017 with first 6 months of 0 weights        2 32.00000 400 #> 3      1    WLR Xu 2017 with first 6 months of 0 weights        3 48.05091 400 #> 4      2    WLR Xu 2017 with first 6 months of 0 weights        1 24.00000 400 #> 5      2    WLR Xu 2017 with first 6 months of 0 weights        2 32.00000 400 #> 6      2    WLR Xu 2017 with first 6 months of 0 weights        3 45.00000 400 #> 7      3    WLR Xu 2017 with first 6 months of 0 weights        1 24.00000 400 #> 8      3    WLR Xu 2017 with first 6 months of 0 weights        2 32.00000 400 #> 9      3    WLR Xu 2017 with first 6 months of 0 weights        3 45.73872 400 #>   event   estimate       se         z     info info0 #> 1   219  -7.233088 4.459505 1.6219486 20.17284 20.25 #> 2   289  -5.322163 6.090125 0.8739003 37.66887 37.75 #> 3   350  -6.283640 7.184216 0.8746452 52.15311 52.25 #> 4   246 -17.168891 5.269039 3.2584480 28.26087 28.75 #> 5   312 -23.808172 6.567445 3.6251801 45.08287 45.25 #> 6   359 -26.581367 7.266207 3.6582179 56.50000 56.50 #> 7   255  -7.792209 5.190782 1.5011629 27.46364 27.50 #> 8   307  -8.396865 6.324591 1.3276535 40.49383 40.50 #> 9   350 -16.086951 7.076497 2.2732929 50.87745 51.00  # Example 5: RMST at all 3 analyses sim_gs_n(   n_sim = 3,   sample_size = 400,   enroll_rate = enroll_rate,   fail_rate = fail_rate,   test = rmst,   cut = list(ia1 = ia1_cut, ia2 = ia2_cut, fa = fa_cut),   tau = 20 ) #> Backend uses sequential processing. #>   sim_id method parameter analysis cut_date   n event  estimate        se #> 1      1   RMST        20        1 24.00000 400   246 0.9620073 0.7703594 #> 2      1   RMST        20        2 32.00000 400   303 1.0704830 0.7434335 #> 3      1   RMST        20        3 45.82652 400   350 1.0754780 0.7446373 #> 4      2   RMST        20        1 24.00000 400   224 1.3565622 0.7654899 #> 5      2   RMST        20        2 32.00000 400   294 1.3234404 0.7136717 #> 6      2   RMST        20        3 49.28090 400   350 1.3267670 0.7112636 #> 7      3   RMST        20        1 24.00000 400   236 2.8786445 0.7466703 #> 8      3   RMST        20        2 32.00000 400   302 2.8336838 0.7139365 #> 9      3   RMST        20        3 45.00000 400   353 2.8416720 0.7127162 #>          z #> 1 1.248777 #> 2 1.439918 #> 3 1.444298 #> 4 1.772149 #> 5 1.854411 #> 6 1.865366 #> 7 3.855308 #> 8 3.969098 #> 9 3.987102  # Example 6: Milestone at all 3 analyses sim_gs_n(   n_sim = 3,   sample_size = 400,   enroll_rate = enroll_rate,   fail_rate = fail_rate,   test = milestone,   cut = list(ia1 = ia1_cut, ia2 = ia2_cut, fa = fa_cut),   ms_time = 10 ) #> Backend uses sequential processing. #>   sim_id    method parameter analysis cut_date   n event     estimate        se #> 1      1 milestone        10        1 24.00000 400   248  0.410514199 0.1481902 #> 2      1 milestone        10        2 32.00000 400   297  0.414543282 0.1478856 #> 3      1 milestone        10        3 49.48058 400   350  0.414543282 0.1478856 #> 4      2 milestone        10        1 24.00000 400   252  0.245726113 0.1434768 #> 5      2 milestone        10        2 32.00000 400   311  0.236741525 0.1427782 #> 6      2 milestone        10        3 45.00000 400   365  0.236741525 0.1427782 #> 7      3 milestone        10        1 24.00000 400   244 -0.008264004 0.1458867 #> 8      3 milestone        10        2 32.00000 400   309  0.016998485 0.1446776 #> 9      3 milestone        10        3 45.82981 400   350  0.016998485 0.1446776 #>             z #> 1  2.77018499 #> 2  2.80313434 #> 3  2.80313434 #> 4  1.71265391 #> 5  1.65810723 #> 6  1.65810723 #> 7 -0.05664674 #> 8  0.11749215 #> 9  0.11749215 # }  # Warning: this example will be executable when we add info info0 to the milestone test # Example 7: WLR with fh(0, 0.5) test at IA1, # WLR with mb(6, Inf) at IA2, and milestone test at FA ia1_test <- create_test(wlr, weight = fh(rho = 0, gamma = 0.5)) ia2_test <- create_test(wlr, weight = mb(delay = 6, w_max = Inf)) fa_test <- create_test(milestone, ms_time = 10) if (FALSE) { # \\dontrun{ sim_gs_n(   n_sim = 3,   sample_size = 400,   enroll_rate = enroll_rate,   fail_rate = fail_rate,   test = list(ia1 = ia1_test, ia2 = ia2_test, fa = fa_test),   cut = list(ia1 = ia1_cut, ia2 = ia2_cut, fa = fa_cut) ) } # }  # WARNING: Multiple tests per cut will be enabled in a future version. #          Currently does not work. # Example 8: At IA1, we conduct 3 tests, LR, WLR with fh(0, 0.5), and RMST test. # At IA2, we conduct 2 tests, LR and WLR with early zero (6). # At FA, we conduct 2 tests, LR and milestone test. ia1_test <- list(   test1 = create_test(wlr, weight = fh(rho = 0, gamma = 0)),   test2 = create_test(wlr, weight = fh(rho = 0, gamma = 0.5)),   test3 = create_test(rmst, tau = 20) ) ia2_test <- list(   test1 = create_test(wlr, weight = fh(rho = 0, gamma = 0)),   test2 = create_test(wlr, weight = early_zero(6)) ) fa_test <- list(   test1 = create_test(wlr, weight = fh(rho = 0, gamma = 0)),   test3 = create_test(milestone, ms_time = 20) ) if (FALSE) { # \\dontrun{ sim_gs_n(   n_sim = 3,   sample_size = 400,   enroll_rate = enroll_rate,   fail_rate = fail_rate,   test = list(ia1 = ia1_test, ia2 = ia2_test, fa = fa_test),   cut = list(ia1 = ia1_cut, ia2 = ia2_cut, fa = fa_cut) ) } # }  # \\donttest{ # Example 9: regular logrank test at all 3 analyses in parallel plan(\"multisession\", workers = 2) sim_gs_n(   n_sim = 3,   sample_size = 400,   enroll_rate = enroll_rate,   fail_rate = fail_rate,   test = wlr,   cut = list(ia1 = ia1_cut, ia2 = ia2_cut, fa = fa_cut),   weight = fh(rho = 0, gamma = 0) ) #> Using 2 cores with backend multisession #>   sim_id method          parameter analysis cut_date   n event   estimate #> 1      1    WLR FH(rho=0, gamma=0)        1       24 400   243  -8.214034 #> 2      1    WLR FH(rho=0, gamma=0)        2       32 400   304 -17.213140 #> 3      1    WLR FH(rho=0, gamma=0)        3       45 400   354 -20.877501 #> 4      2    WLR FH(rho=0, gamma=0)        1       24 400   259 -23.598942 #> 5      2    WLR FH(rho=0, gamma=0)        2       32 400   315 -24.300718 #> 6      2    WLR FH(rho=0, gamma=0)        3       45 400   363 -29.136121 #> 7      3    WLR FH(rho=0, gamma=0)        1       24 400   242  -8.625253 #> 8      3    WLR FH(rho=0, gamma=0)        2       32 400   311 -16.179327 #> 9      3    WLR FH(rho=0, gamma=0)        3       45 400   368 -20.646537 #>         se        z     info info0 #> 1 7.785096 1.055097 60.66667 60.75 #> 2 8.690860 1.980603 75.67105 76.00 #> 3 9.327781 2.238207 88.39831 88.50 #> 4 8.018639 2.943011 63.93822 64.75 #> 5 8.818336 2.755703 78.46349 78.75 #> 6 9.410491 3.096132 90.63361 90.75 #> 7 7.773275 1.109603 60.29752 60.50 #> 8 8.798732 1.838825 77.45981 77.75 #> 9 9.487108 2.176273 91.69482 91.75 plan(\"sequential\")  # Example 10: group sequential design with updated bounds -- efficacy only x <- gs_design_ahr(analysis_time = 1:3*12) |> to_integer() sim_gs_n(   n_sim = 1,   sample_size = max(x$analysis$n),   enroll_rate = x$enroll_rate,   fail_rate = x$fail_rate,   test = wlr,   cut = list(ia1 = create_cut(planned_calendar_time = x$analysis$time[1]),              ia2 = create_cut(planned_calendar_time = x$analysis$time[2]),              fa = create_cut(planned_calendar_time = x$analysis$time[3])),   weight = fh(rho = 0, gamma = 0),   original_design = x ) #> Backend uses sequential processing. #>   sim_id method          parameter analysis cut_date   n event   estimate #> 1      1    WLR FH(rho=0, gamma=0)        1 12.00002 428   103  -5.027225 #> 2      1    WLR FH(rho=0, gamma=0)        2 23.99062 524   250 -18.698773 #> 3      1    WLR FH(rho=0, gamma=0)        3 35.93242 524   326 -33.341788 #>         se         z     info info0 planned_lower_bound planned_upper_bound #> 1 5.073530 0.9908732 25.45631 25.75          -1.7052708            3.870248 #> 2 7.894615 2.3685479 61.47600 62.50           0.9601286            2.356655 #> 3 8.979590 3.7130636 79.73313 81.50           2.0047523            2.009758 #>   updated_lower_bound updated_upper_bound #> 1          -1.7474033            3.870248 #> 2           0.9922834            2.356669 #> 3           1.9788284            2.003621  # Example 11: group sequential design with updated bounds -- efficacy & futility x <- gs_design_ahr(  alpha = 0.025, beta = 0.1, analysis_time = 1:3*12,  upper = gs_spending_bound, upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025),  lower = gs_spending_bound, lpar = list(sf = gsDesign::sfHSD, param = -4, total_spend = 0.01),  test_upper = c(FALSE, TRUE, TRUE), test_lower = c(TRUE, FALSE, FALSE)) |> to_integer() sim_gs_n(   n_sim = 1,   sample_size = max(x$analysis$n),   enroll_rate = x$enroll_rate,   fail_rate = x$fail_rate,   test = wlr,   cut = list(ia1 = create_cut(planned_calendar_time = x$analysis$time[1]),              ia2 = create_cut(planned_calendar_time = x$analysis$time[2]),              fa = create_cut(planned_calendar_time = x$analysis$time[3])),   weight = fh(rho = 0, gamma = 0),   original_design = x ) #> Backend uses sequential processing. #>   sim_id method          parameter analysis cut_date   n event   estimate #> 1      1    WLR FH(rho=0, gamma=0)        1 11.95079 415    75  -8.370586 #> 2      1    WLR FH(rho=0, gamma=0)        2 23.95510 496   215 -24.615573 #> 3      1    WLR FH(rho=0, gamma=0)        3 35.96078 496   281 -24.634761 #>         se        z     info info0 planned_lower_bound planned_upper_bound #> 1 4.328620 1.933777 18.00000 18.75           -2.319759                  NA #> 2 7.306296 3.369091 52.15814 53.75                  NA            2.358356 #> 3 8.331563 2.956800 69.60142 70.25                  NA            2.009328 #>   updated_lower_bound updated_upper_bound #> 1           -2.635304                 Inf #> 2                -Inf            2.423161 #> 3                -Inf            1.990588 # }"},{"path":"https://merck.github.io/simtrial/reference/sim_pw_surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate a stratified time-to-event outcome randomized trial — sim_pw_surv","title":"Simulate a stratified time-to-event outcome randomized trial — sim_pw_surv","text":"sim_pw_surv() enables simulation clinical trial essentially arbitrary patterns enrollment, failure rates censoring. piecewise exponential distribution allows simple method specify distribution enrollment pattern enrollment, failure, dropout rate changes time. main purpose may generate trial can analyzed single point time using group sequential methods, routine can also used simulate adaptive trial design. Enrollment, failure, dropout rates specified treatment group, stratum time period. Fixed block randomization used; blocks must include treatments provided failure dropout specification. Default arguments set allow simple implementation non-proportional hazards assumption unstratified design.","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_pw_surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate a stratified time-to-event outcome randomized trial — sim_pw_surv","text":"","code":"sim_pw_surv(   n = 100,   stratum = data.frame(stratum = \"All\", p = 1),   block = c(rep(\"control\", 2), rep(\"experimental\", 2)),   enroll_rate = data.frame(rate = 9, duration = 1),   fail_rate = data.frame(stratum = rep(\"All\", 4), period = rep(1:2, 2), treatment =     c(rep(\"control\", 2), rep(\"experimental\", 2)), duration = rep(c(3, 1), 2), rate =     log(2)/c(9, 9, 9, 18)),   dropout_rate = data.frame(stratum = rep(\"All\", 2), period = rep(1, 2), treatment =     c(\"control\", \"experimental\"), duration = rep(100, 2), rate = rep(0.001, 2)) )"},{"path":"https://merck.github.io/simtrial/reference/sim_pw_surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate a stratified time-to-event outcome randomized trial — sim_pw_surv","text":"n Number observations. length(n) > 1, length taken number required. stratum data frame stratum specified stratum, probability (incidence) stratum p. block Vector treatments included block. Also used calculate attribute \"ratio\" (details see section Value ). enroll_rate Enrollment rates; see details examples. fail_rate Failure rates; see details examples; note treatments need input block. dropout_rate Dropout rates; see details examples; note treatments need input block.","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_pw_surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate a stratified time-to-event outcome randomized trial — sim_pw_surv","text":"data frame following variables observation: stratum: Stratum observation. enroll_time: Enrollment time observation. treatment: Treatment group; one values input block. fail_time: Failure time generated using rpwexp(). dropout_time: Dropout time generated using rpwexp(). cte: Calendar time enrollment plus minimum failure time dropout time. fail: Indicator cte set using failure time; .e., 1 failure, 0 dropout. data frame also attribute \"ratio\", calculated number \"experimental\" treatments divided number \"control\" treatments input argument block.","code":""},{"path":"https://merck.github.io/simtrial/reference/sim_pw_surv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate a stratified time-to-event outcome randomized trial — sim_pw_surv","text":"","code":"library(dplyr)  # Example 1 sim_pw_surv(n = 20) #>    stratum enroll_time    treatment  fail_time dropout_time        cte fail #> 1      All  0.04593469 experimental  0.3408276     98.58106  0.3867623    1 #> 2      All  0.04842350      control 10.6974702    126.02694 10.7458937    1 #> 3      All  0.14582853      control 12.2867886    222.00638 12.4326171    1 #> 4      All  0.36172506 experimental 48.4943098   3940.42836 48.8560349    1 #> 5      All  0.37138895      control  5.5165464    747.72368  5.8879353    1 #> 6      All  0.43100250      control 46.7612306   1035.36115 47.1922331    1 #> 7      All  0.50269713 experimental  4.6297940    591.70021  5.1324911    1 #> 8      All  0.64269364 experimental 25.3045387   1074.12731 25.9472323    1 #> 9      All  0.77982087      control 12.3506497    280.66035 13.1304706    1 #> 10     All  0.79589330 experimental  8.2785049    460.90846  9.0743982    1 #> 11     All  0.81015489      control 27.5026277    159.48258 28.3127826    1 #> 12     All  0.89218614 experimental  1.6351292    480.78425  2.5273153    1 #> 13     All  1.00490722      control 24.6939029   2312.83176 25.6988101    1 #> 14     All  1.11772985      control  2.0823743    195.25467  3.2001042    1 #> 15     All  1.40185144 experimental 19.0080405     80.18976 20.4098919    1 #> 16     All  1.44496111 experimental  0.7551894    278.42173  2.2001505    1 #> 17     All  1.68591991      control  2.5583299    204.01239  4.2442498    1 #> 18     All  1.76044835 experimental 32.7148660   1376.63546 34.4753143    1 #> 19     All  1.94917066 experimental  0.1472751    176.17803  2.0964457    1 #> 20     All  1.98601442      control 10.4512454   2664.66156 12.4372598    1  # Example 2 # 3:1 randomization sim_pw_surv(   n = 20,   block = c(rep(\"experimental\", 3), \"control\") ) #>    stratum enroll_time    treatment   fail_time dropout_time        cte fail #> 1      All   0.3217242 experimental   9.4928294   742.229574   9.814554    1 #> 2      All   0.3565670 experimental  12.4943694   685.656819  12.850936    1 #> 3      All   0.3830329      control   7.9711034  3357.369819   8.354136    1 #> 4      All   0.4244951 experimental  41.0686377  1134.605316  41.493133    1 #> 5      All   0.4762787 experimental 116.8281381  1848.415820 117.304417    1 #> 6      All   0.4887699      control  28.9180215   146.013236  29.406791    1 #> 7      All   0.6136093 experimental   1.1196077   162.507928   1.733217    1 #> 8      All   0.6891445 experimental  44.2434604     4.963087   5.652231    0 #> 9      All   0.7894425 experimental   4.5214569   456.380132   5.310899    1 #> 10     All   1.0188476      control   5.8872020  1544.620162   6.906050    1 #> 11     All   1.0209447 experimental   6.9775576   276.484136   7.998502    1 #> 12     All   1.2873632 experimental  14.8730426   426.240944  16.160406    1 #> 13     All   1.4099907 experimental   0.1715598    30.568471   1.581550    1 #> 14     All   1.4468614 experimental  10.0687941  3025.328402  11.515656    1 #> 15     All   1.4532458      control   2.4995260  1411.869284   3.952772    1 #> 16     All   1.5900233 experimental  17.4354083  1147.682266  19.025432    1 #> 17     All   1.6577903 experimental  99.0519123    76.763221  78.421012    0 #> 18     All   1.8990358 experimental  19.0166778   440.688450  20.915714    1 #> 19     All   2.1388782      control  19.5929947   286.458360  21.731873    1 #> 20     All   2.2620772 experimental   3.6437051  1873.164324   5.905782    1  # Example 3 # Simulate 2 stratum; will use defaults for blocking and enrollRates sim_pw_surv(   n = 20,   # 2 stratum,30% and 70% prevalence   stratum = data.frame(stratum = c(\"Low\", \"High\"), p = c(.3, .7)),   fail_rate = data.frame(     stratum = c(rep(\"Low\", 4), rep(\"High\", 4)),     period = rep(1:2, 4),     treatment = rep(c(       rep(\"control\", 2),       rep(\"experimental\", 2)     ), 2),     duration = rep(c(3, 1), 4),     rate = c(.03, .05, .03, .03, .05, .08, .07, .04)   ),   dropout_rate = data.frame(     stratum = c(rep(\"Low\", 2), rep(\"High\", 2)),     period = rep(1, 4),     treatment = rep(c(\"control\", \"experimental\"), 2),     duration = rep(1, 4),     rate = rep(.001, 4)   ) ) #>    stratum enroll_time    treatment fail_time dropout_time       cte fail #> 1     High  0.05272381 experimental  9.066633    494.34540  9.119357    1 #> 2      Low  0.13566515 experimental 78.546249    128.42704 78.681914    1 #> 3     High  0.26260540 experimental 54.966515     21.84553 22.108138    0 #> 4     High  0.33482645      control  7.189508   2008.07518  7.524335    1 #> 5      Low  0.48250535      control 14.974977    517.85966 15.457482    1 #> 6     High  0.68305515      control  7.064524    513.65581  7.747579    1 #> 7     High  0.81710026      control 21.438898   1164.23533 22.255998    1 #> 8     High  1.07033538      control 19.713971   2212.00385 20.784306    1 #> 9      Low  1.41332672      control 19.401860   2560.64452 20.815187    1 #> 10    High  1.61703621 experimental 17.517759    699.12197 19.134795    1 #> 11    High  1.61704018 experimental  7.688537    788.59361  9.305577    1 #> 12     Low  1.68979094 experimental  8.225572     89.70154  9.915363    1 #> 13     Low  1.73695233      control  4.916503   1871.11105  6.653455    1 #> 14     Low  1.78646504      control  6.955286    276.59924  8.741751    1 #> 15    High  1.79986228 experimental 16.726290    382.11254 18.526153    1 #> 16     Low  1.80771972 experimental 40.504842    653.13538 42.312562    1 #> 17     Low  1.90859178 experimental  4.846215    170.22468  6.754807    1 #> 18    High  1.99798037      control 43.722842     23.72062 25.718601    0 #> 19    High  2.00729138      control 15.319417    661.56404 17.326709    1 #> 20    High  2.02787066 experimental 22.863487    134.13149 24.891357    1 # Example 4 # If you want a more rectangular entry for a data.frame fail_rate <- bind_rows(   data.frame(stratum = \"Low\", period = 1, treatment = \"control\", duration = 3, rate = .03),   data.frame(stratum = \"Low\", period = 1, treatment = \"experimental\", duration = 3, rate = .03),   data.frame(stratum = \"Low\", period = 2, treatment = \"experimental\", duration = 3, rate = .02),   data.frame(stratum = \"High\", period = 1, treatment = \"control\", duration = 3, rate = .05),   data.frame(stratum = \"High\", period = 1, treatment = \"experimental\", duration = 3, rate = .06),   data.frame(stratum = \"High\", period = 2, treatment = \"experimental\", duration = 3, rate = .03) )  dropout_rate <- bind_rows(   data.frame(stratum = \"Low\", period = 1, treatment = \"control\", duration = 3, rate = .001),   data.frame(stratum = \"Low\", period = 1, treatment = \"experimental\", duration = 3, rate = .001),   data.frame(stratum = \"High\", period = 1, treatment = \"control\", duration = 3, rate = .001),   data.frame(stratum = \"High\", period = 1, treatment = \"experimental\", duration = 3, rate = .001) )  sim_pw_surv(   n = 12,   stratum = data.frame(stratum = c(\"Low\", \"High\"), p = c(.3, .7)),   fail_rate = fail_rate,   dropout_rate = dropout_rate ) #>    stratum enroll_time    treatment fail_time dropout_time        cte fail #> 1      Low   0.1321033 experimental 49.865443   1562.73537  49.997547    1 #> 2     High   0.3007465 experimental 18.103313    117.95707  18.404059    1 #> 3     High   0.4960628      control 13.752074    908.18929  14.248136    1 #> 4     High   0.5495319 experimental 36.791951    599.65573  37.341483    1 #> 5      Low   0.7205039 experimental 22.158442   1352.21930  22.878946    1 #> 6     High   0.8137968      control 34.253180    930.71607  35.066977    1 #> 7     High   0.8824684      control  8.837317     13.13534   9.719785    1 #> 8     High   0.9442470 experimental 53.139230   1493.85426  54.083477    1 #> 9     High   0.9865067 experimental 57.256334   1265.50109  58.242841    1 #> 10     Low   1.2318692      control 41.671776    403.53936  42.903645    1 #> 11    High   1.2658735      control 56.696444     46.61400  47.879875    0 #> 12     Low   1.4219050      control 98.788315    553.18286 100.210220    1"},{"path":"https://merck.github.io/simtrial/reference/simtrial-package.html","id":null,"dir":"Reference","previous_headings":"","what":"simtrial: Clinical Trial Simulation — simtrial-package","title":"simtrial: Clinical Trial Simulation — simtrial-package","text":"Provides basic routines simulating clinical trial. primary intent provide tools generate trial simulations trials time event outcomes. Piecewise exponential failure rates piecewise constant enrollment rates underlying mechanism used simulate broad range scenarios presented Lin et al. (2020) doi:10.1080/19466315.2019.1697738 . However, basic generation data done using pipes allow maximum flexibility users meet different needs.","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/reference/simtrial-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"simtrial: Clinical Trial Simulation — simtrial-package","text":"Maintainer: Yujie Zhao yujie.zhao@merck.com Authors: Keaven Anderson keaven_anderson@merck.com John Blischak Yilong Zhang contributors: Nan Xiao [contributor] Jianxiao Yang [contributor] Lili Ling [contributor] Xintong Li [contributor] Ruixue Wang [contributor] Yi Cui [contributor] Ping Yang [contributor] Yalin Zhu [contributor] Heng Zhou [contributor] Amin Shirazi [contributor] Cole Manschot [contributor] Larry Leon [contributor] Merck & Co., Inc., Rahway, NJ, USA affiliates [copyright holder]","code":""},{"path":"https://merck.github.io/simtrial/reference/summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of group sequential simulations. — summary.simtrial_gs_wlr","title":"Summary of group sequential simulations. — summary.simtrial_gs_wlr","text":"Summary group sequential simulations.","code":""},{"path":"https://merck.github.io/simtrial/reference/summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of group sequential simulations. — summary.simtrial_gs_wlr","text":"","code":"# S3 method for class 'simtrial_gs_wlr' summary(object, design = NULL, bound = NULL, ...)"},{"path":"https://merck.github.io/simtrial/reference/summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of group sequential simulations. — summary.simtrial_gs_wlr","text":"object Simulation results generated sim_gs_n() design Asymptotic design generated gsDesign2::gs_design_ahr(), gsDesign2::gs_power_ahr(), gsDesign2::gs_design_wlr(), gsDesign2::gs_power_wlr. bound boundaries. ... Additional parameters (used).","code":""},{"path":"https://merck.github.io/simtrial/reference/summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of group sequential simulations. — summary.simtrial_gs_wlr","text":"data frame","code":""},{"path":"https://merck.github.io/simtrial/reference/summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of group sequential simulations. — summary.simtrial_gs_wlr","text":"","code":"library(gsDesign2)  # Parameters for enrollment enroll_rampup_duration <- 4 # Duration for enrollment ramp up enroll_duration <- 16 # Total enrollment duration enroll_rate <- define_enroll_rate(   duration = c(     enroll_rampup_duration, enroll_duration - enroll_rampup_duration),  rate = c(10, 30))  # Parameters for treatment effect delay_effect_duration <- 3 # Delay treatment effect in months median_ctrl <- 9 # Survival median of the control arm median_exp <- c(9, 14) # Survival median of the experimental arm dropout_rate <- 0.001 fail_rate <- define_fail_rate(   duration = c(delay_effect_duration, 100),   fail_rate = log(2) / median_ctrl,   hr = median_ctrl / median_exp,   dropout_rate = dropout_rate)  # Other related parameters alpha <- 0.025 # Type I error beta <- 0.1 # Type II error ratio <- 1 # Randomization ratio (experimental:control)  # Build a one-sided group sequential design design <- gs_design_ahr(   enroll_rate = enroll_rate, fail_rate = fail_rate,   ratio = ratio, alpha = alpha, beta = beta,   analysis_time = c(12, 24, 36),   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = alpha),   lower = gs_b,   lpar = rep(-Inf, 3))  # Define cuttings of 2 IAs and 1 FA ia1_cut <- create_cut(target_event_overall = ceiling(design$analysis$event[1])) ia2_cut <- create_cut(target_event_overall = ceiling(design$analysis$event[2])) fa_cut <- create_cut(target_event_overall = ceiling(design$analysis$event[3]))  # Run simulations simulation <- sim_gs_n(   n_sim = 3,   sample_size = ceiling(design$analysis$n[3]),   enroll_rate = design$enroll_rate,   fail_rate = design$fail_rate,   test = wlr,   cut = list(ia1 = ia1_cut, ia2 = ia2_cut, fa = fa_cut),   weight = fh(rho = 0, gamma = 0.5)) #> Backend uses sequential processing.  # Summarize simulations bound <- gsDesign::gsDesign(k = 3, test.type = 1, sfu = gsDesign::sfLDOF)$upper$bound simulation |> summary(bound = bound) #>   analysis    sim_n sim_event sim_time sim_upper_prob #> 1        1 356.6667        97 11.87400             NA #> 2        2 505.0000       305 24.66698              1 #> 3        3 505.0000       405 37.58585             NA  # Summarize simulation and compare with the planned design simulation |> summary(design = design) #>   analysis asy_upper_prob sim_upper_prob sim_event    sim_n sim_time asy_time #> 1        1   0.0001486592             NA        97 356.6667 11.87400       12 #> 2        2   0.5723210881              1       305 505.0000 24.66698       24 #> 3        3   0.8999997572             NA       405 505.0000 37.58585       36 #>      asy_n asy_event #> 1 353.0464  96.77449 #> 2 504.3520 304.00970 #> 3 504.3520 404.14162"},{"path":"https://merck.github.io/simtrial/reference/to_sim_pw_surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert enrollment and failure rates from sim_fixed_n() to sim_pw_surv() format — to_sim_pw_surv","title":"Convert enrollment and failure rates from sim_fixed_n() to sim_pw_surv() format — to_sim_pw_surv","text":"to_sim_pw_surv() converts failure rates dropout rates entered simpler format sim_fixed_n() used sim_pw_surv(). fail_rate argument sim_fixed_n() requires enrollment rates, failure rates hazard ratios dropout rates stratum 2-arm trial, sim_pw_surv() flexible less obvious flexible format. Since sim_fixed_n() automatically analyzes data sim_pw_surv() just produces simulation dataset, latter provides additional options analyze otherwise evaluate individual simulations ways sim_fixed_n() .","code":""},{"path":"https://merck.github.io/simtrial/reference/to_sim_pw_surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert enrollment and failure rates from sim_fixed_n() to sim_pw_surv() format — to_sim_pw_surv","text":"","code":"to_sim_pw_surv(   fail_rate = data.frame(stratum = \"All\", duration = c(3, 100), fail_rate = log(2)/c(9,     18), hr = c(0.9, 0.6), dropout_rate = rep(0.001, 2)) )"},{"path":"https://merck.github.io/simtrial/reference/to_sim_pw_surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert enrollment and failure rates from sim_fixed_n() to sim_pw_surv() format — to_sim_pw_surv","text":"fail_rate Piecewise constant control group failure rates, hazard ratio experimental vs. control, dropout rates stratum time period.","code":""},{"path":"https://merck.github.io/simtrial/reference/to_sim_pw_surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert enrollment and failure rates from sim_fixed_n() to sim_pw_surv() format — to_sim_pw_surv","text":"list two data frame components formatted sim_pw_surv(): fail_rate dropout_rate.","code":""},{"path":"https://merck.github.io/simtrial/reference/to_sim_pw_surv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert enrollment and failure rates from sim_fixed_n() to sim_pw_surv() format — to_sim_pw_surv","text":"","code":"# Example 1 # Convert standard input to_sim_pw_surv() #> $fail_rate #>   stratum period    treatment duration       rate #> 1     All      1      control        3 0.07701635 #> 2     All      2      control      100 0.03850818 #> 3     All      1 experimental        3 0.06931472 #> 4     All      2 experimental      100 0.02310491 #>  #> $dropout_rate #>   stratum period    treatment duration  rate #> 1     All      1      control        3 0.001 #> 2     All      2      control      100 0.001 #> 3     All      1 experimental        3 0.001 #> 4     All      2 experimental      100 0.001 #>   # Stratified example fail_rate <- data.frame(   stratum = c(rep(\"Low\", 3), rep(\"High\", 3)),   duration = rep(c(4, 10, 100), 2),   fail_rate = c(     .04, .1, .06,     .08, .16, .12   ),   hr = c(     1.5, .5, 2 / 3,     2, 10 / 16, 10 / 12   ),   dropout_rate = .01 )  x <- to_sim_pw_surv(fail_rate)  # Do a single simulation with the above rates # Enroll 300 patients in ~12 months at constant rate sim <- sim_pw_surv(   n = 300,   stratum = data.frame(stratum = c(\"Low\", \"High\"), p = c(.6, .4)),   enroll_rate = data.frame(duration = 12, rate = 300 / 12),   fail_rate = x$fail_rate,   dropout_rate = x$dropout_rate )  # Cut after 200 events and do a stratified logrank test sim |>   cut_data_by_event(200) |> # Cut data   wlr(weight = fh(rho = 0, gamma = 0)) # Stratified logrank #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"FH(rho=0, gamma=0)\" #>  #> $estimate #> [1] 2.340246 #>  #> $se #> [1] 6.972734 #>  #> $z #> [1] -0.3356281 #>  #> $info #> [1] 49.92 #>  #> $info0 #> [1] 50 #>"},{"path":"https://merck.github.io/simtrial/reference/wlr.html","id":null,"dir":"Reference","previous_headings":"","what":"Weighted logrank test — wlr","title":"Weighted logrank test — wlr","text":"Weighted logrank test","code":""},{"path":"https://merck.github.io/simtrial/reference/wlr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weighted logrank test — wlr","text":"","code":"wlr(data, weight, return_variance = FALSE, ratio = NULL, formula = NULL)  # Default S3 method wlr(data, weight, return_variance = FALSE, ratio = NULL, formula = NULL)  # S3 method for class 'tte_data' wlr(data, weight, return_variance = FALSE, ratio = NULL, formula = NULL)  # S3 method for class 'counting_process' wlr(data, weight, return_variance = FALSE, ratio = NULL, formula = NULL)"},{"path":"https://merck.github.io/simtrial/reference/wlr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Weighted logrank test — wlr","text":"data Dataset (generated sim_pw_surv()) cut counting_process(), cut_data_by_date(), cut_data_by_event(). weight Weighting functions, fh(), mb(), early_zero(). return_variance logical flag , TRUE, adds columns estimated variance weighted sum observed minus expected; see details; Default: FALSE. ratio randomization ratio (experimental:control). data generated simtrial, data = sim_pw_surv(...) |> cut_data_by_date(...) data = sim_pw_surv(...) |> cut_data_by_event(...) data = sim_pw_surv(...) |> cut_data_by_date(...) |> counting_process(...) data = sim_pw_surv(...) |> cut_data_by_event(...) |> counting_process(...) need input ratio, simtrial gets ratio via block arguments sim_pw_surv(). data custom dataset (see Example 2) , Users suggested input planned randomization ratio ratio; , simtrial takes empirical randomization ratio. formula formula specify columns contain time--event, event, treatment, stratum variables. used default S3 method classes aleady required column names. stratified designs, formula form Surv(tte, event) ~ treatment + strata(stratum), tte, event, treatment, stratum column names data time--event measurement, event status, treatment group, stratum, respectively. unstratified designs, formula can omit stratum column: Surv(tte, event) ~ treatment.","code":""},{"path":"https://merck.github.io/simtrial/reference/wlr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Weighted logrank test — wlr","text":"list containing test method (method), parameters test method (parameter), point estimate treatment effect (estimate), standardized error treatment effect (se), Z-score (z), p-values (p_value).","code":""},{"path":"https://merck.github.io/simtrial/reference/wlr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Weighted logrank test — wlr","text":"\\(z\\) - Standardized normal Fleming-Harrington weighted logrank test. \\(\\) - Stratum index. \\(d_i\\) - Number distinct times events occurred stratum \\(\\). \\(t_{ij}\\) - Ordered times events stratum \\(\\), \\(j = 1, 2, \\ldots, d_i\\) observed; observation, \\(t_{ij}\\) represents time post study entry. \\(O_{ij.}\\) - Total number events stratum \\(\\) occurred time \\(t_{ij}\\). \\(O_{ije}\\) - Total number events stratum \\(\\) experimental treatment group occurred time \\(t_{ij}\\). \\(N_{ij.}\\) - Total number study subjects stratum \\(\\) followed least duration. \\(E_{ije}\\) - Expected observations experimental treatment group given random selection \\(O_{ij.}\\) stratum \\(\\) risk time \\(t_{ij}\\). \\(V_{ije}\\) - Hypergeometric variance \\(E_{ije}\\) produced Var counting_process(). \\(N_{ije}\\) - Total number study subjects stratum \\(\\) experimental treatment group followed least duration \\(t_{ij}\\). \\(E_{ije}\\) - Expected observations experimental group stratum \\(\\) time \\(t_{ij}\\) conditioning overall number events risk populations time sampling risk observations without replacement: $$E_{ije} = O_{ij.} N_{ije}/N_{ij.}$$ \\(S_{ij}\\) - Kaplan-Meier estimate survival combined treatment groups immediately prior time \\(t_{ij}\\). \\(\\rho, \\gamma\\) - Real parameters Fleming-Harrington test. \\(X_i\\) - Numerator signed logrank test stratum \\(\\) $$X_i = \\sum_{j=1}^{d_{}} S_{ij}^\\rho(1-S_{ij}^\\gamma)(O_{ije}-E_{ije})$$ \\(V_{ij}\\) - Variance used denominator Fleming-Harrington weighted logrank tests $$V_i = \\sum_{j=1}^{d_{}} (S_{ij}^\\rho(1-S_{ij}^\\gamma))^2V_{ij})$$ stratified Fleming-Harrington weighted logrank test computed : $$z = \\sum_i X_i/\\sqrt{\\sum_i V_i}.$$","code":""},{"path":"https://merck.github.io/simtrial/reference/wlr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Weighted logrank test — wlr","text":"","code":"# ---------------------- # #      Example 1         # #  Use dataset generated # #     by simtrial        # # ---------------------- # x <- sim_pw_surv(n = 200) |> cut_data_by_event(100)  # Example 1A: WLR test with FH wights x |> wlr(weight = fh(rho = 0, gamma = 0.5)) #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"FH(rho=0, gamma=0.5)\" #>  #> $estimate #> [1] -8.982144 #>  #> $se #> [1] 2.598847 #>  #> $z #> [1] 3.456203 #>  #> $info #> [1] 6.622735 #>  #> $info0 #> [1] 7.11092 #>  x |> wlr(weight = fh(rho = 0, gamma = 0.5), return_variance = TRUE) #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"FH(rho=0, gamma=0.5)\" #>  #> $estimate #> [1] -8.982144 #>  #> $se #> [1] 2.598847 #>  #> $z #> [1] 3.456203 #>  #> $info #> [1] 6.622735 #>  #> $info0 #> [1] 7.11092 #>   # Example 1B: WLR test with MB wights x |> wlr(weight = mb(delay = 4, w_max = 2)) #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"MB(delay = 4, max_weight = 2)\" #>  #> $estimate #> [1] -17.35719 #>  #> $se #> [1] 6.009561 #>  #> $z #> [1] 2.888262 #>  #> $info #> [1] 35.45611 #>  #> $info0 #> [1] 37.12714 #>   # Example 1C: WLR test with early zero wights x |> wlr(weight = early_zero(early_period = 4)) #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"Xu 2017 with first 4 months of 0 weights\" #>  #> $estimate #> [1] -16.35958 #>  #> $se #> [1] 3.658775 #>  #> $z #> [1] 4.471326 #>  #> $info #> [1] 11.42857 #>  #> $info0 #> [1] 14 #>   # Example 1D # For increased computational speed when running many WLR tests, you can # pre-compute the counting_process() step first, and then pass the result of # counting_process() directly to wlr() x <- x |> counting_process(arm = \"experimental\") x |> wlr(weight = fh(rho = 0, gamma = 1)) #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"FH(rho=0, gamma=1)\" #>  #> $estimate #> [1] -6.044199 #>  #> $se #> [1] 1.645134 #>  #> $z #> [1] 3.673987 #>  #> $info #> [1] 2.737818 #>  #> $info0 #> [1] 2.918227 #>  x |> wlr(weight = mb(delay = 4, w_max = 2)) #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"MB(delay = 4, max_weight = 2)\" #>  #> $estimate #> [1] -17.35719 #>  #> $se #> [1] 6.009561 #>  #> $z #> [1] 2.888262 #>  #> $info #> [1] 35.45611 #>  #> $info0 #> [1] 37.12714 #>  x |> wlr(weight = early_zero(early_period = 4)) #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"Xu 2017 with first 4 months of 0 weights\" #>  #> $estimate #> [1] -16.35958 #>  #> $se #> [1] 3.658775 #>  #> $z #> [1] 4.471326 #>  #> $info #> [1] 11.42857 #>  #> $info0 #> [1] 14 #>   # ---------------------- # #      Example 2         # #  Use cumsum dataset    # # ---------------------- # x <- data.frame(treatment = ifelse(ex1_delayed_effect$trt == 1, \"experimental\", \"control\"),                 stratum = rep(\"All\", nrow(ex1_delayed_effect)),                 tte = ex1_delayed_effect$month,                 event = ex1_delayed_effect$evntd)  # Users can specify the randomization ratio to calculate the statistical information under H0 x |> wlr(weight = fh(rho = 0, gamma = 0.5), ratio = 2) #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"FH(rho=0, gamma=0.5)\" #>  #> $estimate #> [1] -12.28665 #>  #> $se #> [1] 3.716574 #>  #> $z #> [1] 3.305908 #>  #> $info #> [1] 16.60727 #>  #> $info0 #> [1] 15.27192 #>   x |>   counting_process(arm = \"experimental\") |>   wlr(weight = fh(rho = 0, gamma = 0.5), ratio = 2) #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"FH(rho=0, gamma=0.5)\" #>  #> $estimate #> [1] -12.28665 #>  #> $se #> [1] 3.716574 #>  #> $z #> [1] 3.305908 #>  #> $info #> [1] 16.60727 #>  #> $info0 #> [1] 15.27192 #>   # If users don't provide the randomization ratio, we will calculate the emperical ratio x |> wlr(weight = fh(rho = 0, gamma = 0.5)) #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"FH(rho=0, gamma=0.5)\" #>  #> $estimate #> [1] -12.28665 #>  #> $se #> [1] 3.716574 #>  #> $z #> [1] 3.305908 #>  #> $info #> [1] 16.60727 #>  #> $info0 #> [1] 15.31399 #>   x |>   counting_process(arm = \"experimental\") |>   wlr(weight = fh(rho = 0, gamma = 0.5)) #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"FH(rho=0, gamma=0.5)\" #>  #> $estimate #> [1] -12.28665 #>  #> $se #> [1] 3.716574 #>  #> $z #> [1] 3.305908 #>  #> $info #> [1] 16.60727 #>  #> $info0 #> [1] 15.31399 #>   # ---------------------- # #      Example 3         # #  Use formula           # # ---------------------- # library(\"survival\")  # Unstratified design x <- sim_pw_surv(n = 200) |> cut_data_by_event(100) |> as.data.frame() colnames(x) <- c(\"tte\", \"evnt\", \"strtm\", \"trtmnt\") wlr(x, weight = fh(0, 0.5), formula = Surv(tte, evnt) ~ trtmnt) #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"FH(rho=0, gamma=0.5)\" #>  #> $estimate #> [1] -8.151712 #>  #> $se #> [1] 2.559737 #>  #> $z #> [1] 3.184589 #>  #> $info #> [1] 6.588311 #>  #> $info0 #> [1] 6.955264 #>   # Stratified design x$strtm <- sample(c(\"s1\", \"s2\"), size = nrow(x), replace = TRUE) wlr(x, weight = fh(0, 0.5), formula = Surv(tte, evnt) ~ trtmnt + strata(strtm)) #> $method #> [1] \"WLR\" #>  #> $parameter #> [1] \"FH(rho=0, gamma=0.5)\" #>  #> $estimate #> [1] -7.446813 #>  #> $se #> [1] 2.571142 #>  #> $z #> [1] 2.896306 #>  #> $info #> [1] 6.562729 #>  #> $info0 #> [1] 6.925405 #>"},{"path":"https://merck.github.io/simtrial/news/index.html","id":"simtrial-100","dir":"Changelog","previous_headings":"","what":"simtrial 1.0.0","title":"simtrial 1.0.0","text":"CRAN release: 2025-06-11","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"statistical-improvements-1-0-0","dir":"Changelog","previous_headings":"","what":"Statistical improvements","title":"simtrial 1.0.0","text":"Provide updated boundary objects generated sim_gs_n() (#255, thanks @LittleBeannie). Users can now pass formula call wlr() function (#280, thanks @jdblischak). wlr() now S3 class method tte_data class counting_process class (@276, #280, @281, thanks @jdblischak) randomization ratio output attributes sim_pw_surv() (#279, #311 thanks @LittleBeannie @jdblischak).","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"documentation-1-0-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"simtrial 1.0.0","text":"Add 3 vignettes introducing simulation fixed group sequential design via single function call sim_fixed_n() sim_gs_n() ground (#302, #316, thanks @LittleBeannie). Add vignette discussing potential discrepancies simtrial survdiff (#308, thanks @larry-leon). Update parallel vignette address data.table multithreading (#319, thanks @jdblischak).","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"speed-improvements-1-0-0","dir":"Changelog","previous_headings":"","what":"Speed improvements","title":"simtrial 1.0.0","text":"Optimize parallel simulation speed sim_fixed_n() sim_gs_n() replacing foreach(.combine = \"rbind\") manual data frame combination (#318, thanks @nanxstats).","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"simtrial-042","dir":"Changelog","previous_headings":"","what":"simtrial 0.4.2","title":"simtrial 0.4.2","text":"CRAN release: 2024-11-18","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"statistical-improvements-0-4-2","dir":"Changelog","previous_headings":"","what":"Statistical improvements","title":"simtrial 0.4.2","text":"Summary function sim_gs_n() available (#268, thanks @LittleBeannie). denominator milestone test Z-score corrected (#270, thanks @LittleBeannie). Statistical information added output sim_gs_n() (#273, thanks @LittleBeannie). randomization ratio built attribute sim_pw_surv() passed wlr() test (#281, #285 thanks @LittleBeannie @jdblischak). sign Z-score unified positive numbers (#272, #286, thanks @LittleBeannie @jdblischak).","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"computational-improvements-0-4-2","dir":"Changelog","previous_headings":"","what":"Computational improvements","title":"simtrial 0.4.2","text":"source code summary() rewritten tibble data.frame data.table, optimized use little memory possible avoiding making unnecessary temporary copies data frames. results code efficient time memory use. (#289, thanks @jdblischak). sim_fixed_n() function updated allow parallel simulations (#249, #252, #253, #262, thanks @cmansch @jdblischak).","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"bug-fixes-0-4-2","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"simtrial 0.4.2","text":"Fixed bug cut functions parallel (#261, thanks @cmansch).","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"coding-improvements-0-4-2","dir":"Changelog","previous_headings":"","what":"Coding improvements","title":"simtrial 0.4.2","text":"wlr() function enhanced S3 generic accept counting process time--event data input (#276, #277, thanks @jdblischak).","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"documentation-0-4-2","dir":"Changelog","previous_headings":"","what":"Documentation","title":"simtrial 0.4.2","text":"Use KaTeX pkgdown math rendering (#263, thanks @nanxstats).","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"tests-0-4-2","dir":"Changelog","previous_headings":"","what":"Tests","title":"simtrial 0.4.2","text":"Regression tests summary() added (#282, thanks @jdblischak).","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"simtrial-041","dir":"Changelog","previous_headings":"","what":"simtrial 0.4.1","title":"simtrial 0.4.1","text":"CRAN release: 2024-05-03","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"improvements-0-4-1","dir":"Changelog","previous_headings":"","what":"Improvements","title":"simtrial 0.4.1","text":"Pass noSuggests checks running code examples, tests, vignettes conditionally Suggests dependencies installed (#243).","code":""},{"path":[]},{"path":"https://merck.github.io/simtrial/news/index.html","id":"new-features-0-4-0","dir":"Changelog","previous_headings":"","what":"New features","title":"simtrial 0.4.0","text":"rmst() introduces RMST test (#188, thanks, @LittleBeannie). milestone() introduces milestone test (#199, #204, #211, #237, thanks, @LittleBeannie). sim_gs_n() provides experimental implementation fixed sample size group sequential design simulation, unit tests upcoming (#195, #201, #208, #212, thanks, @LittleBeannie @jdblischak). create_cut() allows users create custom interim final analyses cuttings based specific requirements (#201, #221, thanks, @jdblischak). create_test() enables users create various testing approaches interim final analyses (#215, #221, thanks, @jdblischak). multitest() gives users option perform multiple tests simulated dataset (#215, thanks, @jdblischak). Note: function still experimental may improved future releases, created prior standardization test functions #227. Test outputs (logrank, weighted logrank, RMST, milestone, MaxCombo) now unified list including method, parameter, estimate, se, z-value, p-value (#227, thanks, @LittleBeannie).","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"bug-fixes-0-4-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"simtrial 0.4.0","text":"Fixed incorrect weights generated early_zero() stratified designs (#233, thanks, @LittleBeannie).","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"documentation-0-4-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"simtrial 0.4.0","text":"Enhanced documentation get_analysis_date() (#186, thanks, @LittleBeannie).","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"dependency-0-4-0","dir":"Changelog","previous_headings":"","what":"Dependency","title":"simtrial 0.4.0","text":"Removed dependency bshazard package archived CRAN (#234, thanks, @nanxstats).","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"simtrial-032","dir":"Changelog","previous_headings":"","what":"simtrial 0.3.2","title":"simtrial 0.3.2","text":"CRAN release: 2023-12-11 release makes minor improvements auxiliary code side-effects.","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"improvements-0-3-2","dir":"Changelog","previous_headings":"","what":"Improvements","title":"simtrial 0.3.2","text":"Remove code sets options() within vignette(\"modest-wlrt\"). Updated code used generating image assets. scripts now write tempdir() instead package directory.","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"simtrial-031","dir":"Changelog","previous_headings":"","what":"simtrial 0.3.1","title":"simtrial 0.3.1","text":"release introduces significant changes API, improves simulation performance substantially, adds new features documentation.","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"significant-user-visible-changes-0-3-1","dir":"Changelog","previous_headings":"","what":"Significant user-visible changes","title":"simtrial 0.3.1","text":"Complete overhaul API. Function argument names now use snake case consistency readability. See function reference updated naming scheme. Detailed change history available merged pull requests (thanks, @LittleBeannie, @lili-ling-msd, @XintongLi2023). Dataset names updated snake case (thanks, @nanxstats, #164). base pipe operator now used throughout package. magrittr pipe longer re-exported (thanks, @nanxstats, #146).","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"improvements-0-3-1","dir":"Changelog","previous_headings":"","what":"Improvements","title":"simtrial 0.3.1","text":"Rewritten table backend simtrial functions using data.table, achieving 3x 5x speedup compared previous implementation (thanks, @jdblischak, #111). sim_fixed_n() now utilizes %dofuture% operator parallelization, enhancing flexibility reproducibility (thanks, @cmansch, #110). rpwexp() adopts inverse CDF method random number generation, naive methods now internal functions (thanks, @jianxiaoyang, #15 #174). sim_fixed_n() optimized skip Breslow’s method absence ties (thanks, @jdblischak, #130). internal function computing Z statistics Fleming-Harrington weighted logrank tests now named wlr_z_stat() (thanks, @elong0527, #105).","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"new-features-0-3-1","dir":"Changelog","previous_headings":"","what":"New features","title":"simtrial 0.3.1","text":"early_zero_weight() added weighting function early data removal (thanks, @LittleBeannie, #123). get_analysis_date() added calculate interim/final analysis dates various conditions (thanks, @LittleBeannie, #122).","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"documentation-0-3-1","dir":"Changelog","previous_headings":"","what":"Documentation","title":"simtrial 0.3.1","text":"New vignette(\"workflow\") providing overview data manipulations involved TTE simulations (thanks, @keaven, #99). New vignette(\"parallel\") demonstrating parallelization workflow coding best practices (thanks, @cmansch, #113 #134).","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"miscellaneous-0-3-1","dir":"Changelog","previous_headings":"","what":"Miscellaneous","title":"simtrial 0.3.1","text":"Added hex sticker logo generative art design package (thanks, @keaven, #158).","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"simtrial-022","dir":"Changelog","previous_headings":"","what":"simtrial 0.2.2","title":"simtrial 0.2.2","text":"GitHub release February 2023. version enables parallel computation simfix().","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"simtrial-021","dir":"Changelog","previous_headings":"","what":"simtrial 0.2.1","title":"simtrial 0.2.1","text":"GitHub release May 2022. version supports Biometrical Journal paper “unified framework weighted parametric group sequential design (WPGSD)” Keaven M. Anderson, Zifang Guo, Jing Zhao, Linda Z. Sun.","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"simtrial-020","dir":"Changelog","previous_headings":"","what":"simtrial 0.2.0","title":"simtrial 0.2.0","text":"Internal development release August 2020. Updated vignettes website. Prepared Regulatory/Industry training session September.","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"simtrial-0179004","dir":"Changelog","previous_headings":"","what":"simtrial 0.1.7.9004","title":"simtrial 0.1.7.9004","text":"Internal development release February 2020. Added wMB() compute Magirr-Burman weights. Added vignette demonstrate working different weighting schemes. Replaced Depends Imports DESCRIPTION.","code":""},{"path":"https://merck.github.io/simtrial/news/index.html","id":"simtrial-0179003","dir":"Changelog","previous_headings":"","what":"simtrial 0.1.7.9003","title":"simtrial 0.1.7.9003","text":"Internal development release November 2019. Incorporated new functions simplify use (simfix(), simfix2simPWSurv(), pMaxCombo()). Removed hgraph() intent put release gsDesign. Limited 2 essential vignettes. Added continuous integration/continuous deployment (YAML) pkgdown website generation. Limited dependencies essential; removed convenience functions related core package functionality.","code":""}]
